2022-09-13 00:17:14,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:17:14,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:17:14,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:17:14,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:17:15,196:INFO:PyCaret RegressionExperiment
2022-09-13 00:17:15,197:INFO:Logging name: reg-default-name
2022-09-13 00:17:15,197:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-13 00:17:15,197:INFO:version 3.0.0.rc3
2022-09-13 00:17:15,197:INFO:Initializing setup()
2022-09-13 00:17:15,197:INFO:self.USI: ce03
2022-09-13 00:17:15,197:INFO:self.variable_keys: {'_gpu_n_jobs_param', 'exp_id', 'X_test', '_ml_usecase', 'display_container', 'target_param', 'gpu_param', 'pipeline', '_all_models', 'n_jobs_param', 'master_model_container', 'exp_name_log', 'fold_groups_param', 'data', 'html_param', 'logging_param', 'X', 'y_test', 'X_train', 'transform_target_param', 'variable_keys', '_all_metrics', 'idx', 'y_train', '_available_plots', 'y', 'log_plots_param', 'USI', 'fold_generator', 'fold_shuffle_param', 'memory', 'transform_target_method_param', 'seed', '_all_models_internal'}
2022-09-13 00:17:15,197:INFO:Checking environment
2022-09-13 00:17:15,197:INFO:python_version: 3.7.11
2022-09-13 00:17:15,198:INFO:python_build: ('default', 'Jul 27 2021 09:42:29')
2022-09-13 00:17:15,198:INFO:machine: AMD64
2022-09-13 00:17:15,198:INFO:platform: Windows-10-10.0.22000-SP0
2022-09-13 00:17:15,198:INFO:Memory: svmem(total=34156802048, available=11263660032, percent=67.0, used=22893142016, free=11263660032)
2022-09-13 00:17:15,198:INFO:Physical Core: 6
2022-09-13 00:17:15,198:INFO:Logical Core: 12
2022-09-13 00:17:15,198:INFO:Checking libraries
2022-09-13 00:17:15,198:INFO:System:
2022-09-13 00:17:15,198:INFO:    python: 3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]
2022-09-13 00:17:15,198:INFO:executable: c:\Users\Jamel\anaconda3\envs\dev\python.exe
2022-09-13 00:17:15,198:INFO:   machine: Windows-10-10.0.22000-SP0
2022-09-13 00:17:15,198:INFO:PyCaret required dependencies:
2022-09-13 00:17:15,198:INFO:                 pip: 22.1.2
2022-09-13 00:17:15,198:INFO:          setuptools: 60.10.0
2022-09-13 00:17:15,198:INFO:             pycaret: 3.0.0rc3
2022-09-13 00:17:15,198:INFO:             IPython: 7.31.1
2022-09-13 00:17:15,198:INFO:          ipywidgets: 7.6.5
2022-09-13 00:17:15,199:INFO:                tqdm: 4.64.0
2022-09-13 00:17:15,199:INFO:               numpy: 1.21.6
2022-09-13 00:17:15,199:INFO:              pandas: 1.3.5
2022-09-13 00:17:15,199:INFO:              jinja2: 3.0.3
2022-09-13 00:17:15,199:INFO:               scipy: 1.7.3
2022-09-13 00:17:15,199:INFO:              joblib: 1.1.0
2022-09-13 00:17:15,199:INFO:             sklearn: 1.0.2
2022-09-13 00:17:15,199:INFO:                pyod: 1.0.4
2022-09-13 00:17:15,199:INFO:            imblearn: 0.9.0
2022-09-13 00:17:15,199:INFO:   category_encoders: 2.5.0
2022-09-13 00:17:15,199:INFO:            lightgbm: 3.3.2
2022-09-13 00:17:15,199:INFO:               numba: 0.55.1
2022-09-13 00:17:15,199:INFO:            requests: 2.28.1
2022-09-13 00:17:15,199:INFO:          matplotlib: 3.5.1
2022-09-13 00:17:15,199:INFO:          scikitplot: 0.3.7
2022-09-13 00:17:15,199:INFO:         yellowbrick: 1.5
2022-09-13 00:17:15,199:INFO:              plotly: 5.9.0
2022-09-13 00:17:15,199:INFO:             kaleido: 0.2.1
2022-09-13 00:17:15,199:INFO:         statsmodels: 0.13.2
2022-09-13 00:17:15,199:INFO:              sktime: 0.13.2
2022-09-13 00:17:15,200:INFO:               tbats: 1.1.0
2022-09-13 00:17:15,200:INFO:            pmdarima: 1.8.5
2022-09-13 00:17:15,200:INFO:              psutil: 5.9.0
2022-09-13 00:17:15,200:INFO:PyCaret optional dependencies:
2022-09-13 00:17:15,211:INFO:                shap: 0.41.0
2022-09-13 00:17:15,211:INFO:           interpret: 0.2.7
2022-09-13 00:17:15,211:INFO:                umap: 0.5.3
2022-09-13 00:17:15,211:INFO:    pandas_profiling: 3.2.0
2022-09-13 00:17:15,211:INFO:  explainerdashboard: 0.3.8.2
2022-09-13 00:17:15,211:INFO:             autoviz: 0.1.43
2022-09-13 00:17:15,212:INFO:           fairlearn: 0.7.0
2022-09-13 00:17:15,212:INFO:             xgboost: 1.6.1
2022-09-13 00:17:15,212:INFO:            catboost: Not installed
2022-09-13 00:17:15,212:INFO:              kmodes: 0.12.1
2022-09-13 00:17:15,212:INFO:             mlxtend: Not installed
2022-09-13 00:17:15,212:INFO:       statsforecast: Not installed
2022-09-13 00:17:15,212:INFO:        tune_sklearn: Not installed
2022-09-13 00:17:15,212:INFO:                 ray: Not installed
2022-09-13 00:17:15,212:INFO:            hyperopt: Not installed
2022-09-13 00:17:15,212:INFO:              optuna: Not installed
2022-09-13 00:17:15,212:INFO:               skopt: Not installed
2022-09-13 00:17:15,212:INFO:              mlflow: Not installed
2022-09-13 00:17:15,212:INFO:              gradio: Not installed
2022-09-13 00:17:15,213:INFO:             fastapi: Not installed
2022-09-13 00:17:15,213:INFO:             uvicorn: Not installed
2022-09-13 00:17:15,213:INFO:              m2cgen: Not installed
2022-09-13 00:17:15,213:INFO:           evidently: Not installed
2022-09-13 00:17:15,213:INFO:                nltk: 3.7
2022-09-13 00:17:15,213:INFO:            pyLDAvis: Not installed
2022-09-13 00:17:15,213:INFO:              gensim: 4.2.0
2022-09-13 00:17:15,213:INFO:               spacy: 3.3.0
2022-09-13 00:17:15,213:INFO:           wordcloud: 1.8.1
2022-09-13 00:17:15,213:INFO:            textblob: 0.17.1
2022-09-13 00:17:15,213:INFO:               fugue: Not installed
2022-09-13 00:17:15,213:INFO:           streamlit: 1.11.0
2022-09-13 00:17:15,213:INFO:             prophet: Not installed
2022-09-13 00:17:15,214:INFO:None
2022-09-13 00:17:15,214:INFO:Set up data.
2022-09-13 00:17:15,221:INFO:Set up train/test split.
2022-09-13 00:17:15,229:INFO:Set up index.
2022-09-13 00:17:15,230:INFO:Set up folding strategy.
2022-09-13 00:17:15,230:INFO:Assigning column types.
2022-09-13 00:17:15,238:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-13 00:17:15,239:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,243:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,248:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,303:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,346:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:15,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:15,632:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,637:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,641:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,693:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,733:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:15,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:15,736:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-13 00:17:15,742:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,746:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,796:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,837:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,838:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:15,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:15,845:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,850:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:17:15,964:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:15,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:15,969:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-13 00:17:15,977:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,038:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,088:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,089:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:16,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:16,099:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,202:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:16,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:16,204:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-13 00:17:16,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,301:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:16,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:16,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,413:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:16,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:16,416:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-13 00:17:16,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,516:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:16,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:16,580:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:17:16,619:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:16,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:16,621:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-13 00:17:16,722:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:16,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:16,825:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:16,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:16,831:INFO:Preparing preprocessing pipeline...
2022-09-13 00:17:16,832:INFO:Set up simple imputation.
2022-09-13 00:17:16,837:INFO:Set up encoding of categorical features.
2022-09-13 00:17:16,837:INFO:Set up variance threshold.
2022-09-13 00:17:17,080:INFO:Finished creating preprocessing pipeline.
2022-09-13 00:17:17,091:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Jamel\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['unix', 'open', 'high', 'low',
                                             'Volume ETH', 'Volume USD'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'date', 'symbol'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Unnamed: 0', 'unix', 'date',
                                             'open', 'high', 'low',
                                             'Volume ETH', 'Volume USD'],
                                    transformer=LeaveOneOutEncoder(cols=['Unnamed: '
                                                                         '0',
                                                                         'date'],
                                                                   handle_missing='return_nan',
                                                                   random_state=1086))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-13 00:17:17,091:INFO:Creating final display dataframe.
2022-09-13 00:17:17,871:INFO:Setup display_container:                  Description             Value
0                 Session id              1086
1                     Target             close
2                Target type        Regression
3                 Data shape          (876, 7)
4           Train data shape          (613, 7)
5            Test data shape          (263, 7)
6           Numeric features                 6
7       Categorical features                 3
8                 Preprocess              True
9            Imputation type            simple
10        Numeric imputation              mean
11    Categorical imputation          constant
12  Maximum one-hot encoding                 5
13           Encoding method              None
14    Low variance threshold                 0
15            Fold Generator             KFold
16               Fold Number                10
17                  CPU Jobs                -1
18                   Use GPU             False
19            Log Experiment             False
20           Experiment Name  reg-default-name
21                       USI              ce03
2022-09-13 00:17:17,983:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:17,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:18,097:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:17:18,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:17:18,106:INFO:setup() successfully completed in 2.91s...............
2022-09-13 00:52:15,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:52:15,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:52:15,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:52:15,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:52:16,355:INFO:PyCaret RegressionExperiment
2022-09-13 00:52:16,355:INFO:Logging name: reg-default-name
2022-09-13 00:52:16,355:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-13 00:52:16,355:INFO:version 3.0.0.rc3
2022-09-13 00:52:16,355:INFO:Initializing setup()
2022-09-13 00:52:16,355:INFO:self.USI: 47bd
2022-09-13 00:52:16,355:INFO:self.variable_keys: {'_available_plots', 'master_model_container', 'log_plots_param', 'gpu_param', 'idx', 'transform_target_method_param', 'display_container', 'y', 'exp_name_log', 'html_param', 'y_train', 'y_test', 'X', 'target_param', 'data', 'fold_generator', '_all_models_internal', 'variable_keys', '_gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', '_ml_usecase', 'transform_target_param', '_all_models', 'memory', 'X_test', 'n_jobs_param', 'X_train', 'logging_param', 'seed', 'USI', '_all_metrics', 'fold_groups_param', 'exp_id'}
2022-09-13 00:52:16,355:INFO:Checking environment
2022-09-13 00:52:16,355:INFO:python_version: 3.7.11
2022-09-13 00:52:16,355:INFO:python_build: ('default', 'Jul 27 2021 09:42:29')
2022-09-13 00:52:16,355:INFO:machine: AMD64
2022-09-13 00:52:16,355:INFO:platform: Windows-10-10.0.22000-SP0
2022-09-13 00:52:16,355:INFO:Memory: svmem(total=34156802048, available=10523799552, percent=69.2, used=23633002496, free=10523799552)
2022-09-13 00:52:16,356:INFO:Physical Core: 6
2022-09-13 00:52:16,356:INFO:Logical Core: 12
2022-09-13 00:52:16,356:INFO:Checking libraries
2022-09-13 00:52:16,356:INFO:System:
2022-09-13 00:52:16,356:INFO:    python: 3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]
2022-09-13 00:52:16,356:INFO:executable: c:\Users\Jamel\anaconda3\envs\dev\python.exe
2022-09-13 00:52:16,356:INFO:   machine: Windows-10-10.0.22000-SP0
2022-09-13 00:52:16,356:INFO:PyCaret required dependencies:
2022-09-13 00:52:16,356:INFO:                 pip: 22.1.2
2022-09-13 00:52:16,356:INFO:          setuptools: 60.10.0
2022-09-13 00:52:16,356:INFO:             pycaret: 3.0.0rc3
2022-09-13 00:52:16,356:INFO:             IPython: 7.31.1
2022-09-13 00:52:16,356:INFO:          ipywidgets: 7.6.5
2022-09-13 00:52:16,356:INFO:                tqdm: 4.64.0
2022-09-13 00:52:16,358:INFO:               numpy: 1.21.6
2022-09-13 00:52:16,358:INFO:              pandas: 1.3.5
2022-09-13 00:52:16,358:INFO:              jinja2: 3.0.3
2022-09-13 00:52:16,358:INFO:               scipy: 1.7.3
2022-09-13 00:52:16,358:INFO:              joblib: 1.1.0
2022-09-13 00:52:16,358:INFO:             sklearn: 1.0.2
2022-09-13 00:52:16,358:INFO:                pyod: 1.0.4
2022-09-13 00:52:16,359:INFO:            imblearn: 0.9.0
2022-09-13 00:52:16,359:INFO:   category_encoders: 2.5.0
2022-09-13 00:52:16,359:INFO:            lightgbm: 3.3.2
2022-09-13 00:52:16,359:INFO:               numba: 0.55.1
2022-09-13 00:52:16,359:INFO:            requests: 2.28.1
2022-09-13 00:52:16,359:INFO:          matplotlib: 3.5.1
2022-09-13 00:52:16,359:INFO:          scikitplot: 0.3.7
2022-09-13 00:52:16,359:INFO:         yellowbrick: 1.5
2022-09-13 00:52:16,359:INFO:              plotly: 5.9.0
2022-09-13 00:52:16,359:INFO:             kaleido: 0.2.1
2022-09-13 00:52:16,359:INFO:         statsmodels: 0.13.2
2022-09-13 00:52:16,359:INFO:              sktime: 0.13.2
2022-09-13 00:52:16,359:INFO:               tbats: 1.1.0
2022-09-13 00:52:16,359:INFO:            pmdarima: 1.8.5
2022-09-13 00:52:16,359:INFO:              psutil: 5.9.0
2022-09-13 00:52:16,359:INFO:PyCaret optional dependencies:
2022-09-13 00:52:16,370:INFO:                shap: 0.41.0
2022-09-13 00:52:16,370:INFO:           interpret: 0.2.7
2022-09-13 00:52:16,370:INFO:                umap: 0.5.3
2022-09-13 00:52:16,370:INFO:    pandas_profiling: 3.2.0
2022-09-13 00:52:16,370:INFO:  explainerdashboard: 0.3.8.2
2022-09-13 00:52:16,370:INFO:             autoviz: 0.1.43
2022-09-13 00:52:16,370:INFO:           fairlearn: 0.7.0
2022-09-13 00:52:16,370:INFO:             xgboost: 1.6.1
2022-09-13 00:52:16,370:INFO:            catboost: Not installed
2022-09-13 00:52:16,370:INFO:              kmodes: 0.12.1
2022-09-13 00:52:16,370:INFO:             mlxtend: Not installed
2022-09-13 00:52:16,370:INFO:       statsforecast: Not installed
2022-09-13 00:52:16,370:INFO:        tune_sklearn: Not installed
2022-09-13 00:52:16,371:INFO:                 ray: Not installed
2022-09-13 00:52:16,371:INFO:            hyperopt: Not installed
2022-09-13 00:52:16,371:INFO:              optuna: Not installed
2022-09-13 00:52:16,371:INFO:               skopt: Not installed
2022-09-13 00:52:16,371:INFO:              mlflow: Not installed
2022-09-13 00:52:16,371:INFO:              gradio: Not installed
2022-09-13 00:52:16,371:INFO:             fastapi: Not installed
2022-09-13 00:52:16,371:INFO:             uvicorn: Not installed
2022-09-13 00:52:16,371:INFO:              m2cgen: Not installed
2022-09-13 00:52:16,371:INFO:           evidently: Not installed
2022-09-13 00:52:16,371:INFO:                nltk: 3.7
2022-09-13 00:52:16,371:INFO:            pyLDAvis: Not installed
2022-09-13 00:52:16,371:INFO:              gensim: 4.2.0
2022-09-13 00:52:16,371:INFO:               spacy: 3.3.0
2022-09-13 00:52:16,371:INFO:           wordcloud: 1.8.1
2022-09-13 00:52:16,371:INFO:            textblob: 0.17.1
2022-09-13 00:52:16,371:INFO:               fugue: Not installed
2022-09-13 00:52:16,371:INFO:           streamlit: 1.11.0
2022-09-13 00:52:16,371:INFO:             prophet: Not installed
2022-09-13 00:52:16,371:INFO:None
2022-09-13 00:52:16,372:INFO:Set up data.
2022-09-13 00:52:16,379:INFO:Set up train/test split.
2022-09-13 00:52:16,383:INFO:Set up index.
2022-09-13 00:52:16,384:INFO:Set up folding strategy.
2022-09-13 00:52:16,384:INFO:Assigning column types.
2022-09-13 00:52:16,391:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-13 00:52:16,391:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,396:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,400:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,502:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,503:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:16,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:16,631:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,635:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,639:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,732:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:16,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:16,735:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-13 00:52:16,739:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,744:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,803:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,845:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:16,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:16,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,855:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,906:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:52:16,947:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:16,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:16,949:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-13 00:52:16,958:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,052:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,053:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:17,055:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:17,063:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,159:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:17,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:17,161:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-13 00:52:17,226:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,268:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,268:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:17,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:17,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,372:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,373:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:17,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:17,377:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-13 00:52:17,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,474:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:17,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:17,538:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:52:17,582:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:17,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:17,585:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-13 00:52:17,717:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:17,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:17,830:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:17,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:17,834:INFO:Preparing preprocessing pipeline...
2022-09-13 00:52:17,835:INFO:Set up simple imputation.
2022-09-13 00:52:17,837:INFO:Set up encoding of categorical features.
2022-09-13 00:52:17,838:INFO:Set up variance threshold.
2022-09-13 00:52:18,057:INFO:Finished creating preprocessing pipeline.
2022-09-13 00:52:18,067:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Jamel\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['unix', 'open', 'high', 'low',
                                             'Volume ETH', 'Volume USD'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'date', 'symbol'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Unnamed: 0', 'unix', 'date',
                                             'open', 'high', 'low',
                                             'Volume ETH', 'Volume USD'],
                                    transformer=LeaveOneOutEncoder(cols=['Unnamed: '
                                                                         '0',
                                                                         'date'],
                                                                   handle_missing='return_nan',
                                                                   random_state=5937))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-13 00:52:18,067:INFO:Creating final display dataframe.
2022-09-13 00:52:18,848:INFO:Setup display_container:                  Description             Value
0                 Session id              5937
1                     Target             close
2                Target type        Regression
3                 Data shape          (876, 7)
4           Train data shape          (613, 7)
5            Test data shape          (263, 7)
6           Numeric features                 6
7       Categorical features                 3
8                 Preprocess              True
9            Imputation type            simple
10        Numeric imputation              mean
11    Categorical imputation          constant
12  Maximum one-hot encoding                 5
13           Encoding method              None
14    Low variance threshold                 0
15            Fold Generator             KFold
16               Fold Number                10
17                  CPU Jobs                -1
18                   Use GPU             False
19            Log Experiment             False
20           Experiment Name  reg-default-name
21                       USI              47bd
2022-09-13 00:52:19,022:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:19,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:19,161:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:52:19,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:52:19,172:INFO:setup() successfully completed in 2.82s...............
2022-09-13 00:53:09,818:INFO:Initializing compare_models()
2022-09-13 00:53:09,819:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engines': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-13 00:53:09,819:INFO:Checking exceptions
2022-09-13 00:53:09,827:INFO:Preparing display monitor
2022-09-13 00:53:09,880:INFO:Initializing Linear Regression
2022-09-13 00:53:09,880:INFO:Total runtime is 0.0 minutes
2022-09-13 00:53:09,884:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:09,885:INFO:Initializing create_model()
2022-09-13 00:53:09,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:09,885:INFO:Checking exceptions
2022-09-13 00:53:09,887:INFO:Importing libraries
2022-09-13 00:53:09,887:INFO:Copying training dataset
2022-09-13 00:53:09,890:INFO:Defining folds
2022-09-13 00:53:09,890:INFO:Declaring metric variables
2022-09-13 00:53:09,893:INFO:Importing untrained model
2022-09-13 00:53:09,897:INFO:Linear Regression Imported successfully
2022-09-13 00:53:09,904:INFO:Starting cross validation
2022-09-13 00:53:09,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:21,635:INFO:Calculating mean and std
2022-09-13 00:53:21,643:INFO:Creating metrics dataframe
2022-09-13 00:53:21,660:INFO:Uploading results into container
2022-09-13 00:53:21,661:INFO:Uploading model into container now
2022-09-13 00:53:21,662:INFO:master_model_container: 1
2022-09-13 00:53:21,663:INFO:display_container: 2
2022-09-13 00:53:21,664:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:53:21,664:INFO:create_model() successfully completed......................................
2022-09-13 00:53:22,146:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:22,146:INFO:Creating metrics dataframe
2022-09-13 00:53:22,164:INFO:Initializing Lasso Regression
2022-09-13 00:53:22,164:INFO:Total runtime is 0.20473208030064902 minutes
2022-09-13 00:53:22,170:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:22,170:INFO:Initializing create_model()
2022-09-13 00:53:22,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:22,170:INFO:Checking exceptions
2022-09-13 00:53:22,173:INFO:Importing libraries
2022-09-13 00:53:22,173:INFO:Copying training dataset
2022-09-13 00:53:22,178:INFO:Defining folds
2022-09-13 00:53:22,178:INFO:Declaring metric variables
2022-09-13 00:53:22,185:INFO:Importing untrained model
2022-09-13 00:53:22,190:INFO:Lasso Regression Imported successfully
2022-09-13 00:53:22,198:INFO:Starting cross validation
2022-09-13 00:53:22,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:22,340:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.981e+05, tolerance: 9.855e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:22,361:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+05, tolerance: 9.625e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:22,386:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.026e+05, tolerance: 9.948e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:22,404:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.770e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:22,417:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.085e+05, tolerance: 1.009e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:22,438:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.809e+05, tolerance: 9.715e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:22,463:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.138e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:22,498:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+05, tolerance: 1.003e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:25,018:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e+05, tolerance: 9.884e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:25,061:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.193e+05, tolerance: 9.675e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:25,182:INFO:Calculating mean and std
2022-09-13 00:53:25,183:INFO:Creating metrics dataframe
2022-09-13 00:53:25,190:INFO:Uploading results into container
2022-09-13 00:53:25,191:INFO:Uploading model into container now
2022-09-13 00:53:25,192:INFO:master_model_container: 2
2022-09-13 00:53:25,192:INFO:display_container: 2
2022-09-13 00:53:25,192:INFO:Lasso(random_state=5937)
2022-09-13 00:53:25,192:INFO:create_model() successfully completed......................................
2022-09-13 00:53:25,341:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:25,341:INFO:Creating metrics dataframe
2022-09-13 00:53:25,360:INFO:Initializing Ridge Regression
2022-09-13 00:53:25,360:INFO:Total runtime is 0.2579985499382019 minutes
2022-09-13 00:53:25,365:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:25,365:INFO:Initializing create_model()
2022-09-13 00:53:25,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:25,365:INFO:Checking exceptions
2022-09-13 00:53:25,368:INFO:Importing libraries
2022-09-13 00:53:25,368:INFO:Copying training dataset
2022-09-13 00:53:25,372:INFO:Defining folds
2022-09-13 00:53:25,373:INFO:Declaring metric variables
2022-09-13 00:53:25,377:INFO:Importing untrained model
2022-09-13 00:53:25,382:INFO:Ridge Regression Imported successfully
2022-09-13 00:53:25,392:INFO:Starting cross validation
2022-09-13 00:53:25,393:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:25,486:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.11213e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,496:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.2421e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,510:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.11934e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,522:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.13544e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,569:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.22073e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,584:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.01843e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,597:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.16107e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,610:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.69088e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,620:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.1381e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,633:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.92715e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:53:25,681:INFO:Calculating mean and std
2022-09-13 00:53:25,683:INFO:Creating metrics dataframe
2022-09-13 00:53:25,686:INFO:Uploading results into container
2022-09-13 00:53:25,687:INFO:Uploading model into container now
2022-09-13 00:53:25,688:INFO:master_model_container: 3
2022-09-13 00:53:25,688:INFO:display_container: 2
2022-09-13 00:53:25,689:INFO:Ridge(random_state=5937)
2022-09-13 00:53:25,689:INFO:create_model() successfully completed......................................
2022-09-13 00:53:25,842:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:25,842:INFO:Creating metrics dataframe
2022-09-13 00:53:25,861:INFO:Initializing Elastic Net
2022-09-13 00:53:25,861:INFO:Total runtime is 0.2663397192955017 minutes
2022-09-13 00:53:25,866:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:25,866:INFO:Initializing create_model()
2022-09-13 00:53:25,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:25,867:INFO:Checking exceptions
2022-09-13 00:53:25,869:INFO:Importing libraries
2022-09-13 00:53:25,869:INFO:Copying training dataset
2022-09-13 00:53:25,873:INFO:Defining folds
2022-09-13 00:53:25,873:INFO:Declaring metric variables
2022-09-13 00:53:25,878:INFO:Importing untrained model
2022-09-13 00:53:25,884:INFO:Elastic Net Imported successfully
2022-09-13 00:53:25,895:INFO:Starting cross validation
2022-09-13 00:53:25,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:25,978:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.189e+05, tolerance: 9.675e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:25,997:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+05, tolerance: 9.884e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,038:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.977e+05, tolerance: 9.855e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,045:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.895e+05, tolerance: 9.625e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,049:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+05, tolerance: 9.948e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,087:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+05, tolerance: 1.009e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,095:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.767e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,113:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.805e+05, tolerance: 9.715e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,122:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.134e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,135:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e+05, tolerance: 1.003e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:53:26,177:INFO:Calculating mean and std
2022-09-13 00:53:26,179:INFO:Creating metrics dataframe
2022-09-13 00:53:26,183:INFO:Uploading results into container
2022-09-13 00:53:26,183:INFO:Uploading model into container now
2022-09-13 00:53:26,184:INFO:master_model_container: 4
2022-09-13 00:53:26,184:INFO:display_container: 2
2022-09-13 00:53:26,184:INFO:ElasticNet(random_state=5937)
2022-09-13 00:53:26,184:INFO:create_model() successfully completed......................................
2022-09-13 00:53:26,332:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:26,333:INFO:Creating metrics dataframe
2022-09-13 00:53:26,351:INFO:Initializing Least Angle Regression
2022-09-13 00:53:26,351:INFO:Total runtime is 0.2745178023974101 minutes
2022-09-13 00:53:26,357:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:26,357:INFO:Initializing create_model()
2022-09-13 00:53:26,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:26,357:INFO:Checking exceptions
2022-09-13 00:53:26,359:INFO:Importing libraries
2022-09-13 00:53:26,360:INFO:Copying training dataset
2022-09-13 00:53:26,365:INFO:Defining folds
2022-09-13 00:53:26,365:INFO:Declaring metric variables
2022-09-13 00:53:26,370:INFO:Importing untrained model
2022-09-13 00:53:26,378:INFO:Least Angle Regression Imported successfully
2022-09-13 00:53:26,387:INFO:Starting cross validation
2022-09-13 00:53:26,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:26,474:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,491:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,510:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,536:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,548:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,552:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,582:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,602:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,614:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,632:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:26,668:INFO:Calculating mean and std
2022-09-13 00:53:26,669:INFO:Creating metrics dataframe
2022-09-13 00:53:26,674:INFO:Uploading results into container
2022-09-13 00:53:26,675:INFO:Uploading model into container now
2022-09-13 00:53:26,676:INFO:master_model_container: 5
2022-09-13 00:53:26,676:INFO:display_container: 2
2022-09-13 00:53:26,676:INFO:Lars(random_state=5937)
2022-09-13 00:53:26,676:INFO:create_model() successfully completed......................................
2022-09-13 00:53:26,819:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:26,820:INFO:Creating metrics dataframe
2022-09-13 00:53:26,841:INFO:Initializing Lasso Least Angle Regression
2022-09-13 00:53:26,842:INFO:Total runtime is 0.28269588549931846 minutes
2022-09-13 00:53:26,847:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:26,847:INFO:Initializing create_model()
2022-09-13 00:53:26,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:26,847:INFO:Checking exceptions
2022-09-13 00:53:26,849:INFO:Importing libraries
2022-09-13 00:53:26,849:INFO:Copying training dataset
2022-09-13 00:53:26,854:INFO:Defining folds
2022-09-13 00:53:26,854:INFO:Declaring metric variables
2022-09-13 00:53:26,860:INFO:Importing untrained model
2022-09-13 00:53:26,864:INFO:Lasso Least Angle Regression Imported successfully
2022-09-13 00:53:26,871:INFO:Starting cross validation
2022-09-13 00:53:26,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:26,955:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:26,975:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:26,981:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:27,006:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:27,025:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:27,038:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:27,058:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:27,068:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:27,094:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:27,101:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:53:27,153:INFO:Calculating mean and std
2022-09-13 00:53:27,155:INFO:Creating metrics dataframe
2022-09-13 00:53:27,160:INFO:Uploading results into container
2022-09-13 00:53:27,160:INFO:Uploading model into container now
2022-09-13 00:53:27,161:INFO:master_model_container: 6
2022-09-13 00:53:27,161:INFO:display_container: 2
2022-09-13 00:53:27,161:INFO:LassoLars(random_state=5937)
2022-09-13 00:53:27,162:INFO:create_model() successfully completed......................................
2022-09-13 00:53:27,302:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:27,303:INFO:Creating metrics dataframe
2022-09-13 00:53:27,321:INFO:Initializing Orthogonal Matching Pursuit
2022-09-13 00:53:27,322:INFO:Total runtime is 0.2906911889712016 minutes
2022-09-13 00:53:27,327:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:27,328:INFO:Initializing create_model()
2022-09-13 00:53:27,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:27,328:INFO:Checking exceptions
2022-09-13 00:53:27,330:INFO:Importing libraries
2022-09-13 00:53:27,330:INFO:Copying training dataset
2022-09-13 00:53:27,334:INFO:Defining folds
2022-09-13 00:53:27,334:INFO:Declaring metric variables
2022-09-13 00:53:27,339:INFO:Importing untrained model
2022-09-13 00:53:27,345:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-13 00:53:27,353:INFO:Starting cross validation
2022-09-13 00:53:27,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:27,449:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,470:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,471:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,511:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,518:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,551:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,563:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,570:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,596:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,610:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:53:27,654:INFO:Calculating mean and std
2022-09-13 00:53:27,655:INFO:Creating metrics dataframe
2022-09-13 00:53:27,661:INFO:Uploading results into container
2022-09-13 00:53:27,662:INFO:Uploading model into container now
2022-09-13 00:53:27,662:INFO:master_model_container: 7
2022-09-13 00:53:27,662:INFO:display_container: 2
2022-09-13 00:53:27,663:INFO:OrthogonalMatchingPursuit()
2022-09-13 00:53:27,663:INFO:create_model() successfully completed......................................
2022-09-13 00:53:27,808:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:27,808:INFO:Creating metrics dataframe
2022-09-13 00:53:27,824:INFO:Initializing Bayesian Ridge
2022-09-13 00:53:27,825:INFO:Total runtime is 0.2990854064623515 minutes
2022-09-13 00:53:27,830:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:27,830:INFO:Initializing create_model()
2022-09-13 00:53:27,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:27,830:INFO:Checking exceptions
2022-09-13 00:53:27,832:INFO:Importing libraries
2022-09-13 00:53:27,832:INFO:Copying training dataset
2022-09-13 00:53:27,835:INFO:Defining folds
2022-09-13 00:53:27,836:INFO:Declaring metric variables
2022-09-13 00:53:27,840:INFO:Importing untrained model
2022-09-13 00:53:27,846:INFO:Bayesian Ridge Imported successfully
2022-09-13 00:53:27,853:INFO:Starting cross validation
2022-09-13 00:53:27,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:28,147:INFO:Calculating mean and std
2022-09-13 00:53:28,149:INFO:Creating metrics dataframe
2022-09-13 00:53:28,153:INFO:Uploading results into container
2022-09-13 00:53:28,153:INFO:Uploading model into container now
2022-09-13 00:53:28,154:INFO:master_model_container: 8
2022-09-13 00:53:28,154:INFO:display_container: 2
2022-09-13 00:53:28,154:INFO:BayesianRidge()
2022-09-13 00:53:28,154:INFO:create_model() successfully completed......................................
2022-09-13 00:53:28,297:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:28,297:INFO:Creating metrics dataframe
2022-09-13 00:53:28,320:INFO:Initializing Passive Aggressive Regressor
2022-09-13 00:53:28,320:INFO:Total runtime is 0.30733005205790204 minutes
2022-09-13 00:53:28,326:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:28,326:INFO:Initializing create_model()
2022-09-13 00:53:28,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:28,326:INFO:Checking exceptions
2022-09-13 00:53:28,328:INFO:Importing libraries
2022-09-13 00:53:28,329:INFO:Copying training dataset
2022-09-13 00:53:28,332:INFO:Defining folds
2022-09-13 00:53:28,332:INFO:Declaring metric variables
2022-09-13 00:53:28,337:INFO:Importing untrained model
2022-09-13 00:53:28,342:INFO:Passive Aggressive Regressor Imported successfully
2022-09-13 00:53:28,351:INFO:Starting cross validation
2022-09-13 00:53:28,353:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:28,667:INFO:Calculating mean and std
2022-09-13 00:53:28,669:INFO:Creating metrics dataframe
2022-09-13 00:53:28,673:INFO:Uploading results into container
2022-09-13 00:53:28,673:INFO:Uploading model into container now
2022-09-13 00:53:28,674:INFO:master_model_container: 9
2022-09-13 00:53:28,674:INFO:display_container: 2
2022-09-13 00:53:28,675:INFO:PassiveAggressiveRegressor(random_state=5937)
2022-09-13 00:53:28,675:INFO:create_model() successfully completed......................................
2022-09-13 00:53:28,804:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:28,804:INFO:Creating metrics dataframe
2022-09-13 00:53:28,822:INFO:Initializing Huber Regressor
2022-09-13 00:53:28,822:INFO:Total runtime is 0.31569098631540937 minutes
2022-09-13 00:53:28,827:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:28,827:INFO:Initializing create_model()
2022-09-13 00:53:28,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:28,828:INFO:Checking exceptions
2022-09-13 00:53:28,829:INFO:Importing libraries
2022-09-13 00:53:28,829:INFO:Copying training dataset
2022-09-13 00:53:28,833:INFO:Defining folds
2022-09-13 00:53:28,833:INFO:Declaring metric variables
2022-09-13 00:53:28,836:INFO:Importing untrained model
2022-09-13 00:53:28,840:INFO:Huber Regressor Imported successfully
2022-09-13 00:53:28,849:INFO:Starting cross validation
2022-09-13 00:53:28,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:29,177:INFO:Calculating mean and std
2022-09-13 00:53:29,180:INFO:Creating metrics dataframe
2022-09-13 00:53:29,185:INFO:Uploading results into container
2022-09-13 00:53:29,186:INFO:Uploading model into container now
2022-09-13 00:53:29,186:INFO:master_model_container: 10
2022-09-13 00:53:29,186:INFO:display_container: 2
2022-09-13 00:53:29,187:INFO:HuberRegressor()
2022-09-13 00:53:29,187:INFO:create_model() successfully completed......................................
2022-09-13 00:53:29,346:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:29,347:INFO:Creating metrics dataframe
2022-09-13 00:53:29,363:INFO:Initializing K Neighbors Regressor
2022-09-13 00:53:29,363:INFO:Total runtime is 0.32472233772277836 minutes
2022-09-13 00:53:29,367:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:29,367:INFO:Initializing create_model()
2022-09-13 00:53:29,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:29,367:INFO:Checking exceptions
2022-09-13 00:53:29,369:INFO:Importing libraries
2022-09-13 00:53:29,369:INFO:Copying training dataset
2022-09-13 00:53:29,372:INFO:Defining folds
2022-09-13 00:53:29,372:INFO:Declaring metric variables
2022-09-13 00:53:29,377:INFO:Importing untrained model
2022-09-13 00:53:29,381:INFO:K Neighbors Regressor Imported successfully
2022-09-13 00:53:29,388:INFO:Starting cross validation
2022-09-13 00:53:29,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:29,816:INFO:Calculating mean and std
2022-09-13 00:53:29,817:INFO:Creating metrics dataframe
2022-09-13 00:53:29,821:INFO:Uploading results into container
2022-09-13 00:53:29,821:INFO:Uploading model into container now
2022-09-13 00:53:29,821:INFO:master_model_container: 11
2022-09-13 00:53:29,821:INFO:display_container: 2
2022-09-13 00:53:29,822:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-13 00:53:29,822:INFO:create_model() successfully completed......................................
2022-09-13 00:53:29,966:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:29,967:INFO:Creating metrics dataframe
2022-09-13 00:53:29,990:INFO:Initializing Decision Tree Regressor
2022-09-13 00:53:29,991:INFO:Total runtime is 0.33518009583155317 minutes
2022-09-13 00:53:29,995:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:29,996:INFO:Initializing create_model()
2022-09-13 00:53:29,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:29,996:INFO:Checking exceptions
2022-09-13 00:53:29,998:INFO:Importing libraries
2022-09-13 00:53:29,998:INFO:Copying training dataset
2022-09-13 00:53:30,001:INFO:Defining folds
2022-09-13 00:53:30,002:INFO:Declaring metric variables
2022-09-13 00:53:30,006:INFO:Importing untrained model
2022-09-13 00:53:30,011:INFO:Decision Tree Regressor Imported successfully
2022-09-13 00:53:30,018:INFO:Starting cross validation
2022-09-13 00:53:30,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:30,337:INFO:Calculating mean and std
2022-09-13 00:53:30,339:INFO:Creating metrics dataframe
2022-09-13 00:53:30,344:INFO:Uploading results into container
2022-09-13 00:53:30,345:INFO:Uploading model into container now
2022-09-13 00:53:30,346:INFO:master_model_container: 12
2022-09-13 00:53:30,346:INFO:display_container: 2
2022-09-13 00:53:30,347:INFO:DecisionTreeRegressor(random_state=5937)
2022-09-13 00:53:30,347:INFO:create_model() successfully completed......................................
2022-09-13 00:53:30,491:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:30,491:INFO:Creating metrics dataframe
2022-09-13 00:53:30,509:INFO:Initializing Random Forest Regressor
2022-09-13 00:53:30,509:INFO:Total runtime is 0.34382040103276573 minutes
2022-09-13 00:53:30,513:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:30,514:INFO:Initializing create_model()
2022-09-13 00:53:30,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:30,514:INFO:Checking exceptions
2022-09-13 00:53:30,516:INFO:Importing libraries
2022-09-13 00:53:30,516:INFO:Copying training dataset
2022-09-13 00:53:30,519:INFO:Defining folds
2022-09-13 00:53:30,519:INFO:Declaring metric variables
2022-09-13 00:53:30,523:INFO:Importing untrained model
2022-09-13 00:53:30,528:INFO:Random Forest Regressor Imported successfully
2022-09-13 00:53:30,535:INFO:Starting cross validation
2022-09-13 00:53:30,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:31,512:INFO:Calculating mean and std
2022-09-13 00:53:31,514:INFO:Creating metrics dataframe
2022-09-13 00:53:31,519:INFO:Uploading results into container
2022-09-13 00:53:31,520:INFO:Uploading model into container now
2022-09-13 00:53:31,520:INFO:master_model_container: 13
2022-09-13 00:53:31,520:INFO:display_container: 2
2022-09-13 00:53:31,521:INFO:RandomForestRegressor(n_jobs=-1, random_state=5937)
2022-09-13 00:53:31,521:INFO:create_model() successfully completed......................................
2022-09-13 00:53:31,673:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:31,673:INFO:Creating metrics dataframe
2022-09-13 00:53:31,693:INFO:Initializing Extra Trees Regressor
2022-09-13 00:53:31,694:INFO:Total runtime is 0.3635573943456014 minutes
2022-09-13 00:53:31,698:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:31,699:INFO:Initializing create_model()
2022-09-13 00:53:31,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:31,699:INFO:Checking exceptions
2022-09-13 00:53:31,701:INFO:Importing libraries
2022-09-13 00:53:31,701:INFO:Copying training dataset
2022-09-13 00:53:31,705:INFO:Defining folds
2022-09-13 00:53:31,705:INFO:Declaring metric variables
2022-09-13 00:53:31,713:INFO:Importing untrained model
2022-09-13 00:53:31,720:INFO:Extra Trees Regressor Imported successfully
2022-09-13 00:53:31,728:INFO:Starting cross validation
2022-09-13 00:53:31,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:32,573:INFO:Calculating mean and std
2022-09-13 00:53:32,575:INFO:Creating metrics dataframe
2022-09-13 00:53:32,580:INFO:Uploading results into container
2022-09-13 00:53:32,581:INFO:Uploading model into container now
2022-09-13 00:53:32,581:INFO:master_model_container: 14
2022-09-13 00:53:32,582:INFO:display_container: 2
2022-09-13 00:53:32,582:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5937)
2022-09-13 00:53:32,582:INFO:create_model() successfully completed......................................
2022-09-13 00:53:32,755:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:32,756:INFO:Creating metrics dataframe
2022-09-13 00:53:32,790:INFO:Initializing AdaBoost Regressor
2022-09-13 00:53:32,790:INFO:Total runtime is 0.3818242867787679 minutes
2022-09-13 00:53:32,800:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:32,801:INFO:Initializing create_model()
2022-09-13 00:53:32,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:32,802:INFO:Checking exceptions
2022-09-13 00:53:32,804:INFO:Importing libraries
2022-09-13 00:53:32,805:INFO:Copying training dataset
2022-09-13 00:53:32,810:INFO:Defining folds
2022-09-13 00:53:32,811:INFO:Declaring metric variables
2022-09-13 00:53:32,819:INFO:Importing untrained model
2022-09-13 00:53:32,824:INFO:AdaBoost Regressor Imported successfully
2022-09-13 00:53:32,835:INFO:Starting cross validation
2022-09-13 00:53:32,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:33,378:INFO:Calculating mean and std
2022-09-13 00:53:33,380:INFO:Creating metrics dataframe
2022-09-13 00:53:33,384:INFO:Uploading results into container
2022-09-13 00:53:33,385:INFO:Uploading model into container now
2022-09-13 00:53:33,386:INFO:master_model_container: 15
2022-09-13 00:53:33,386:INFO:display_container: 2
2022-09-13 00:53:33,387:INFO:AdaBoostRegressor(random_state=5937)
2022-09-13 00:53:33,387:INFO:create_model() successfully completed......................................
2022-09-13 00:53:33,547:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:33,547:INFO:Creating metrics dataframe
2022-09-13 00:53:33,572:INFO:Initializing Gradient Boosting Regressor
2022-09-13 00:53:33,572:INFO:Total runtime is 0.39486865599950155 minutes
2022-09-13 00:53:33,577:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:33,578:INFO:Initializing create_model()
2022-09-13 00:53:33,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:33,579:INFO:Checking exceptions
2022-09-13 00:53:33,581:INFO:Importing libraries
2022-09-13 00:53:33,582:INFO:Copying training dataset
2022-09-13 00:53:33,587:INFO:Defining folds
2022-09-13 00:53:33,587:INFO:Declaring metric variables
2022-09-13 00:53:33,593:INFO:Importing untrained model
2022-09-13 00:53:33,602:INFO:Gradient Boosting Regressor Imported successfully
2022-09-13 00:53:33,617:INFO:Starting cross validation
2022-09-13 00:53:33,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:34,187:INFO:Calculating mean and std
2022-09-13 00:53:34,194:INFO:Creating metrics dataframe
2022-09-13 00:53:34,206:INFO:Uploading results into container
2022-09-13 00:53:34,207:INFO:Uploading model into container now
2022-09-13 00:53:34,208:INFO:master_model_container: 16
2022-09-13 00:53:34,208:INFO:display_container: 2
2022-09-13 00:53:34,209:INFO:GradientBoostingRegressor(random_state=5937)
2022-09-13 00:53:34,209:INFO:create_model() successfully completed......................................
2022-09-13 00:53:34,388:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:34,388:INFO:Creating metrics dataframe
2022-09-13 00:53:34,408:INFO:Initializing Extreme Gradient Boosting
2022-09-13 00:53:34,408:INFO:Total runtime is 0.40880026419957477 minutes
2022-09-13 00:53:34,412:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:34,412:INFO:Initializing create_model()
2022-09-13 00:53:34,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:34,413:INFO:Checking exceptions
2022-09-13 00:53:34,416:INFO:Importing libraries
2022-09-13 00:53:34,416:INFO:Copying training dataset
2022-09-13 00:53:34,420:INFO:Defining folds
2022-09-13 00:53:34,421:INFO:Declaring metric variables
2022-09-13 00:53:34,425:INFO:Importing untrained model
2022-09-13 00:53:34,431:INFO:Extreme Gradient Boosting Imported successfully
2022-09-13 00:53:34,441:INFO:Starting cross validation
2022-09-13 00:53:34,443:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:35,299:INFO:Calculating mean and std
2022-09-13 00:53:35,302:INFO:Creating metrics dataframe
2022-09-13 00:53:35,307:INFO:Uploading results into container
2022-09-13 00:53:35,307:INFO:Uploading model into container now
2022-09-13 00:53:35,308:INFO:master_model_container: 17
2022-09-13 00:53:35,308:INFO:display_container: 2
2022-09-13 00:53:35,309:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=5937,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-13 00:53:35,309:INFO:create_model() successfully completed......................................
2022-09-13 00:53:35,541:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:35,541:INFO:Creating metrics dataframe
2022-09-13 00:53:35,570:INFO:Initializing Light Gradient Boosting Machine
2022-09-13 00:53:35,571:INFO:Total runtime is 0.42818177541097 minutes
2022-09-13 00:53:35,576:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:35,577:INFO:Initializing create_model()
2022-09-13 00:53:35,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:35,577:INFO:Checking exceptions
2022-09-13 00:53:35,579:INFO:Importing libraries
2022-09-13 00:53:35,579:INFO:Copying training dataset
2022-09-13 00:53:35,589:INFO:Defining folds
2022-09-13 00:53:35,589:INFO:Declaring metric variables
2022-09-13 00:53:35,594:INFO:Importing untrained model
2022-09-13 00:53:35,609:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-13 00:53:35,625:INFO:Starting cross validation
2022-09-13 00:53:35,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:37,585:INFO:Calculating mean and std
2022-09-13 00:53:37,587:INFO:Creating metrics dataframe
2022-09-13 00:53:37,592:INFO:Uploading results into container
2022-09-13 00:53:37,592:INFO:Uploading model into container now
2022-09-13 00:53:37,593:INFO:master_model_container: 18
2022-09-13 00:53:37,593:INFO:display_container: 2
2022-09-13 00:53:37,594:INFO:LGBMRegressor(random_state=5937)
2022-09-13 00:53:37,594:INFO:create_model() successfully completed......................................
2022-09-13 00:53:37,737:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:37,737:INFO:Creating metrics dataframe
2022-09-13 00:53:37,760:INFO:Initializing Dummy Regressor
2022-09-13 00:53:37,760:INFO:Total runtime is 0.46465701262156167 minutes
2022-09-13 00:53:37,764:INFO:SubProcess create_model() called ==================================
2022-09-13 00:53:37,764:INFO:Initializing create_model()
2022-09-13 00:53:37,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE42CB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:37,764:INFO:Checking exceptions
2022-09-13 00:53:37,766:INFO:Importing libraries
2022-09-13 00:53:37,766:INFO:Copying training dataset
2022-09-13 00:53:37,771:INFO:Defining folds
2022-09-13 00:53:37,771:INFO:Declaring metric variables
2022-09-13 00:53:37,775:INFO:Importing untrained model
2022-09-13 00:53:37,781:INFO:Dummy Regressor Imported successfully
2022-09-13 00:53:37,789:INFO:Starting cross validation
2022-09-13 00:53:37,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:53:38,111:INFO:Calculating mean and std
2022-09-13 00:53:38,113:INFO:Creating metrics dataframe
2022-09-13 00:53:38,118:INFO:Uploading results into container
2022-09-13 00:53:38,118:INFO:Uploading model into container now
2022-09-13 00:53:38,119:INFO:master_model_container: 19
2022-09-13 00:53:38,119:INFO:display_container: 2
2022-09-13 00:53:38,120:INFO:DummyRegressor()
2022-09-13 00:53:38,120:INFO:create_model() successfully completed......................................
2022-09-13 00:53:38,258:INFO:SubProcess create_model() end ==================================
2022-09-13 00:53:38,258:INFO:Creating metrics dataframe
2022-09-13 00:53:38,291:INFO:Initializing create_model()
2022-09-13 00:53:38,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:53:38,291:INFO:Checking exceptions
2022-09-13 00:53:38,294:INFO:Importing libraries
2022-09-13 00:53:38,294:INFO:Copying training dataset
2022-09-13 00:53:38,296:INFO:Defining folds
2022-09-13 00:53:38,296:INFO:Declaring metric variables
2022-09-13 00:53:38,296:INFO:Importing untrained model
2022-09-13 00:53:38,297:INFO:Declaring custom model
2022-09-13 00:53:38,297:INFO:Linear Regression Imported successfully
2022-09-13 00:53:38,298:INFO:Cross validation set to False
2022-09-13 00:53:38,298:INFO:Fitting Model
2022-09-13 00:53:38,529:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:53:38,529:INFO:create_model() successfully completed......................................
2022-09-13 00:53:38,763:INFO:master_model_container: 19
2022-09-13 00:53:38,764:INFO:display_container: 2
2022-09-13 00:53:38,764:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:53:38,764:INFO:compare_models() successfully completed......................................
2022-09-13 00:56:41,643:INFO:Initializing compare_models()
2022-09-13 00:56:41,643:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engines': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-13 00:56:41,644:INFO:Checking exceptions
2022-09-13 00:56:41,646:INFO:Preparing display monitor
2022-09-13 00:56:41,702:INFO:Initializing Linear Regression
2022-09-13 00:56:41,703:INFO:Total runtime is 1.6025702158610026e-05 minutes
2022-09-13 00:56:41,709:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:41,709:INFO:Initializing create_model()
2022-09-13 00:56:41,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:41,709:INFO:Checking exceptions
2022-09-13 00:56:41,711:INFO:Importing libraries
2022-09-13 00:56:41,711:INFO:Copying training dataset
2022-09-13 00:56:41,713:INFO:Defining folds
2022-09-13 00:56:41,714:INFO:Declaring metric variables
2022-09-13 00:56:41,720:INFO:Importing untrained model
2022-09-13 00:56:41,728:INFO:Linear Regression Imported successfully
2022-09-13 00:56:41,741:INFO:Starting cross validation
2022-09-13 00:56:41,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:42,093:INFO:Calculating mean and std
2022-09-13 00:56:42,093:INFO:Creating metrics dataframe
2022-09-13 00:56:42,097:INFO:Uploading results into container
2022-09-13 00:56:42,098:INFO:Uploading model into container now
2022-09-13 00:56:42,098:INFO:master_model_container: 20
2022-09-13 00:56:42,098:INFO:display_container: 3
2022-09-13 00:56:42,098:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:56:42,098:INFO:create_model() successfully completed......................................
2022-09-13 00:56:42,273:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:42,273:INFO:Creating metrics dataframe
2022-09-13 00:56:42,291:INFO:Initializing Lasso Regression
2022-09-13 00:56:42,292:INFO:Total runtime is 0.00981057087580363 minutes
2022-09-13 00:56:42,296:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:42,297:INFO:Initializing create_model()
2022-09-13 00:56:42,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:42,297:INFO:Checking exceptions
2022-09-13 00:56:42,299:INFO:Importing libraries
2022-09-13 00:56:42,300:INFO:Copying training dataset
2022-09-13 00:56:42,305:INFO:Defining folds
2022-09-13 00:56:42,305:INFO:Declaring metric variables
2022-09-13 00:56:42,310:INFO:Importing untrained model
2022-09-13 00:56:42,316:INFO:Lasso Regression Imported successfully
2022-09-13 00:56:42,327:INFO:Starting cross validation
2022-09-13 00:56:42,328:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:42,423:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.193e+05, tolerance: 9.675e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,442:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e+05, tolerance: 9.884e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,452:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.981e+05, tolerance: 9.855e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,472:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+05, tolerance: 9.625e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,485:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.026e+05, tolerance: 9.948e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,490:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.085e+05, tolerance: 1.009e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,522:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.770e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,536:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.809e+05, tolerance: 9.715e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,554:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.138e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,561:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+05, tolerance: 1.003e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:42,611:INFO:Calculating mean and std
2022-09-13 00:56:42,611:INFO:Creating metrics dataframe
2022-09-13 00:56:42,615:INFO:Uploading results into container
2022-09-13 00:56:42,615:INFO:Uploading model into container now
2022-09-13 00:56:42,616:INFO:master_model_container: 21
2022-09-13 00:56:42,616:INFO:display_container: 3
2022-09-13 00:56:42,616:INFO:Lasso(random_state=5937)
2022-09-13 00:56:42,616:INFO:create_model() successfully completed......................................
2022-09-13 00:56:42,775:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:42,775:INFO:Creating metrics dataframe
2022-09-13 00:56:42,793:INFO:Initializing Ridge Regression
2022-09-13 00:56:42,793:INFO:Total runtime is 0.018169597784678145 minutes
2022-09-13 00:56:42,797:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:42,798:INFO:Initializing create_model()
2022-09-13 00:56:42,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:42,798:INFO:Checking exceptions
2022-09-13 00:56:42,800:INFO:Importing libraries
2022-09-13 00:56:42,801:INFO:Copying training dataset
2022-09-13 00:56:42,805:INFO:Defining folds
2022-09-13 00:56:42,806:INFO:Declaring metric variables
2022-09-13 00:56:42,810:INFO:Importing untrained model
2022-09-13 00:56:42,817:INFO:Ridge Regression Imported successfully
2022-09-13 00:56:42,826:INFO:Starting cross validation
2022-09-13 00:56:42,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:42,916:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.11213e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:42,928:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.2421e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:42,964:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.11934e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:42,978:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.13544e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:42,979:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.22073e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:43,006:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.01843e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:43,021:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.16107e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:43,043:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.69088e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:43,050:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.1381e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:43,062:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.92715e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:43,098:INFO:Calculating mean and std
2022-09-13 00:56:43,101:INFO:Creating metrics dataframe
2022-09-13 00:56:43,107:INFO:Uploading results into container
2022-09-13 00:56:43,107:INFO:Uploading model into container now
2022-09-13 00:56:43,107:INFO:master_model_container: 22
2022-09-13 00:56:43,107:INFO:display_container: 3
2022-09-13 00:56:43,108:INFO:Ridge(random_state=5937)
2022-09-13 00:56:43,108:INFO:create_model() successfully completed......................................
2022-09-13 00:56:43,249:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:43,249:INFO:Creating metrics dataframe
2022-09-13 00:56:43,270:INFO:Initializing Elastic Net
2022-09-13 00:56:43,270:INFO:Total runtime is 0.026131025950113934 minutes
2022-09-13 00:56:43,275:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:43,276:INFO:Initializing create_model()
2022-09-13 00:56:43,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:43,276:INFO:Checking exceptions
2022-09-13 00:56:43,278:INFO:Importing libraries
2022-09-13 00:56:43,278:INFO:Copying training dataset
2022-09-13 00:56:43,282:INFO:Defining folds
2022-09-13 00:56:43,282:INFO:Declaring metric variables
2022-09-13 00:56:43,288:INFO:Importing untrained model
2022-09-13 00:56:43,293:INFO:Elastic Net Imported successfully
2022-09-13 00:56:43,305:INFO:Starting cross validation
2022-09-13 00:56:43,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:43,408:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.189e+05, tolerance: 9.675e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,422:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+05, tolerance: 9.884e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,438:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.977e+05, tolerance: 9.855e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,468:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.895e+05, tolerance: 9.625e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,469:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+05, tolerance: 9.948e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,493:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+05, tolerance: 1.009e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,510:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.767e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,516:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.805e+05, tolerance: 9.715e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,537:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.134e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,547:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e+05, tolerance: 1.003e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:43,588:INFO:Calculating mean and std
2022-09-13 00:56:43,588:INFO:Creating metrics dataframe
2022-09-13 00:56:43,592:INFO:Uploading results into container
2022-09-13 00:56:43,593:INFO:Uploading model into container now
2022-09-13 00:56:43,593:INFO:master_model_container: 23
2022-09-13 00:56:43,593:INFO:display_container: 3
2022-09-13 00:56:43,593:INFO:ElasticNet(random_state=5937)
2022-09-13 00:56:43,593:INFO:create_model() successfully completed......................................
2022-09-13 00:56:43,730:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:43,730:INFO:Creating metrics dataframe
2022-09-13 00:56:43,749:INFO:Initializing Least Angle Regression
2022-09-13 00:56:43,750:INFO:Total runtime is 0.034127116203308105 minutes
2022-09-13 00:56:43,755:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:43,756:INFO:Initializing create_model()
2022-09-13 00:56:43,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:43,756:INFO:Checking exceptions
2022-09-13 00:56:43,758:INFO:Importing libraries
2022-09-13 00:56:43,758:INFO:Copying training dataset
2022-09-13 00:56:43,762:INFO:Defining folds
2022-09-13 00:56:43,763:INFO:Declaring metric variables
2022-09-13 00:56:43,768:INFO:Importing untrained model
2022-09-13 00:56:43,772:INFO:Least Angle Regression Imported successfully
2022-09-13 00:56:43,783:INFO:Starting cross validation
2022-09-13 00:56:43,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:43,870:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:43,890:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:43,895:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:43,925:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:43,947:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:43,965:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:43,980:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,001:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,008:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,045:INFO:Calculating mean and std
2022-09-13 00:56:44,047:INFO:Creating metrics dataframe
2022-09-13 00:56:44,050:INFO:Uploading results into container
2022-09-13 00:56:44,051:INFO:Uploading model into container now
2022-09-13 00:56:44,051:INFO:master_model_container: 24
2022-09-13 00:56:44,051:INFO:display_container: 3
2022-09-13 00:56:44,052:INFO:Lars(random_state=5937)
2022-09-13 00:56:44,052:INFO:create_model() successfully completed......................................
2022-09-13 00:56:44,198:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:44,198:INFO:Creating metrics dataframe
2022-09-13 00:56:44,217:INFO:Initializing Lasso Least Angle Regression
2022-09-13 00:56:44,217:INFO:Total runtime is 0.041905482610066734 minutes
2022-09-13 00:56:44,224:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:44,224:INFO:Initializing create_model()
2022-09-13 00:56:44,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:44,225:INFO:Checking exceptions
2022-09-13 00:56:44,227:INFO:Importing libraries
2022-09-13 00:56:44,227:INFO:Copying training dataset
2022-09-13 00:56:44,231:INFO:Defining folds
2022-09-13 00:56:44,231:INFO:Declaring metric variables
2022-09-13 00:56:44,236:INFO:Importing untrained model
2022-09-13 00:56:44,241:INFO:Lasso Least Angle Regression Imported successfully
2022-09-13 00:56:44,250:INFO:Starting cross validation
2022-09-13 00:56:44,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:44,358:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,361:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,375:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,376:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,399:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,411:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,446:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,458:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,464:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,482:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:44,530:INFO:Calculating mean and std
2022-09-13 00:56:44,531:INFO:Creating metrics dataframe
2022-09-13 00:56:44,535:INFO:Uploading results into container
2022-09-13 00:56:44,536:INFO:Uploading model into container now
2022-09-13 00:56:44,537:INFO:master_model_container: 25
2022-09-13 00:56:44,537:INFO:display_container: 3
2022-09-13 00:56:44,538:INFO:LassoLars(random_state=5937)
2022-09-13 00:56:44,538:INFO:create_model() successfully completed......................................
2022-09-13 00:56:44,681:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:44,682:INFO:Creating metrics dataframe
2022-09-13 00:56:44,700:INFO:Initializing Orthogonal Matching Pursuit
2022-09-13 00:56:44,701:INFO:Total runtime is 0.049967817465464276 minutes
2022-09-13 00:56:44,706:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:44,706:INFO:Initializing create_model()
2022-09-13 00:56:44,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:44,706:INFO:Checking exceptions
2022-09-13 00:56:44,708:INFO:Importing libraries
2022-09-13 00:56:44,708:INFO:Copying training dataset
2022-09-13 00:56:44,712:INFO:Defining folds
2022-09-13 00:56:44,712:INFO:Declaring metric variables
2022-09-13 00:56:44,717:INFO:Importing untrained model
2022-09-13 00:56:44,722:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-13 00:56:44,731:INFO:Starting cross validation
2022-09-13 00:56:44,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:44,817:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,832:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,843:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,865:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,866:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,898:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,909:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,922:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,932:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,940:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:44,984:INFO:Calculating mean and std
2022-09-13 00:56:44,987:INFO:Creating metrics dataframe
2022-09-13 00:56:44,991:INFO:Uploading results into container
2022-09-13 00:56:44,991:INFO:Uploading model into container now
2022-09-13 00:56:44,992:INFO:master_model_container: 26
2022-09-13 00:56:44,992:INFO:display_container: 3
2022-09-13 00:56:44,992:INFO:OrthogonalMatchingPursuit()
2022-09-13 00:56:44,992:INFO:create_model() successfully completed......................................
2022-09-13 00:56:45,128:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:45,129:INFO:Creating metrics dataframe
2022-09-13 00:56:45,151:INFO:Initializing Bayesian Ridge
2022-09-13 00:56:45,151:INFO:Total runtime is 0.05748049815495809 minutes
2022-09-13 00:56:45,157:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:45,157:INFO:Initializing create_model()
2022-09-13 00:56:45,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:45,158:INFO:Checking exceptions
2022-09-13 00:56:45,160:INFO:Importing libraries
2022-09-13 00:56:45,160:INFO:Copying training dataset
2022-09-13 00:56:45,164:INFO:Defining folds
2022-09-13 00:56:45,164:INFO:Declaring metric variables
2022-09-13 00:56:45,169:INFO:Importing untrained model
2022-09-13 00:56:45,175:INFO:Bayesian Ridge Imported successfully
2022-09-13 00:56:45,183:INFO:Starting cross validation
2022-09-13 00:56:45,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:45,451:INFO:Calculating mean and std
2022-09-13 00:56:45,452:INFO:Creating metrics dataframe
2022-09-13 00:56:45,457:INFO:Uploading results into container
2022-09-13 00:56:45,457:INFO:Uploading model into container now
2022-09-13 00:56:45,458:INFO:master_model_container: 27
2022-09-13 00:56:45,459:INFO:display_container: 3
2022-09-13 00:56:45,459:INFO:BayesianRidge()
2022-09-13 00:56:45,459:INFO:create_model() successfully completed......................................
2022-09-13 00:56:45,616:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:45,616:INFO:Creating metrics dataframe
2022-09-13 00:56:45,641:INFO:Initializing Passive Aggressive Regressor
2022-09-13 00:56:45,641:INFO:Total runtime is 0.06564429203669231 minutes
2022-09-13 00:56:45,646:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:45,646:INFO:Initializing create_model()
2022-09-13 00:56:45,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:45,647:INFO:Checking exceptions
2022-09-13 00:56:45,648:INFO:Importing libraries
2022-09-13 00:56:45,649:INFO:Copying training dataset
2022-09-13 00:56:45,652:INFO:Defining folds
2022-09-13 00:56:45,652:INFO:Declaring metric variables
2022-09-13 00:56:45,657:INFO:Importing untrained model
2022-09-13 00:56:45,663:INFO:Passive Aggressive Regressor Imported successfully
2022-09-13 00:56:45,674:INFO:Starting cross validation
2022-09-13 00:56:45,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:45,977:INFO:Calculating mean and std
2022-09-13 00:56:45,979:INFO:Creating metrics dataframe
2022-09-13 00:56:45,982:INFO:Uploading results into container
2022-09-13 00:56:45,982:INFO:Uploading model into container now
2022-09-13 00:56:45,982:INFO:master_model_container: 28
2022-09-13 00:56:45,982:INFO:display_container: 3
2022-09-13 00:56:45,983:INFO:PassiveAggressiveRegressor(random_state=5937)
2022-09-13 00:56:45,983:INFO:create_model() successfully completed......................................
2022-09-13 00:56:46,131:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:46,131:INFO:Creating metrics dataframe
2022-09-13 00:56:46,152:INFO:Initializing Huber Regressor
2022-09-13 00:56:46,153:INFO:Total runtime is 0.07417224248250326 minutes
2022-09-13 00:56:46,160:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:46,160:INFO:Initializing create_model()
2022-09-13 00:56:46,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:46,160:INFO:Checking exceptions
2022-09-13 00:56:46,163:INFO:Importing libraries
2022-09-13 00:56:46,163:INFO:Copying training dataset
2022-09-13 00:56:46,167:INFO:Defining folds
2022-09-13 00:56:46,168:INFO:Declaring metric variables
2022-09-13 00:56:46,173:INFO:Importing untrained model
2022-09-13 00:56:46,178:INFO:Huber Regressor Imported successfully
2022-09-13 00:56:46,187:INFO:Starting cross validation
2022-09-13 00:56:46,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:46,499:INFO:Calculating mean and std
2022-09-13 00:56:46,502:INFO:Creating metrics dataframe
2022-09-13 00:56:46,506:INFO:Uploading results into container
2022-09-13 00:56:46,507:INFO:Uploading model into container now
2022-09-13 00:56:46,508:INFO:master_model_container: 29
2022-09-13 00:56:46,509:INFO:display_container: 3
2022-09-13 00:56:46,509:INFO:HuberRegressor()
2022-09-13 00:56:46,509:INFO:create_model() successfully completed......................................
2022-09-13 00:56:46,668:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:46,668:INFO:Creating metrics dataframe
2022-09-13 00:56:46,693:INFO:Initializing K Neighbors Regressor
2022-09-13 00:56:46,694:INFO:Total runtime is 0.08319735129674276 minutes
2022-09-13 00:56:46,698:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:46,699:INFO:Initializing create_model()
2022-09-13 00:56:46,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:46,699:INFO:Checking exceptions
2022-09-13 00:56:46,701:INFO:Importing libraries
2022-09-13 00:56:46,701:INFO:Copying training dataset
2022-09-13 00:56:46,705:INFO:Defining folds
2022-09-13 00:56:46,705:INFO:Declaring metric variables
2022-09-13 00:56:46,710:INFO:Importing untrained model
2022-09-13 00:56:46,715:INFO:K Neighbors Regressor Imported successfully
2022-09-13 00:56:46,724:INFO:Starting cross validation
2022-09-13 00:56:46,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:47,132:INFO:Calculating mean and std
2022-09-13 00:56:47,134:INFO:Creating metrics dataframe
2022-09-13 00:56:47,140:INFO:Uploading results into container
2022-09-13 00:56:47,141:INFO:Uploading model into container now
2022-09-13 00:56:47,141:INFO:master_model_container: 30
2022-09-13 00:56:47,141:INFO:display_container: 3
2022-09-13 00:56:47,142:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-13 00:56:47,142:INFO:create_model() successfully completed......................................
2022-09-13 00:56:47,284:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:47,285:INFO:Creating metrics dataframe
2022-09-13 00:56:47,307:INFO:Initializing Decision Tree Regressor
2022-09-13 00:56:47,307:INFO:Total runtime is 0.09340045849482219 minutes
2022-09-13 00:56:47,312:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:47,312:INFO:Initializing create_model()
2022-09-13 00:56:47,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:47,312:INFO:Checking exceptions
2022-09-13 00:56:47,314:INFO:Importing libraries
2022-09-13 00:56:47,314:INFO:Copying training dataset
2022-09-13 00:56:47,318:INFO:Defining folds
2022-09-13 00:56:47,318:INFO:Declaring metric variables
2022-09-13 00:56:47,323:INFO:Importing untrained model
2022-09-13 00:56:47,328:INFO:Decision Tree Regressor Imported successfully
2022-09-13 00:56:47,336:INFO:Starting cross validation
2022-09-13 00:56:47,338:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:47,603:INFO:Calculating mean and std
2022-09-13 00:56:47,606:INFO:Creating metrics dataframe
2022-09-13 00:56:47,610:INFO:Uploading results into container
2022-09-13 00:56:47,610:INFO:Uploading model into container now
2022-09-13 00:56:47,610:INFO:master_model_container: 31
2022-09-13 00:56:47,610:INFO:display_container: 3
2022-09-13 00:56:47,611:INFO:DecisionTreeRegressor(random_state=5937)
2022-09-13 00:56:47,611:INFO:create_model() successfully completed......................................
2022-09-13 00:56:47,752:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:47,752:INFO:Creating metrics dataframe
2022-09-13 00:56:47,775:INFO:Initializing Random Forest Regressor
2022-09-13 00:56:47,775:INFO:Total runtime is 0.10121288696924846 minutes
2022-09-13 00:56:47,780:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:47,780:INFO:Initializing create_model()
2022-09-13 00:56:47,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:47,780:INFO:Checking exceptions
2022-09-13 00:56:47,782:INFO:Importing libraries
2022-09-13 00:56:47,782:INFO:Copying training dataset
2022-09-13 00:56:47,786:INFO:Defining folds
2022-09-13 00:56:47,786:INFO:Declaring metric variables
2022-09-13 00:56:47,791:INFO:Importing untrained model
2022-09-13 00:56:47,796:INFO:Random Forest Regressor Imported successfully
2022-09-13 00:56:47,805:INFO:Starting cross validation
2022-09-13 00:56:47,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:48,689:INFO:Calculating mean and std
2022-09-13 00:56:48,691:INFO:Creating metrics dataframe
2022-09-13 00:56:48,696:INFO:Uploading results into container
2022-09-13 00:56:48,697:INFO:Uploading model into container now
2022-09-13 00:56:48,698:INFO:master_model_container: 32
2022-09-13 00:56:48,698:INFO:display_container: 3
2022-09-13 00:56:48,698:INFO:RandomForestRegressor(n_jobs=-1, random_state=5937)
2022-09-13 00:56:48,698:INFO:create_model() successfully completed......................................
2022-09-13 00:56:48,837:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:48,837:INFO:Creating metrics dataframe
2022-09-13 00:56:48,858:INFO:Initializing Extra Trees Regressor
2022-09-13 00:56:48,859:INFO:Total runtime is 0.1192812204360962 minutes
2022-09-13 00:56:48,863:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:48,864:INFO:Initializing create_model()
2022-09-13 00:56:48,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:48,864:INFO:Checking exceptions
2022-09-13 00:56:48,866:INFO:Importing libraries
2022-09-13 00:56:48,867:INFO:Copying training dataset
2022-09-13 00:56:48,874:INFO:Defining folds
2022-09-13 00:56:48,874:INFO:Declaring metric variables
2022-09-13 00:56:48,881:INFO:Importing untrained model
2022-09-13 00:56:48,885:INFO:Extra Trees Regressor Imported successfully
2022-09-13 00:56:48,894:INFO:Starting cross validation
2022-09-13 00:56:48,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:49,600:INFO:Calculating mean and std
2022-09-13 00:56:49,602:INFO:Creating metrics dataframe
2022-09-13 00:56:49,606:INFO:Uploading results into container
2022-09-13 00:56:49,607:INFO:Uploading model into container now
2022-09-13 00:56:49,608:INFO:master_model_container: 33
2022-09-13 00:56:49,608:INFO:display_container: 3
2022-09-13 00:56:49,608:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5937)
2022-09-13 00:56:49,609:INFO:create_model() successfully completed......................................
2022-09-13 00:56:49,760:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:49,761:INFO:Creating metrics dataframe
2022-09-13 00:56:49,785:INFO:Initializing AdaBoost Regressor
2022-09-13 00:56:49,786:INFO:Total runtime is 0.13472382227579752 minutes
2022-09-13 00:56:49,790:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:49,791:INFO:Initializing create_model()
2022-09-13 00:56:49,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:49,792:INFO:Checking exceptions
2022-09-13 00:56:49,794:INFO:Importing libraries
2022-09-13 00:56:49,795:INFO:Copying training dataset
2022-09-13 00:56:49,800:INFO:Defining folds
2022-09-13 00:56:49,800:INFO:Declaring metric variables
2022-09-13 00:56:49,804:INFO:Importing untrained model
2022-09-13 00:56:49,811:INFO:AdaBoost Regressor Imported successfully
2022-09-13 00:56:49,819:INFO:Starting cross validation
2022-09-13 00:56:49,821:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:50,224:INFO:Calculating mean and std
2022-09-13 00:56:50,226:INFO:Creating metrics dataframe
2022-09-13 00:56:50,230:INFO:Uploading results into container
2022-09-13 00:56:50,230:INFO:Uploading model into container now
2022-09-13 00:56:50,231:INFO:master_model_container: 34
2022-09-13 00:56:50,231:INFO:display_container: 3
2022-09-13 00:56:50,231:INFO:AdaBoostRegressor(random_state=5937)
2022-09-13 00:56:50,231:INFO:create_model() successfully completed......................................
2022-09-13 00:56:50,383:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:50,383:INFO:Creating metrics dataframe
2022-09-13 00:56:50,408:INFO:Initializing Gradient Boosting Regressor
2022-09-13 00:56:50,408:INFO:Total runtime is 0.1450910965601603 minutes
2022-09-13 00:56:50,413:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:50,414:INFO:Initializing create_model()
2022-09-13 00:56:50,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:50,414:INFO:Checking exceptions
2022-09-13 00:56:50,416:INFO:Importing libraries
2022-09-13 00:56:50,416:INFO:Copying training dataset
2022-09-13 00:56:50,420:INFO:Defining folds
2022-09-13 00:56:50,420:INFO:Declaring metric variables
2022-09-13 00:56:50,424:INFO:Importing untrained model
2022-09-13 00:56:50,430:INFO:Gradient Boosting Regressor Imported successfully
2022-09-13 00:56:50,438:INFO:Starting cross validation
2022-09-13 00:56:50,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:50,850:INFO:Calculating mean and std
2022-09-13 00:56:50,852:INFO:Creating metrics dataframe
2022-09-13 00:56:50,855:INFO:Uploading results into container
2022-09-13 00:56:50,855:INFO:Uploading model into container now
2022-09-13 00:56:50,856:INFO:master_model_container: 35
2022-09-13 00:56:50,856:INFO:display_container: 3
2022-09-13 00:56:50,856:INFO:GradientBoostingRegressor(random_state=5937)
2022-09-13 00:56:50,856:INFO:create_model() successfully completed......................................
2022-09-13 00:56:50,995:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:50,995:INFO:Creating metrics dataframe
2022-09-13 00:56:51,017:INFO:Initializing Extreme Gradient Boosting
2022-09-13 00:56:51,018:INFO:Total runtime is 0.15526420672734578 minutes
2022-09-13 00:56:51,023:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:51,023:INFO:Initializing create_model()
2022-09-13 00:56:51,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:51,023:INFO:Checking exceptions
2022-09-13 00:56:51,026:INFO:Importing libraries
2022-09-13 00:56:51,026:INFO:Copying training dataset
2022-09-13 00:56:51,030:INFO:Defining folds
2022-09-13 00:56:51,030:INFO:Declaring metric variables
2022-09-13 00:56:51,035:INFO:Importing untrained model
2022-09-13 00:56:51,040:INFO:Extreme Gradient Boosting Imported successfully
2022-09-13 00:56:51,049:INFO:Starting cross validation
2022-09-13 00:56:51,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:51,524:INFO:Calculating mean and std
2022-09-13 00:56:51,526:INFO:Creating metrics dataframe
2022-09-13 00:56:51,530:INFO:Uploading results into container
2022-09-13 00:56:51,531:INFO:Uploading model into container now
2022-09-13 00:56:51,531:INFO:master_model_container: 36
2022-09-13 00:56:51,531:INFO:display_container: 3
2022-09-13 00:56:51,532:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=5937,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-13 00:56:51,533:INFO:create_model() successfully completed......................................
2022-09-13 00:56:51,672:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:51,672:INFO:Creating metrics dataframe
2022-09-13 00:56:51,694:INFO:Initializing Light Gradient Boosting Machine
2022-09-13 00:56:51,694:INFO:Total runtime is 0.16651800473531086 minutes
2022-09-13 00:56:51,699:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:51,700:INFO:Initializing create_model()
2022-09-13 00:56:51,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:51,700:INFO:Checking exceptions
2022-09-13 00:56:51,702:INFO:Importing libraries
2022-09-13 00:56:51,702:INFO:Copying training dataset
2022-09-13 00:56:51,705:INFO:Defining folds
2022-09-13 00:56:51,705:INFO:Declaring metric variables
2022-09-13 00:56:51,708:INFO:Importing untrained model
2022-09-13 00:56:51,713:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-13 00:56:51,721:INFO:Starting cross validation
2022-09-13 00:56:51,723:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:52,614:INFO:Calculating mean and std
2022-09-13 00:56:52,616:INFO:Creating metrics dataframe
2022-09-13 00:56:52,619:INFO:Uploading results into container
2022-09-13 00:56:52,619:INFO:Uploading model into container now
2022-09-13 00:56:52,620:INFO:master_model_container: 37
2022-09-13 00:56:52,620:INFO:display_container: 3
2022-09-13 00:56:52,620:INFO:LGBMRegressor(random_state=5937)
2022-09-13 00:56:52,620:INFO:create_model() successfully completed......................................
2022-09-13 00:56:52,764:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:52,765:INFO:Creating metrics dataframe
2022-09-13 00:56:52,787:INFO:Initializing Dummy Regressor
2022-09-13 00:56:52,787:INFO:Total runtime is 0.18473570346832274 minutes
2022-09-13 00:56:52,792:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:52,792:INFO:Initializing create_model()
2022-09-13 00:56:52,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECCE3C1B88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:52,793:INFO:Checking exceptions
2022-09-13 00:56:52,795:INFO:Importing libraries
2022-09-13 00:56:52,796:INFO:Copying training dataset
2022-09-13 00:56:52,800:INFO:Defining folds
2022-09-13 00:56:52,800:INFO:Declaring metric variables
2022-09-13 00:56:52,804:INFO:Importing untrained model
2022-09-13 00:56:52,809:INFO:Dummy Regressor Imported successfully
2022-09-13 00:56:52,817:INFO:Starting cross validation
2022-09-13 00:56:52,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:53,094:INFO:Calculating mean and std
2022-09-13 00:56:53,096:INFO:Creating metrics dataframe
2022-09-13 00:56:53,099:INFO:Uploading results into container
2022-09-13 00:56:53,100:INFO:Uploading model into container now
2022-09-13 00:56:53,100:INFO:master_model_container: 38
2022-09-13 00:56:53,100:INFO:display_container: 3
2022-09-13 00:56:53,100:INFO:DummyRegressor()
2022-09-13 00:56:53,100:INFO:create_model() successfully completed......................................
2022-09-13 00:56:53,258:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:53,259:INFO:Creating metrics dataframe
2022-09-13 00:56:53,300:INFO:Initializing create_model()
2022-09-13 00:56:53,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:53,301:INFO:Checking exceptions
2022-09-13 00:56:53,305:INFO:Importing libraries
2022-09-13 00:56:53,305:INFO:Copying training dataset
2022-09-13 00:56:53,307:INFO:Defining folds
2022-09-13 00:56:53,307:INFO:Declaring metric variables
2022-09-13 00:56:53,308:INFO:Importing untrained model
2022-09-13 00:56:53,308:INFO:Declaring custom model
2022-09-13 00:56:53,308:INFO:Linear Regression Imported successfully
2022-09-13 00:56:53,309:INFO:Cross validation set to False
2022-09-13 00:56:53,309:INFO:Fitting Model
2022-09-13 00:56:53,361:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:56:53,362:INFO:create_model() successfully completed......................................
2022-09-13 00:56:53,580:INFO:master_model_container: 38
2022-09-13 00:56:53,580:INFO:display_container: 3
2022-09-13 00:56:53,580:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:56:53,580:INFO:compare_models() successfully completed......................................
2022-09-13 00:56:53,581:INFO:Initializing compare_models()
2022-09-13 00:56:53,581:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engines': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-13 00:56:53,581:INFO:Checking exceptions
2022-09-13 00:56:53,583:INFO:Preparing display monitor
2022-09-13 00:56:53,625:INFO:Initializing Linear Regression
2022-09-13 00:56:53,625:INFO:Total runtime is 0.0 minutes
2022-09-13 00:56:53,631:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:53,631:INFO:Initializing create_model()
2022-09-13 00:56:53,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:53,631:INFO:Checking exceptions
2022-09-13 00:56:53,633:INFO:Importing libraries
2022-09-13 00:56:53,633:INFO:Copying training dataset
2022-09-13 00:56:53,635:INFO:Defining folds
2022-09-13 00:56:53,635:INFO:Declaring metric variables
2022-09-13 00:56:53,639:INFO:Importing untrained model
2022-09-13 00:56:53,644:INFO:Linear Regression Imported successfully
2022-09-13 00:56:53,654:INFO:Starting cross validation
2022-09-13 00:56:53,656:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:53,946:INFO:Calculating mean and std
2022-09-13 00:56:53,946:INFO:Creating metrics dataframe
2022-09-13 00:56:53,950:INFO:Uploading results into container
2022-09-13 00:56:53,951:INFO:Uploading model into container now
2022-09-13 00:56:53,951:INFO:master_model_container: 39
2022-09-13 00:56:53,951:INFO:display_container: 4
2022-09-13 00:56:53,951:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:56:53,951:INFO:create_model() successfully completed......................................
2022-09-13 00:56:54,096:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:54,096:INFO:Creating metrics dataframe
2022-09-13 00:56:54,112:INFO:Initializing Lasso Regression
2022-09-13 00:56:54,113:INFO:Total runtime is 0.008137373129526775 minutes
2022-09-13 00:56:54,118:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:54,119:INFO:Initializing create_model()
2022-09-13 00:56:54,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:54,119:INFO:Checking exceptions
2022-09-13 00:56:54,121:INFO:Importing libraries
2022-09-13 00:56:54,121:INFO:Copying training dataset
2022-09-13 00:56:54,124:INFO:Defining folds
2022-09-13 00:56:54,124:INFO:Declaring metric variables
2022-09-13 00:56:54,129:INFO:Importing untrained model
2022-09-13 00:56:54,134:INFO:Lasso Regression Imported successfully
2022-09-13 00:56:54,143:INFO:Starting cross validation
2022-09-13 00:56:54,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:54,238:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.193e+05, tolerance: 9.675e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,248:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e+05, tolerance: 9.884e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,266:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.981e+05, tolerance: 9.855e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,288:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+05, tolerance: 9.625e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,293:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.026e+05, tolerance: 9.948e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,321:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.085e+05, tolerance: 1.009e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,341:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.809e+05, tolerance: 9.715e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,342:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.770e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,364:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.138e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,372:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+05, tolerance: 1.003e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:54,408:INFO:Calculating mean and std
2022-09-13 00:56:54,409:INFO:Creating metrics dataframe
2022-09-13 00:56:54,413:INFO:Uploading results into container
2022-09-13 00:56:54,413:INFO:Uploading model into container now
2022-09-13 00:56:54,414:INFO:master_model_container: 40
2022-09-13 00:56:54,414:INFO:display_container: 4
2022-09-13 00:56:54,414:INFO:Lasso(random_state=5937)
2022-09-13 00:56:54,414:INFO:create_model() successfully completed......................................
2022-09-13 00:56:54,556:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:54,557:INFO:Creating metrics dataframe
2022-09-13 00:56:54,575:INFO:Initializing Ridge Regression
2022-09-13 00:56:54,575:INFO:Total runtime is 0.015833461284637453 minutes
2022-09-13 00:56:54,580:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:54,581:INFO:Initializing create_model()
2022-09-13 00:56:54,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:54,581:INFO:Checking exceptions
2022-09-13 00:56:54,583:INFO:Importing libraries
2022-09-13 00:56:54,583:INFO:Copying training dataset
2022-09-13 00:56:54,586:INFO:Defining folds
2022-09-13 00:56:54,586:INFO:Declaring metric variables
2022-09-13 00:56:54,589:INFO:Importing untrained model
2022-09-13 00:56:54,594:INFO:Ridge Regression Imported successfully
2022-09-13 00:56:54,607:INFO:Starting cross validation
2022-09-13 00:56:54,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:54,694:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.11213e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,697:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.2421e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,737:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.13544e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,740:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.11934e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,766:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.22073e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,798:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.01843e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,810:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.16107e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,823:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.69088e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,839:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.1381e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,854:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.92715e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:56:54,895:INFO:Calculating mean and std
2022-09-13 00:56:54,895:INFO:Creating metrics dataframe
2022-09-13 00:56:54,901:INFO:Uploading results into container
2022-09-13 00:56:54,902:INFO:Uploading model into container now
2022-09-13 00:56:54,902:INFO:master_model_container: 41
2022-09-13 00:56:54,903:INFO:display_container: 4
2022-09-13 00:56:54,903:INFO:Ridge(random_state=5937)
2022-09-13 00:56:54,903:INFO:create_model() successfully completed......................................
2022-09-13 00:56:55,040:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:55,040:INFO:Creating metrics dataframe
2022-09-13 00:56:55,059:INFO:Initializing Elastic Net
2022-09-13 00:56:55,059:INFO:Total runtime is 0.023895223935445152 minutes
2022-09-13 00:56:55,063:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:55,064:INFO:Initializing create_model()
2022-09-13 00:56:55,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:55,064:INFO:Checking exceptions
2022-09-13 00:56:55,066:INFO:Importing libraries
2022-09-13 00:56:55,066:INFO:Copying training dataset
2022-09-13 00:56:55,070:INFO:Defining folds
2022-09-13 00:56:55,070:INFO:Declaring metric variables
2022-09-13 00:56:55,075:INFO:Importing untrained model
2022-09-13 00:56:55,079:INFO:Elastic Net Imported successfully
2022-09-13 00:56:55,087:INFO:Starting cross validation
2022-09-13 00:56:55,088:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:55,182:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+05, tolerance: 9.884e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,194:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.189e+05, tolerance: 9.675e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,209:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.977e+05, tolerance: 9.855e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,221:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.895e+05, tolerance: 9.625e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,227:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+05, tolerance: 9.948e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,253:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+05, tolerance: 1.009e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,266:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.767e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,278:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.805e+05, tolerance: 9.715e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,296:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e+05, tolerance: 1.003e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,300:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.134e+05, tolerance: 9.802e+04
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:56:55,347:INFO:Calculating mean and std
2022-09-13 00:56:55,349:INFO:Creating metrics dataframe
2022-09-13 00:56:55,353:INFO:Uploading results into container
2022-09-13 00:56:55,354:INFO:Uploading model into container now
2022-09-13 00:56:55,354:INFO:master_model_container: 42
2022-09-13 00:56:55,354:INFO:display_container: 4
2022-09-13 00:56:55,355:INFO:ElasticNet(random_state=5937)
2022-09-13 00:56:55,355:INFO:create_model() successfully completed......................................
2022-09-13 00:56:55,495:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:55,495:INFO:Creating metrics dataframe
2022-09-13 00:56:55,514:INFO:Initializing Least Angle Regression
2022-09-13 00:56:55,515:INFO:Total runtime is 0.03149156173070272 minutes
2022-09-13 00:56:55,519:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:55,520:INFO:Initializing create_model()
2022-09-13 00:56:55,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:55,520:INFO:Checking exceptions
2022-09-13 00:56:55,522:INFO:Importing libraries
2022-09-13 00:56:55,522:INFO:Copying training dataset
2022-09-13 00:56:55,526:INFO:Defining folds
2022-09-13 00:56:55,526:INFO:Declaring metric variables
2022-09-13 00:56:55,531:INFO:Importing untrained model
2022-09-13 00:56:55,537:INFO:Least Angle Regression Imported successfully
2022-09-13 00:56:55,545:INFO:Starting cross validation
2022-09-13 00:56:55,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:55,628:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,643:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,651:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,685:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,696:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,720:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,736:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,749:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,759:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,767:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:55,810:INFO:Calculating mean and std
2022-09-13 00:56:55,811:INFO:Creating metrics dataframe
2022-09-13 00:56:55,816:INFO:Uploading results into container
2022-09-13 00:56:55,817:INFO:Uploading model into container now
2022-09-13 00:56:55,817:INFO:master_model_container: 43
2022-09-13 00:56:55,817:INFO:display_container: 4
2022-09-13 00:56:55,818:INFO:Lars(random_state=5937)
2022-09-13 00:56:55,818:INFO:create_model() successfully completed......................................
2022-09-13 00:56:55,948:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:55,949:INFO:Creating metrics dataframe
2022-09-13 00:56:55,968:INFO:Initializing Lasso Least Angle Regression
2022-09-13 00:56:55,969:INFO:Total runtime is 0.03907132148742676 minutes
2022-09-13 00:56:55,974:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:55,975:INFO:Initializing create_model()
2022-09-13 00:56:55,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:55,975:INFO:Checking exceptions
2022-09-13 00:56:55,976:INFO:Importing libraries
2022-09-13 00:56:55,977:INFO:Copying training dataset
2022-09-13 00:56:55,981:INFO:Defining folds
2022-09-13 00:56:55,981:INFO:Declaring metric variables
2022-09-13 00:56:55,986:INFO:Importing untrained model
2022-09-13 00:56:55,990:INFO:Lasso Least Angle Regression Imported successfully
2022-09-13 00:56:55,999:INFO:Starting cross validation
2022-09-13 00:56:56,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:56,090:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,098:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,103:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,140:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,150:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,154:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,179:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,190:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,209:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,220:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:56:56,264:INFO:Calculating mean and std
2022-09-13 00:56:56,267:INFO:Creating metrics dataframe
2022-09-13 00:56:56,270:INFO:Uploading results into container
2022-09-13 00:56:56,271:INFO:Uploading model into container now
2022-09-13 00:56:56,271:INFO:master_model_container: 44
2022-09-13 00:56:56,271:INFO:display_container: 4
2022-09-13 00:56:56,271:INFO:LassoLars(random_state=5937)
2022-09-13 00:56:56,271:INFO:create_model() successfully completed......................................
2022-09-13 00:56:56,413:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:56,413:INFO:Creating metrics dataframe
2022-09-13 00:56:56,435:INFO:Initializing Orthogonal Matching Pursuit
2022-09-13 00:56:56,435:INFO:Total runtime is 0.046833868821461996 minutes
2022-09-13 00:56:56,441:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:56,442:INFO:Initializing create_model()
2022-09-13 00:56:56,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:56,442:INFO:Checking exceptions
2022-09-13 00:56:56,445:INFO:Importing libraries
2022-09-13 00:56:56,445:INFO:Copying training dataset
2022-09-13 00:56:56,451:INFO:Defining folds
2022-09-13 00:56:56,451:INFO:Declaring metric variables
2022-09-13 00:56:56,457:INFO:Importing untrained model
2022-09-13 00:56:56,462:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-13 00:56:56,471:INFO:Starting cross validation
2022-09-13 00:56:56,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:56,579:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,582:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,592:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,622:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,646:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,669:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,684:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,706:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,715:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,736:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:56:56,782:INFO:Calculating mean and std
2022-09-13 00:56:56,785:INFO:Creating metrics dataframe
2022-09-13 00:56:56,791:INFO:Uploading results into container
2022-09-13 00:56:56,792:INFO:Uploading model into container now
2022-09-13 00:56:56,792:INFO:master_model_container: 45
2022-09-13 00:56:56,792:INFO:display_container: 4
2022-09-13 00:56:56,793:INFO:OrthogonalMatchingPursuit()
2022-09-13 00:56:56,793:INFO:create_model() successfully completed......................................
2022-09-13 00:56:56,934:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:56,934:INFO:Creating metrics dataframe
2022-09-13 00:56:56,952:INFO:Initializing Bayesian Ridge
2022-09-13 00:56:56,952:INFO:Total runtime is 0.0554563840230306 minutes
2022-09-13 00:56:56,957:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:56,957:INFO:Initializing create_model()
2022-09-13 00:56:56,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:56,957:INFO:Checking exceptions
2022-09-13 00:56:56,959:INFO:Importing libraries
2022-09-13 00:56:56,959:INFO:Copying training dataset
2022-09-13 00:56:56,964:INFO:Defining folds
2022-09-13 00:56:56,964:INFO:Declaring metric variables
2022-09-13 00:56:56,970:INFO:Importing untrained model
2022-09-13 00:56:56,977:INFO:Bayesian Ridge Imported successfully
2022-09-13 00:56:56,986:INFO:Starting cross validation
2022-09-13 00:56:56,988:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:57,263:INFO:Calculating mean and std
2022-09-13 00:56:57,266:INFO:Creating metrics dataframe
2022-09-13 00:56:57,272:INFO:Uploading results into container
2022-09-13 00:56:57,273:INFO:Uploading model into container now
2022-09-13 00:56:57,273:INFO:master_model_container: 46
2022-09-13 00:56:57,273:INFO:display_container: 4
2022-09-13 00:56:57,273:INFO:BayesianRidge()
2022-09-13 00:56:57,273:INFO:create_model() successfully completed......................................
2022-09-13 00:56:57,459:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:57,460:INFO:Creating metrics dataframe
2022-09-13 00:56:57,488:INFO:Initializing Passive Aggressive Regressor
2022-09-13 00:56:57,488:INFO:Total runtime is 0.06438405911127726 minutes
2022-09-13 00:56:57,496:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:57,496:INFO:Initializing create_model()
2022-09-13 00:56:57,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:57,496:INFO:Checking exceptions
2022-09-13 00:56:57,500:INFO:Importing libraries
2022-09-13 00:56:57,500:INFO:Copying training dataset
2022-09-13 00:56:57,507:INFO:Defining folds
2022-09-13 00:56:57,507:INFO:Declaring metric variables
2022-09-13 00:56:57,512:INFO:Importing untrained model
2022-09-13 00:56:57,521:INFO:Passive Aggressive Regressor Imported successfully
2022-09-13 00:56:57,535:INFO:Starting cross validation
2022-09-13 00:56:57,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:57,968:INFO:Calculating mean and std
2022-09-13 00:56:57,970:INFO:Creating metrics dataframe
2022-09-13 00:56:57,975:INFO:Uploading results into container
2022-09-13 00:56:57,976:INFO:Uploading model into container now
2022-09-13 00:56:57,976:INFO:master_model_container: 47
2022-09-13 00:56:57,976:INFO:display_container: 4
2022-09-13 00:56:57,977:INFO:PassiveAggressiveRegressor(random_state=5937)
2022-09-13 00:56:57,978:INFO:create_model() successfully completed......................................
2022-09-13 00:56:58,176:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:58,176:INFO:Creating metrics dataframe
2022-09-13 00:56:58,201:INFO:Initializing Huber Regressor
2022-09-13 00:56:58,201:INFO:Total runtime is 0.07626853783925375 minutes
2022-09-13 00:56:58,209:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:58,209:INFO:Initializing create_model()
2022-09-13 00:56:58,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:58,210:INFO:Checking exceptions
2022-09-13 00:56:58,213:INFO:Importing libraries
2022-09-13 00:56:58,213:INFO:Copying training dataset
2022-09-13 00:56:58,221:INFO:Defining folds
2022-09-13 00:56:58,221:INFO:Declaring metric variables
2022-09-13 00:56:58,228:INFO:Importing untrained model
2022-09-13 00:56:58,234:INFO:Huber Regressor Imported successfully
2022-09-13 00:56:58,248:INFO:Starting cross validation
2022-09-13 00:56:58,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:58,661:INFO:Calculating mean and std
2022-09-13 00:56:58,663:INFO:Creating metrics dataframe
2022-09-13 00:56:58,668:INFO:Uploading results into container
2022-09-13 00:56:58,669:INFO:Uploading model into container now
2022-09-13 00:56:58,669:INFO:master_model_container: 48
2022-09-13 00:56:58,669:INFO:display_container: 4
2022-09-13 00:56:58,670:INFO:HuberRegressor()
2022-09-13 00:56:58,670:INFO:create_model() successfully completed......................................
2022-09-13 00:56:58,904:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:58,904:INFO:Creating metrics dataframe
2022-09-13 00:56:58,935:INFO:Initializing K Neighbors Regressor
2022-09-13 00:56:58,935:INFO:Total runtime is 0.08849908113479615 minutes
2022-09-13 00:56:58,939:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:58,940:INFO:Initializing create_model()
2022-09-13 00:56:58,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:58,940:INFO:Checking exceptions
2022-09-13 00:56:58,942:INFO:Importing libraries
2022-09-13 00:56:58,942:INFO:Copying training dataset
2022-09-13 00:56:58,945:INFO:Defining folds
2022-09-13 00:56:58,945:INFO:Declaring metric variables
2022-09-13 00:56:58,948:INFO:Importing untrained model
2022-09-13 00:56:58,956:INFO:K Neighbors Regressor Imported successfully
2022-09-13 00:56:58,964:INFO:Starting cross validation
2022-09-13 00:56:58,966:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:59,420:INFO:Calculating mean and std
2022-09-13 00:56:59,422:INFO:Creating metrics dataframe
2022-09-13 00:56:59,426:INFO:Uploading results into container
2022-09-13 00:56:59,427:INFO:Uploading model into container now
2022-09-13 00:56:59,427:INFO:master_model_container: 49
2022-09-13 00:56:59,427:INFO:display_container: 4
2022-09-13 00:56:59,427:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-13 00:56:59,427:INFO:create_model() successfully completed......................................
2022-09-13 00:56:59,577:INFO:SubProcess create_model() end ==================================
2022-09-13 00:56:59,577:INFO:Creating metrics dataframe
2022-09-13 00:56:59,601:INFO:Initializing Decision Tree Regressor
2022-09-13 00:56:59,601:INFO:Total runtime is 0.0996037244796753 minutes
2022-09-13 00:56:59,606:INFO:SubProcess create_model() called ==================================
2022-09-13 00:56:59,607:INFO:Initializing create_model()
2022-09-13 00:56:59,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:56:59,607:INFO:Checking exceptions
2022-09-13 00:56:59,608:INFO:Importing libraries
2022-09-13 00:56:59,608:INFO:Copying training dataset
2022-09-13 00:56:59,612:INFO:Defining folds
2022-09-13 00:56:59,612:INFO:Declaring metric variables
2022-09-13 00:56:59,616:INFO:Importing untrained model
2022-09-13 00:56:59,621:INFO:Decision Tree Regressor Imported successfully
2022-09-13 00:56:59,633:INFO:Starting cross validation
2022-09-13 00:56:59,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:56:59,973:INFO:Calculating mean and std
2022-09-13 00:56:59,975:INFO:Creating metrics dataframe
2022-09-13 00:56:59,980:INFO:Uploading results into container
2022-09-13 00:56:59,981:INFO:Uploading model into container now
2022-09-13 00:56:59,981:INFO:master_model_container: 50
2022-09-13 00:56:59,981:INFO:display_container: 4
2022-09-13 00:56:59,982:INFO:DecisionTreeRegressor(random_state=5937)
2022-09-13 00:56:59,982:INFO:create_model() successfully completed......................................
2022-09-13 00:57:00,133:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:00,134:INFO:Creating metrics dataframe
2022-09-13 00:57:00,155:INFO:Initializing Random Forest Regressor
2022-09-13 00:57:00,155:INFO:Total runtime is 0.10883680979410809 minutes
2022-09-13 00:57:00,160:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:00,160:INFO:Initializing create_model()
2022-09-13 00:57:00,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ECC57F9288>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ECC577B488>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:00,161:INFO:Checking exceptions
2022-09-13 00:57:00,163:INFO:Importing libraries
2022-09-13 00:57:00,163:INFO:Copying training dataset
2022-09-13 00:57:00,168:INFO:Defining folds
2022-09-13 00:57:00,168:INFO:Declaring metric variables
2022-09-13 00:57:00,173:INFO:Importing untrained model
2022-09-13 00:57:00,179:INFO:Random Forest Regressor Imported successfully
2022-09-13 00:57:00,189:INFO:Starting cross validation
2022-09-13 00:57:00,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:33,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:57:33,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:57:33,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:57:33,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-13 00:57:33,992:INFO:PyCaret RegressionExperiment
2022-09-13 00:57:33,992:INFO:Logging name: reg-default-name
2022-09-13 00:57:33,992:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-13 00:57:33,992:INFO:version 3.0.0.rc3
2022-09-13 00:57:33,992:INFO:Initializing setup()
2022-09-13 00:57:33,992:INFO:self.USI: 1ed8
2022-09-13 00:57:33,993:INFO:self.variable_keys: {'_gpu_n_jobs_param', 'data', 'idx', 'n_jobs_param', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'logging_param', 'memory', 'target_param', 'variable_keys', '_all_models', 'exp_id', '_all_metrics', 'pipeline', 'html_param', 'y', '_all_models_internal', 'log_plots_param', 'exp_name_log', 'y_train', 'X', 'display_container', 'transform_target_method_param', 'master_model_container', 'seed', 'X_test', 'transform_target_param', '_ml_usecase', 'gpu_param', 'y_test', 'fold_generator', 'X_train'}
2022-09-13 00:57:33,993:INFO:Checking environment
2022-09-13 00:57:33,993:INFO:python_version: 3.7.11
2022-09-13 00:57:33,993:INFO:python_build: ('default', 'Jul 27 2021 09:42:29')
2022-09-13 00:57:33,993:INFO:machine: AMD64
2022-09-13 00:57:33,993:INFO:platform: Windows-10-10.0.22000-SP0
2022-09-13 00:57:33,993:INFO:Memory: svmem(total=34156802048, available=11673239552, percent=65.8, used=22483562496, free=11673239552)
2022-09-13 00:57:33,993:INFO:Physical Core: 6
2022-09-13 00:57:33,993:INFO:Logical Core: 12
2022-09-13 00:57:33,993:INFO:Checking libraries
2022-09-13 00:57:33,993:INFO:System:
2022-09-13 00:57:33,993:INFO:    python: 3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]
2022-09-13 00:57:33,993:INFO:executable: c:\Users\Jamel\anaconda3\envs\dev\python.exe
2022-09-13 00:57:33,994:INFO:   machine: Windows-10-10.0.22000-SP0
2022-09-13 00:57:33,994:INFO:PyCaret required dependencies:
2022-09-13 00:57:33,994:INFO:                 pip: 22.1.2
2022-09-13 00:57:33,994:INFO:          setuptools: 60.10.0
2022-09-13 00:57:33,994:INFO:             pycaret: 3.0.0rc3
2022-09-13 00:57:33,994:INFO:             IPython: 7.31.1
2022-09-13 00:57:33,994:INFO:          ipywidgets: 7.6.5
2022-09-13 00:57:33,994:INFO:                tqdm: 4.64.0
2022-09-13 00:57:33,994:INFO:               numpy: 1.21.6
2022-09-13 00:57:33,994:INFO:              pandas: 1.3.5
2022-09-13 00:57:33,994:INFO:              jinja2: 3.0.3
2022-09-13 00:57:33,994:INFO:               scipy: 1.7.3
2022-09-13 00:57:33,994:INFO:              joblib: 1.1.0
2022-09-13 00:57:33,994:INFO:             sklearn: 1.0.2
2022-09-13 00:57:33,994:INFO:                pyod: 1.0.4
2022-09-13 00:57:33,994:INFO:            imblearn: 0.9.0
2022-09-13 00:57:33,995:INFO:   category_encoders: 2.5.0
2022-09-13 00:57:33,995:INFO:            lightgbm: 3.3.2
2022-09-13 00:57:33,995:INFO:               numba: 0.55.1
2022-09-13 00:57:33,995:INFO:            requests: 2.28.1
2022-09-13 00:57:33,995:INFO:          matplotlib: 3.5.1
2022-09-13 00:57:33,995:INFO:          scikitplot: 0.3.7
2022-09-13 00:57:33,995:INFO:         yellowbrick: 1.5
2022-09-13 00:57:33,995:INFO:              plotly: 5.9.0
2022-09-13 00:57:33,995:INFO:             kaleido: 0.2.1
2022-09-13 00:57:33,995:INFO:         statsmodels: 0.13.2
2022-09-13 00:57:33,995:INFO:              sktime: 0.13.2
2022-09-13 00:57:33,995:INFO:               tbats: 1.1.0
2022-09-13 00:57:33,996:INFO:            pmdarima: 1.8.5
2022-09-13 00:57:33,996:INFO:              psutil: 5.9.0
2022-09-13 00:57:33,996:INFO:PyCaret optional dependencies:
2022-09-13 00:57:34,008:INFO:                shap: 0.41.0
2022-09-13 00:57:34,008:INFO:           interpret: 0.2.7
2022-09-13 00:57:34,009:INFO:                umap: 0.5.3
2022-09-13 00:57:34,009:INFO:    pandas_profiling: 3.2.0
2022-09-13 00:57:34,009:INFO:  explainerdashboard: 0.3.8.2
2022-09-13 00:57:34,009:INFO:             autoviz: 0.1.43
2022-09-13 00:57:34,009:INFO:           fairlearn: 0.7.0
2022-09-13 00:57:34,009:INFO:             xgboost: 1.6.1
2022-09-13 00:57:34,009:INFO:            catboost: Not installed
2022-09-13 00:57:34,009:INFO:              kmodes: 0.12.1
2022-09-13 00:57:34,009:INFO:             mlxtend: Not installed
2022-09-13 00:57:34,009:INFO:       statsforecast: Not installed
2022-09-13 00:57:34,009:INFO:        tune_sklearn: Not installed
2022-09-13 00:57:34,009:INFO:                 ray: Not installed
2022-09-13 00:57:34,009:INFO:            hyperopt: Not installed
2022-09-13 00:57:34,009:INFO:              optuna: Not installed
2022-09-13 00:57:34,009:INFO:               skopt: Not installed
2022-09-13 00:57:34,009:INFO:              mlflow: Not installed
2022-09-13 00:57:34,010:INFO:              gradio: Not installed
2022-09-13 00:57:34,010:INFO:             fastapi: Not installed
2022-09-13 00:57:34,010:INFO:             uvicorn: Not installed
2022-09-13 00:57:34,010:INFO:              m2cgen: Not installed
2022-09-13 00:57:34,010:INFO:           evidently: Not installed
2022-09-13 00:57:34,010:INFO:                nltk: 3.7
2022-09-13 00:57:34,010:INFO:            pyLDAvis: Not installed
2022-09-13 00:57:34,010:INFO:              gensim: 4.2.0
2022-09-13 00:57:34,010:INFO:               spacy: 3.3.0
2022-09-13 00:57:34,010:INFO:           wordcloud: 1.8.1
2022-09-13 00:57:34,010:INFO:            textblob: 0.17.1
2022-09-13 00:57:34,010:INFO:               fugue: Not installed
2022-09-13 00:57:34,010:INFO:           streamlit: 1.11.0
2022-09-13 00:57:34,010:INFO:             prophet: Not installed
2022-09-13 00:57:34,010:INFO:None
2022-09-13 00:57:34,010:INFO:Set up data.
2022-09-13 00:57:34,021:INFO:Set up train/test split.
2022-09-13 00:57:34,027:INFO:Set up index.
2022-09-13 00:57:34,028:INFO:Set up folding strategy.
2022-09-13 00:57:34,028:INFO:Assigning column types.
2022-09-13 00:57:34,034:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-13 00:57:34,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,039:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,044:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,105:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,153:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,155:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:34,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:34,306:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,310:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,406:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,407:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:34,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:34,410:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-13 00:57:34,414:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,418:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,513:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:34,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:34,521:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,525:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,614:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:34,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:34,618:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-13 00:57:34,634:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,725:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,781:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:34,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:34,792:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,848:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:57:34,896:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:34,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:34,898:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-13 00:57:34,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:35,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:57:35,002:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:35,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:35,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:35,107:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:57:35,107:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:35,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:35,110:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-13 00:57:35,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:35,219:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:35,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:35,281:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:57:35,331:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:35,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:35,334:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-13 00:57:35,458:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:35,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:35,566:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:35,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:35,570:INFO:Preparing preprocessing pipeline...
2022-09-13 00:57:35,571:INFO:Set up simple imputation.
2022-09-13 00:57:35,573:INFO:Set up encoding of categorical features.
2022-09-13 00:57:35,573:INFO:Set up variance threshold.
2022-09-13 00:57:35,804:INFO:Finished creating preprocessing pipeline.
2022-09-13 00:57:35,814:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Jamel\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['unix', 'open', 'high', 'low',
                                             'Volume ETH', 'Volume USD'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'date', 'symbol'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Unnamed: 0', 'unix', 'date',
                                             'open', 'high', 'low',
                                             'Volume ETH', 'Volume USD'],
                                    transformer=LeaveOneOutEncoder(cols=['Unnamed: '
                                                                         '0',
                                                                         'date'],
                                                                   handle_missing='return_nan',
                                                                   random_state=618))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-13 00:57:35,814:INFO:Creating final display dataframe.
2022-09-13 00:57:36,612:INFO:Setup display_container:                  Description             Value
0                 Session id               618
1                     Target             close
2                Target type        Regression
3                 Data shape          (876, 7)
4           Train data shape          (613, 7)
5            Test data shape          (263, 7)
6           Numeric features                 6
7       Categorical features                 3
8                 Preprocess              True
9            Imputation type            simple
10        Numeric imputation              mean
11    Categorical imputation          constant
12  Maximum one-hot encoding                 5
13           Encoding method              None
14    Low variance threshold                 0
15            Fold Generator             KFold
16               Fold Number                10
17                  CPU Jobs                -1
18                   Use GPU             False
19            Log Experiment             False
20           Experiment Name  reg-default-name
21                       USI              1ed8
2022-09-13 00:57:36,750:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:36,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:36,881:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:57:36,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:57:36,890:INFO:setup() successfully completed in 2.9s...............
2022-09-13 00:57:37,183:INFO:Initializing compare_models()
2022-09-13 00:57:37,183:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engines': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-13 00:57:37,183:INFO:Checking exceptions
2022-09-13 00:57:37,187:INFO:Preparing display monitor
2022-09-13 00:57:37,243:INFO:Initializing Linear Regression
2022-09-13 00:57:37,244:INFO:Total runtime is 1.6597906748453774e-05 minutes
2022-09-13 00:57:37,248:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:37,248:INFO:Initializing create_model()
2022-09-13 00:57:37,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:37,248:INFO:Checking exceptions
2022-09-13 00:57:37,251:INFO:Importing libraries
2022-09-13 00:57:37,251:INFO:Copying training dataset
2022-09-13 00:57:37,255:INFO:Defining folds
2022-09-13 00:57:37,255:INFO:Declaring metric variables
2022-09-13 00:57:37,259:INFO:Importing untrained model
2022-09-13 00:57:37,263:INFO:Linear Regression Imported successfully
2022-09-13 00:57:37,274:INFO:Starting cross validation
2022-09-13 00:57:37,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:46,123:INFO:Calculating mean and std
2022-09-13 00:57:46,125:INFO:Creating metrics dataframe
2022-09-13 00:57:46,129:INFO:Uploading results into container
2022-09-13 00:57:46,131:INFO:Uploading model into container now
2022-09-13 00:57:46,131:INFO:master_model_container: 1
2022-09-13 00:57:46,132:INFO:display_container: 2
2022-09-13 00:57:46,132:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:57:46,133:INFO:create_model() successfully completed......................................
2022-09-13 00:57:46,296:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:46,297:INFO:Creating metrics dataframe
2022-09-13 00:57:46,319:INFO:Initializing Lasso Regression
2022-09-13 00:57:46,320:INFO:Total runtime is 0.15128053426742555 minutes
2022-09-13 00:57:46,324:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:46,324:INFO:Initializing create_model()
2022-09-13 00:57:46,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:46,324:INFO:Checking exceptions
2022-09-13 00:57:46,326:INFO:Importing libraries
2022-09-13 00:57:46,326:INFO:Copying training dataset
2022-09-13 00:57:46,329:INFO:Defining folds
2022-09-13 00:57:46,329:INFO:Declaring metric variables
2022-09-13 00:57:46,335:INFO:Importing untrained model
2022-09-13 00:57:46,340:INFO:Lasso Regression Imported successfully
2022-09-13 00:57:46,349:INFO:Starting cross validation
2022-09-13 00:57:46,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:46,470:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.298e+05, tolerance: 1.021e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:46,480:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.198e+05, tolerance: 1.045e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:46,533:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.298e+05, tolerance: 1.037e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:46,545:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.272e+05, tolerance: 1.045e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:46,570:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.146e+05, tolerance: 1.032e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:46,598:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.525e+05, tolerance: 1.031e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:46,632:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.169e+05, tolerance: 1.022e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:46,639:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.728e+05, tolerance: 1.039e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:49,301:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.166e+05, tolerance: 1.017e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:49,359:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.824e+05, tolerance: 1.058e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:49,486:INFO:Calculating mean and std
2022-09-13 00:57:49,489:INFO:Creating metrics dataframe
2022-09-13 00:57:49,495:INFO:Uploading results into container
2022-09-13 00:57:49,496:INFO:Uploading model into container now
2022-09-13 00:57:49,496:INFO:master_model_container: 2
2022-09-13 00:57:49,496:INFO:display_container: 2
2022-09-13 00:57:49,497:INFO:Lasso(random_state=618)
2022-09-13 00:57:49,497:INFO:create_model() successfully completed......................................
2022-09-13 00:57:49,647:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:49,648:INFO:Creating metrics dataframe
2022-09-13 00:57:49,667:INFO:Initializing Ridge Regression
2022-09-13 00:57:49,668:INFO:Total runtime is 0.2070852319399516 minutes
2022-09-13 00:57:49,673:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:49,674:INFO:Initializing create_model()
2022-09-13 00:57:49,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:49,674:INFO:Checking exceptions
2022-09-13 00:57:49,676:INFO:Importing libraries
2022-09-13 00:57:49,676:INFO:Copying training dataset
2022-09-13 00:57:49,680:INFO:Defining folds
2022-09-13 00:57:49,680:INFO:Declaring metric variables
2022-09-13 00:57:49,686:INFO:Importing untrained model
2022-09-13 00:57:49,691:INFO:Ridge Regression Imported successfully
2022-09-13 00:57:49,699:INFO:Starting cross validation
2022-09-13 00:57:49,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:49,798:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05656e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,802:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05235e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,828:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05864e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,829:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05105e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,862:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05064e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,875:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.12807e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,885:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.99844e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,910:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.0432e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,919:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.15202e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,924:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.68373e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:57:49,973:INFO:Calculating mean and std
2022-09-13 00:57:49,974:INFO:Creating metrics dataframe
2022-09-13 00:57:49,978:INFO:Uploading results into container
2022-09-13 00:57:49,978:INFO:Uploading model into container now
2022-09-13 00:57:49,979:INFO:master_model_container: 3
2022-09-13 00:57:49,979:INFO:display_container: 2
2022-09-13 00:57:49,979:INFO:Ridge(random_state=618)
2022-09-13 00:57:49,980:INFO:create_model() successfully completed......................................
2022-09-13 00:57:50,123:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:50,123:INFO:Creating metrics dataframe
2022-09-13 00:57:50,141:INFO:Initializing Elastic Net
2022-09-13 00:57:50,142:INFO:Total runtime is 0.21498069763183594 minutes
2022-09-13 00:57:50,147:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:50,147:INFO:Initializing create_model()
2022-09-13 00:57:50,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:50,148:INFO:Checking exceptions
2022-09-13 00:57:50,149:INFO:Importing libraries
2022-09-13 00:57:50,149:INFO:Copying training dataset
2022-09-13 00:57:50,155:INFO:Defining folds
2022-09-13 00:57:50,156:INFO:Declaring metric variables
2022-09-13 00:57:50,160:INFO:Importing untrained model
2022-09-13 00:57:50,165:INFO:Elastic Net Imported successfully
2022-09-13 00:57:50,175:INFO:Starting cross validation
2022-09-13 00:57:50,177:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:50,263:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.162e+05, tolerance: 1.017e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,276:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.821e+05, tolerance: 1.058e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,293:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.295e+05, tolerance: 1.021e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,318:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.194e+05, tolerance: 1.045e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,347:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.294e+05, tolerance: 1.037e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,350:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.269e+05, tolerance: 1.045e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,374:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.143e+05, tolerance: 1.032e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,386:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.521e+05, tolerance: 1.031e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,399:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.166e+05, tolerance: 1.022e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,412:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.725e+05, tolerance: 1.039e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:57:50,451:INFO:Calculating mean and std
2022-09-13 00:57:50,453:INFO:Creating metrics dataframe
2022-09-13 00:57:50,457:INFO:Uploading results into container
2022-09-13 00:57:50,458:INFO:Uploading model into container now
2022-09-13 00:57:50,459:INFO:master_model_container: 4
2022-09-13 00:57:50,459:INFO:display_container: 2
2022-09-13 00:57:50,460:INFO:ElasticNet(random_state=618)
2022-09-13 00:57:50,460:INFO:create_model() successfully completed......................................
2022-09-13 00:57:50,603:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:50,603:INFO:Creating metrics dataframe
2022-09-13 00:57:50,622:INFO:Initializing Least Angle Regression
2022-09-13 00:57:50,622:INFO:Total runtime is 0.22299264272054037 minutes
2022-09-13 00:57:50,627:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:50,627:INFO:Initializing create_model()
2022-09-13 00:57:50,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:50,628:INFO:Checking exceptions
2022-09-13 00:57:50,630:INFO:Importing libraries
2022-09-13 00:57:50,630:INFO:Copying training dataset
2022-09-13 00:57:50,635:INFO:Defining folds
2022-09-13 00:57:50,635:INFO:Declaring metric variables
2022-09-13 00:57:50,640:INFO:Importing untrained model
2022-09-13 00:57:50,645:INFO:Least Angle Regression Imported successfully
2022-09-13 00:57:50,656:INFO:Starting cross validation
2022-09-13 00:57:50,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:50,738:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,753:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,791:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,806:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,816:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,829:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,847:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,864:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,883:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,890:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:50,927:INFO:Calculating mean and std
2022-09-13 00:57:50,929:INFO:Creating metrics dataframe
2022-09-13 00:57:50,934:INFO:Uploading results into container
2022-09-13 00:57:50,934:INFO:Uploading model into container now
2022-09-13 00:57:50,935:INFO:master_model_container: 5
2022-09-13 00:57:50,935:INFO:display_container: 2
2022-09-13 00:57:50,936:INFO:Lars(random_state=618)
2022-09-13 00:57:50,936:INFO:create_model() successfully completed......................................
2022-09-13 00:57:51,082:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:51,082:INFO:Creating metrics dataframe
2022-09-13 00:57:51,103:INFO:Initializing Lasso Least Angle Regression
2022-09-13 00:57:51,104:INFO:Total runtime is 0.23102116187413535 minutes
2022-09-13 00:57:51,109:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:51,109:INFO:Initializing create_model()
2022-09-13 00:57:51,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:51,109:INFO:Checking exceptions
2022-09-13 00:57:51,112:INFO:Importing libraries
2022-09-13 00:57:51,112:INFO:Copying training dataset
2022-09-13 00:57:51,116:INFO:Defining folds
2022-09-13 00:57:51,117:INFO:Declaring metric variables
2022-09-13 00:57:51,122:INFO:Importing untrained model
2022-09-13 00:57:51,127:INFO:Lasso Least Angle Regression Imported successfully
2022-09-13 00:57:51,137:INFO:Starting cross validation
2022-09-13 00:57:51,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:51,217:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,231:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,259:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,260:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,296:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,306:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,327:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,333:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,362:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,375:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:57:51,411:INFO:Calculating mean and std
2022-09-13 00:57:51,413:INFO:Creating metrics dataframe
2022-09-13 00:57:51,416:INFO:Uploading results into container
2022-09-13 00:57:51,416:INFO:Uploading model into container now
2022-09-13 00:57:51,417:INFO:master_model_container: 6
2022-09-13 00:57:51,417:INFO:display_container: 2
2022-09-13 00:57:51,417:INFO:LassoLars(random_state=618)
2022-09-13 00:57:51,417:INFO:create_model() successfully completed......................................
2022-09-13 00:57:51,555:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:51,555:INFO:Creating metrics dataframe
2022-09-13 00:57:51,574:INFO:Initializing Orthogonal Matching Pursuit
2022-09-13 00:57:51,574:INFO:Total runtime is 0.2388522227605184 minutes
2022-09-13 00:57:51,580:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:51,580:INFO:Initializing create_model()
2022-09-13 00:57:51,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:51,581:INFO:Checking exceptions
2022-09-13 00:57:51,582:INFO:Importing libraries
2022-09-13 00:57:51,582:INFO:Copying training dataset
2022-09-13 00:57:51,587:INFO:Defining folds
2022-09-13 00:57:51,587:INFO:Declaring metric variables
2022-09-13 00:57:51,592:INFO:Importing untrained model
2022-09-13 00:57:51,597:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-13 00:57:51,606:INFO:Starting cross validation
2022-09-13 00:57:51,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:51,684:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,699:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,721:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,746:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,773:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,782:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,782:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,795:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,811:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,835:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:57:51,891:INFO:Calculating mean and std
2022-09-13 00:57:51,892:INFO:Creating metrics dataframe
2022-09-13 00:57:51,895:INFO:Uploading results into container
2022-09-13 00:57:51,895:INFO:Uploading model into container now
2022-09-13 00:57:51,896:INFO:master_model_container: 7
2022-09-13 00:57:51,896:INFO:display_container: 2
2022-09-13 00:57:51,896:INFO:OrthogonalMatchingPursuit()
2022-09-13 00:57:51,896:INFO:create_model() successfully completed......................................
2022-09-13 00:57:52,033:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:52,033:INFO:Creating metrics dataframe
2022-09-13 00:57:52,052:INFO:Initializing Bayesian Ridge
2022-09-13 00:57:52,053:INFO:Total runtime is 0.24683489799499514 minutes
2022-09-13 00:57:52,058:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:52,058:INFO:Initializing create_model()
2022-09-13 00:57:52,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:52,059:INFO:Checking exceptions
2022-09-13 00:57:52,061:INFO:Importing libraries
2022-09-13 00:57:52,061:INFO:Copying training dataset
2022-09-13 00:57:52,065:INFO:Defining folds
2022-09-13 00:57:52,065:INFO:Declaring metric variables
2022-09-13 00:57:52,070:INFO:Importing untrained model
2022-09-13 00:57:52,076:INFO:Bayesian Ridge Imported successfully
2022-09-13 00:57:52,083:INFO:Starting cross validation
2022-09-13 00:57:52,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:52,361:INFO:Calculating mean and std
2022-09-13 00:57:52,363:INFO:Creating metrics dataframe
2022-09-13 00:57:52,366:INFO:Uploading results into container
2022-09-13 00:57:52,367:INFO:Uploading model into container now
2022-09-13 00:57:52,367:INFO:master_model_container: 8
2022-09-13 00:57:52,367:INFO:display_container: 2
2022-09-13 00:57:52,368:INFO:BayesianRidge()
2022-09-13 00:57:52,368:INFO:create_model() successfully completed......................................
2022-09-13 00:57:52,508:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:52,509:INFO:Creating metrics dataframe
2022-09-13 00:57:52,528:INFO:Initializing Passive Aggressive Regressor
2022-09-13 00:57:52,528:INFO:Total runtime is 0.25474707285563153 minutes
2022-09-13 00:57:52,532:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:52,532:INFO:Initializing create_model()
2022-09-13 00:57:52,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:52,532:INFO:Checking exceptions
2022-09-13 00:57:52,535:INFO:Importing libraries
2022-09-13 00:57:52,535:INFO:Copying training dataset
2022-09-13 00:57:52,542:INFO:Defining folds
2022-09-13 00:57:52,543:INFO:Declaring metric variables
2022-09-13 00:57:52,547:INFO:Importing untrained model
2022-09-13 00:57:52,552:INFO:Passive Aggressive Regressor Imported successfully
2022-09-13 00:57:52,562:INFO:Starting cross validation
2022-09-13 00:57:52,564:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:52,850:INFO:Calculating mean and std
2022-09-13 00:57:52,852:INFO:Creating metrics dataframe
2022-09-13 00:57:52,856:INFO:Uploading results into container
2022-09-13 00:57:52,857:INFO:Uploading model into container now
2022-09-13 00:57:52,857:INFO:master_model_container: 9
2022-09-13 00:57:52,858:INFO:display_container: 2
2022-09-13 00:57:52,858:INFO:PassiveAggressiveRegressor(random_state=618)
2022-09-13 00:57:52,858:INFO:create_model() successfully completed......................................
2022-09-13 00:57:52,995:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:52,996:INFO:Creating metrics dataframe
2022-09-13 00:57:53,019:INFO:Initializing Huber Regressor
2022-09-13 00:57:53,020:INFO:Total runtime is 0.2629584511121114 minutes
2022-09-13 00:57:53,026:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:53,026:INFO:Initializing create_model()
2022-09-13 00:57:53,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:53,027:INFO:Checking exceptions
2022-09-13 00:57:53,029:INFO:Importing libraries
2022-09-13 00:57:53,029:INFO:Copying training dataset
2022-09-13 00:57:53,033:INFO:Defining folds
2022-09-13 00:57:53,033:INFO:Declaring metric variables
2022-09-13 00:57:53,038:INFO:Importing untrained model
2022-09-13 00:57:53,043:INFO:Huber Regressor Imported successfully
2022-09-13 00:57:53,053:INFO:Starting cross validation
2022-09-13 00:57:53,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:53,345:INFO:Calculating mean and std
2022-09-13 00:57:53,347:INFO:Creating metrics dataframe
2022-09-13 00:57:53,351:INFO:Uploading results into container
2022-09-13 00:57:53,352:INFO:Uploading model into container now
2022-09-13 00:57:53,352:INFO:master_model_container: 10
2022-09-13 00:57:53,352:INFO:display_container: 2
2022-09-13 00:57:53,352:INFO:HuberRegressor()
2022-09-13 00:57:53,352:INFO:create_model() successfully completed......................................
2022-09-13 00:57:53,491:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:53,491:INFO:Creating metrics dataframe
2022-09-13 00:57:53,512:INFO:Initializing K Neighbors Regressor
2022-09-13 00:57:53,513:INFO:Total runtime is 0.27116790612538655 minutes
2022-09-13 00:57:53,517:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:53,518:INFO:Initializing create_model()
2022-09-13 00:57:53,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:53,518:INFO:Checking exceptions
2022-09-13 00:57:53,521:INFO:Importing libraries
2022-09-13 00:57:53,521:INFO:Copying training dataset
2022-09-13 00:57:53,525:INFO:Defining folds
2022-09-13 00:57:53,525:INFO:Declaring metric variables
2022-09-13 00:57:53,530:INFO:Importing untrained model
2022-09-13 00:57:53,535:INFO:K Neighbors Regressor Imported successfully
2022-09-13 00:57:53,545:INFO:Starting cross validation
2022-09-13 00:57:53,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:53,939:INFO:Calculating mean and std
2022-09-13 00:57:53,941:INFO:Creating metrics dataframe
2022-09-13 00:57:53,946:INFO:Uploading results into container
2022-09-13 00:57:53,947:INFO:Uploading model into container now
2022-09-13 00:57:53,948:INFO:master_model_container: 11
2022-09-13 00:57:53,948:INFO:display_container: 2
2022-09-13 00:57:53,949:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-13 00:57:53,949:INFO:create_model() successfully completed......................................
2022-09-13 00:57:54,088:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:54,089:INFO:Creating metrics dataframe
2022-09-13 00:57:54,108:INFO:Initializing Decision Tree Regressor
2022-09-13 00:57:54,108:INFO:Total runtime is 0.2810964226722717 minutes
2022-09-13 00:57:54,113:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:54,113:INFO:Initializing create_model()
2022-09-13 00:57:54,113:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:54,113:INFO:Checking exceptions
2022-09-13 00:57:54,115:INFO:Importing libraries
2022-09-13 00:57:54,115:INFO:Copying training dataset
2022-09-13 00:57:54,119:INFO:Defining folds
2022-09-13 00:57:54,119:INFO:Declaring metric variables
2022-09-13 00:57:54,124:INFO:Importing untrained model
2022-09-13 00:57:54,129:INFO:Decision Tree Regressor Imported successfully
2022-09-13 00:57:54,139:INFO:Starting cross validation
2022-09-13 00:57:54,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:54,428:INFO:Calculating mean and std
2022-09-13 00:57:54,429:INFO:Creating metrics dataframe
2022-09-13 00:57:54,432:INFO:Uploading results into container
2022-09-13 00:57:54,433:INFO:Uploading model into container now
2022-09-13 00:57:54,433:INFO:master_model_container: 12
2022-09-13 00:57:54,434:INFO:display_container: 2
2022-09-13 00:57:54,435:INFO:DecisionTreeRegressor(random_state=618)
2022-09-13 00:57:54,435:INFO:create_model() successfully completed......................................
2022-09-13 00:57:54,580:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:54,581:INFO:Creating metrics dataframe
2022-09-13 00:57:54,601:INFO:Initializing Random Forest Regressor
2022-09-13 00:57:54,601:INFO:Total runtime is 0.28930954138437903 minutes
2022-09-13 00:57:54,606:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:54,607:INFO:Initializing create_model()
2022-09-13 00:57:54,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:54,607:INFO:Checking exceptions
2022-09-13 00:57:54,610:INFO:Importing libraries
2022-09-13 00:57:54,610:INFO:Copying training dataset
2022-09-13 00:57:54,614:INFO:Defining folds
2022-09-13 00:57:54,615:INFO:Declaring metric variables
2022-09-13 00:57:54,619:INFO:Importing untrained model
2022-09-13 00:57:54,626:INFO:Random Forest Regressor Imported successfully
2022-09-13 00:57:54,635:INFO:Starting cross validation
2022-09-13 00:57:54,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:55,600:INFO:Calculating mean and std
2022-09-13 00:57:55,601:INFO:Creating metrics dataframe
2022-09-13 00:57:55,605:INFO:Uploading results into container
2022-09-13 00:57:55,605:INFO:Uploading model into container now
2022-09-13 00:57:55,606:INFO:master_model_container: 13
2022-09-13 00:57:55,606:INFO:display_container: 2
2022-09-13 00:57:55,607:INFO:RandomForestRegressor(n_jobs=-1, random_state=618)
2022-09-13 00:57:55,608:INFO:create_model() successfully completed......................................
2022-09-13 00:57:55,734:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:55,734:INFO:Creating metrics dataframe
2022-09-13 00:57:55,750:INFO:Initializing Extra Trees Regressor
2022-09-13 00:57:55,751:INFO:Total runtime is 0.30847492218017575 minutes
2022-09-13 00:57:55,754:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:55,754:INFO:Initializing create_model()
2022-09-13 00:57:55,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:55,755:INFO:Checking exceptions
2022-09-13 00:57:55,757:INFO:Importing libraries
2022-09-13 00:57:55,757:INFO:Copying training dataset
2022-09-13 00:57:55,761:INFO:Defining folds
2022-09-13 00:57:55,762:INFO:Declaring metric variables
2022-09-13 00:57:55,767:INFO:Importing untrained model
2022-09-13 00:57:55,771:INFO:Extra Trees Regressor Imported successfully
2022-09-13 00:57:55,779:INFO:Starting cross validation
2022-09-13 00:57:55,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:56,534:INFO:Calculating mean and std
2022-09-13 00:57:56,536:INFO:Creating metrics dataframe
2022-09-13 00:57:56,539:INFO:Uploading results into container
2022-09-13 00:57:56,540:INFO:Uploading model into container now
2022-09-13 00:57:56,541:INFO:master_model_container: 14
2022-09-13 00:57:56,541:INFO:display_container: 2
2022-09-13 00:57:56,541:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=618)
2022-09-13 00:57:56,542:INFO:create_model() successfully completed......................................
2022-09-13 00:57:56,671:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:56,672:INFO:Creating metrics dataframe
2022-09-13 00:57:56,694:INFO:Initializing AdaBoost Regressor
2022-09-13 00:57:56,694:INFO:Total runtime is 0.3241828997929891 minutes
2022-09-13 00:57:56,698:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:56,699:INFO:Initializing create_model()
2022-09-13 00:57:56,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:56,699:INFO:Checking exceptions
2022-09-13 00:57:56,701:INFO:Importing libraries
2022-09-13 00:57:56,701:INFO:Copying training dataset
2022-09-13 00:57:56,704:INFO:Defining folds
2022-09-13 00:57:56,704:INFO:Declaring metric variables
2022-09-13 00:57:56,709:INFO:Importing untrained model
2022-09-13 00:57:56,714:INFO:AdaBoost Regressor Imported successfully
2022-09-13 00:57:56,722:INFO:Starting cross validation
2022-09-13 00:57:56,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:57,188:INFO:Calculating mean and std
2022-09-13 00:57:57,191:INFO:Creating metrics dataframe
2022-09-13 00:57:57,197:INFO:Uploading results into container
2022-09-13 00:57:57,197:INFO:Uploading model into container now
2022-09-13 00:57:57,198:INFO:master_model_container: 15
2022-09-13 00:57:57,198:INFO:display_container: 2
2022-09-13 00:57:57,198:INFO:AdaBoostRegressor(random_state=618)
2022-09-13 00:57:57,198:INFO:create_model() successfully completed......................................
2022-09-13 00:57:57,331:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:57,331:INFO:Creating metrics dataframe
2022-09-13 00:57:57,347:INFO:Initializing Gradient Boosting Regressor
2022-09-13 00:57:57,348:INFO:Total runtime is 0.3350870847702026 minutes
2022-09-13 00:57:57,352:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:57,352:INFO:Initializing create_model()
2022-09-13 00:57:57,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:57,352:INFO:Checking exceptions
2022-09-13 00:57:57,354:INFO:Importing libraries
2022-09-13 00:57:57,354:INFO:Copying training dataset
2022-09-13 00:57:57,357:INFO:Defining folds
2022-09-13 00:57:57,357:INFO:Declaring metric variables
2022-09-13 00:57:57,363:INFO:Importing untrained model
2022-09-13 00:57:57,369:INFO:Gradient Boosting Regressor Imported successfully
2022-09-13 00:57:57,377:INFO:Starting cross validation
2022-09-13 00:57:57,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:57,883:INFO:Calculating mean and std
2022-09-13 00:57:57,885:INFO:Creating metrics dataframe
2022-09-13 00:57:57,889:INFO:Uploading results into container
2022-09-13 00:57:57,889:INFO:Uploading model into container now
2022-09-13 00:57:57,890:INFO:master_model_container: 16
2022-09-13 00:57:57,890:INFO:display_container: 2
2022-09-13 00:57:57,890:INFO:GradientBoostingRegressor(random_state=618)
2022-09-13 00:57:57,890:INFO:create_model() successfully completed......................................
2022-09-13 00:57:58,024:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:58,024:INFO:Creating metrics dataframe
2022-09-13 00:57:58,045:INFO:Initializing Extreme Gradient Boosting
2022-09-13 00:57:58,045:INFO:Total runtime is 0.3467060009638468 minutes
2022-09-13 00:57:58,049:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:58,049:INFO:Initializing create_model()
2022-09-13 00:57:58,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:58,050:INFO:Checking exceptions
2022-09-13 00:57:58,051:INFO:Importing libraries
2022-09-13 00:57:58,051:INFO:Copying training dataset
2022-09-13 00:57:58,056:INFO:Defining folds
2022-09-13 00:57:58,057:INFO:Declaring metric variables
2022-09-13 00:57:58,063:INFO:Importing untrained model
2022-09-13 00:57:58,069:INFO:Extreme Gradient Boosting Imported successfully
2022-09-13 00:57:58,080:INFO:Starting cross validation
2022-09-13 00:57:58,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:57:58,751:INFO:Calculating mean and std
2022-09-13 00:57:58,753:INFO:Creating metrics dataframe
2022-09-13 00:57:58,756:INFO:Uploading results into container
2022-09-13 00:57:58,756:INFO:Uploading model into container now
2022-09-13 00:57:58,756:INFO:master_model_container: 17
2022-09-13 00:57:58,756:INFO:display_container: 2
2022-09-13 00:57:58,757:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=618,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-13 00:57:58,757:INFO:create_model() successfully completed......................................
2022-09-13 00:57:58,900:INFO:SubProcess create_model() end ==================================
2022-09-13 00:57:58,900:INFO:Creating metrics dataframe
2022-09-13 00:57:58,921:INFO:Initializing Light Gradient Boosting Machine
2022-09-13 00:57:58,922:INFO:Total runtime is 0.3613151669502258 minutes
2022-09-13 00:57:58,928:INFO:SubProcess create_model() called ==================================
2022-09-13 00:57:58,928:INFO:Initializing create_model()
2022-09-13 00:57:58,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:57:58,929:INFO:Checking exceptions
2022-09-13 00:57:58,931:INFO:Importing libraries
2022-09-13 00:57:58,931:INFO:Copying training dataset
2022-09-13 00:57:58,935:INFO:Defining folds
2022-09-13 00:57:58,935:INFO:Declaring metric variables
2022-09-13 00:57:58,940:INFO:Importing untrained model
2022-09-13 00:57:58,944:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-13 00:57:58,952:INFO:Starting cross validation
2022-09-13 00:57:58,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:00,500:INFO:Calculating mean and std
2022-09-13 00:58:00,502:INFO:Creating metrics dataframe
2022-09-13 00:58:00,505:INFO:Uploading results into container
2022-09-13 00:58:00,506:INFO:Uploading model into container now
2022-09-13 00:58:00,506:INFO:master_model_container: 18
2022-09-13 00:58:00,506:INFO:display_container: 2
2022-09-13 00:58:00,507:INFO:LGBMRegressor(random_state=618)
2022-09-13 00:58:00,507:INFO:create_model() successfully completed......................................
2022-09-13 00:58:00,644:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:00,645:INFO:Creating metrics dataframe
2022-09-13 00:58:00,669:INFO:Initializing Dummy Regressor
2022-09-13 00:58:00,669:INFO:Total runtime is 0.39043725331624346 minutes
2022-09-13 00:58:00,673:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:00,673:INFO:Initializing create_model()
2022-09-13 00:58:00,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B4D66C8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:00,673:INFO:Checking exceptions
2022-09-13 00:58:00,675:INFO:Importing libraries
2022-09-13 00:58:00,675:INFO:Copying training dataset
2022-09-13 00:58:00,678:INFO:Defining folds
2022-09-13 00:58:00,679:INFO:Declaring metric variables
2022-09-13 00:58:00,684:INFO:Importing untrained model
2022-09-13 00:58:00,688:INFO:Dummy Regressor Imported successfully
2022-09-13 00:58:00,695:INFO:Starting cross validation
2022-09-13 00:58:00,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:01,006:INFO:Calculating mean and std
2022-09-13 00:58:01,008:INFO:Creating metrics dataframe
2022-09-13 00:58:01,012:INFO:Uploading results into container
2022-09-13 00:58:01,013:INFO:Uploading model into container now
2022-09-13 00:58:01,013:INFO:master_model_container: 19
2022-09-13 00:58:01,014:INFO:display_container: 2
2022-09-13 00:58:01,014:INFO:DummyRegressor()
2022-09-13 00:58:01,014:INFO:create_model() successfully completed......................................
2022-09-13 00:58:01,140:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:01,140:INFO:Creating metrics dataframe
2022-09-13 00:58:01,183:INFO:Initializing create_model()
2022-09-13 00:58:01,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:01,183:INFO:Checking exceptions
2022-09-13 00:58:01,189:INFO:Importing libraries
2022-09-13 00:58:01,189:INFO:Copying training dataset
2022-09-13 00:58:01,192:INFO:Defining folds
2022-09-13 00:58:01,192:INFO:Declaring metric variables
2022-09-13 00:58:01,193:INFO:Importing untrained model
2022-09-13 00:58:01,193:INFO:Declaring custom model
2022-09-13 00:58:01,194:INFO:Linear Regression Imported successfully
2022-09-13 00:58:01,196:INFO:Cross validation set to False
2022-09-13 00:58:01,196:INFO:Fitting Model
2022-09-13 00:58:01,392:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:58:01,392:INFO:create_model() successfully completed......................................
2022-09-13 00:58:01,610:INFO:master_model_container: 19
2022-09-13 00:58:01,610:INFO:display_container: 2
2022-09-13 00:58:01,610:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:58:01,610:INFO:compare_models() successfully completed......................................
2022-09-13 00:58:01,611:INFO:Initializing compare_models()
2022-09-13 00:58:01,611:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engines': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-13 00:58:01,611:INFO:Checking exceptions
2022-09-13 00:58:01,613:INFO:Preparing display monitor
2022-09-13 00:58:01,659:INFO:Initializing Linear Regression
2022-09-13 00:58:01,659:INFO:Total runtime is 0.0 minutes
2022-09-13 00:58:01,667:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:01,668:INFO:Initializing create_model()
2022-09-13 00:58:01,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:01,668:INFO:Checking exceptions
2022-09-13 00:58:01,672:INFO:Importing libraries
2022-09-13 00:58:01,672:INFO:Copying training dataset
2022-09-13 00:58:01,675:INFO:Defining folds
2022-09-13 00:58:01,675:INFO:Declaring metric variables
2022-09-13 00:58:01,680:INFO:Importing untrained model
2022-09-13 00:58:01,685:INFO:Linear Regression Imported successfully
2022-09-13 00:58:01,693:INFO:Starting cross validation
2022-09-13 00:58:01,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:02,046:INFO:Calculating mean and std
2022-09-13 00:58:02,046:INFO:Creating metrics dataframe
2022-09-13 00:58:02,050:INFO:Uploading results into container
2022-09-13 00:58:02,050:INFO:Uploading model into container now
2022-09-13 00:58:02,050:INFO:master_model_container: 20
2022-09-13 00:58:02,051:INFO:display_container: 3
2022-09-13 00:58:02,051:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:58:02,051:INFO:create_model() successfully completed......................................
2022-09-13 00:58:02,190:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:02,191:INFO:Creating metrics dataframe
2022-09-13 00:58:02,205:INFO:Initializing Lasso Regression
2022-09-13 00:58:02,206:INFO:Total runtime is 0.009123953183492024 minutes
2022-09-13 00:58:02,210:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:02,210:INFO:Initializing create_model()
2022-09-13 00:58:02,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:02,210:INFO:Checking exceptions
2022-09-13 00:58:02,212:INFO:Importing libraries
2022-09-13 00:58:02,212:INFO:Copying training dataset
2022-09-13 00:58:02,216:INFO:Defining folds
2022-09-13 00:58:02,216:INFO:Declaring metric variables
2022-09-13 00:58:02,222:INFO:Importing untrained model
2022-09-13 00:58:02,226:INFO:Lasso Regression Imported successfully
2022-09-13 00:58:02,235:INFO:Starting cross validation
2022-09-13 00:58:02,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:02,333:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.166e+05, tolerance: 1.017e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,359:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.824e+05, tolerance: 1.058e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,382:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.298e+05, tolerance: 1.021e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,393:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.198e+05, tolerance: 1.045e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,427:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.298e+05, tolerance: 1.037e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,453:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.272e+05, tolerance: 1.045e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,474:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.146e+05, tolerance: 1.032e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,485:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.525e+05, tolerance: 1.031e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,503:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.169e+05, tolerance: 1.022e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,523:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.728e+05, tolerance: 1.039e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:02,581:INFO:Calculating mean and std
2022-09-13 00:58:02,581:INFO:Creating metrics dataframe
2022-09-13 00:58:02,585:INFO:Uploading results into container
2022-09-13 00:58:02,585:INFO:Uploading model into container now
2022-09-13 00:58:02,586:INFO:master_model_container: 21
2022-09-13 00:58:02,586:INFO:display_container: 3
2022-09-13 00:58:02,586:INFO:Lasso(random_state=618)
2022-09-13 00:58:02,586:INFO:create_model() successfully completed......................................
2022-09-13 00:58:02,725:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:02,725:INFO:Creating metrics dataframe
2022-09-13 00:58:02,741:INFO:Initializing Ridge Regression
2022-09-13 00:58:02,741:INFO:Total runtime is 0.01803346872329712 minutes
2022-09-13 00:58:02,745:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:02,745:INFO:Initializing create_model()
2022-09-13 00:58:02,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:02,746:INFO:Checking exceptions
2022-09-13 00:58:02,747:INFO:Importing libraries
2022-09-13 00:58:02,748:INFO:Copying training dataset
2022-09-13 00:58:02,751:INFO:Defining folds
2022-09-13 00:58:02,751:INFO:Declaring metric variables
2022-09-13 00:58:02,757:INFO:Importing untrained model
2022-09-13 00:58:02,762:INFO:Ridge Regression Imported successfully
2022-09-13 00:58:02,773:INFO:Starting cross validation
2022-09-13 00:58:02,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:02,877:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05235e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:02,882:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05656e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:02,902:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05105e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:02,920:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05864e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:02,957:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.05064e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:02,969:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.12807e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:02,992:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.99844e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:03,012:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.0432e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:03,028:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.15202e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:03,036:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.68373e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:58:03,095:INFO:Calculating mean and std
2022-09-13 00:58:03,105:INFO:Creating metrics dataframe
2022-09-13 00:58:03,113:INFO:Uploading results into container
2022-09-13 00:58:03,114:INFO:Uploading model into container now
2022-09-13 00:58:03,115:INFO:master_model_container: 22
2022-09-13 00:58:03,115:INFO:display_container: 3
2022-09-13 00:58:03,116:INFO:Ridge(random_state=618)
2022-09-13 00:58:03,116:INFO:create_model() successfully completed......................................
2022-09-13 00:58:03,341:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:03,341:INFO:Creating metrics dataframe
2022-09-13 00:58:03,357:INFO:Initializing Elastic Net
2022-09-13 00:58:03,357:INFO:Total runtime is 0.028299101193745933 minutes
2022-09-13 00:58:03,361:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:03,362:INFO:Initializing create_model()
2022-09-13 00:58:03,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:03,362:INFO:Checking exceptions
2022-09-13 00:58:03,364:INFO:Importing libraries
2022-09-13 00:58:03,365:INFO:Copying training dataset
2022-09-13 00:58:03,368:INFO:Defining folds
2022-09-13 00:58:03,368:INFO:Declaring metric variables
2022-09-13 00:58:03,372:INFO:Importing untrained model
2022-09-13 00:58:03,378:INFO:Elastic Net Imported successfully
2022-09-13 00:58:03,389:INFO:Starting cross validation
2022-09-13 00:58:03,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:03,504:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.162e+05, tolerance: 1.017e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,538:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.821e+05, tolerance: 1.058e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,556:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.194e+05, tolerance: 1.045e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,574:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.294e+05, tolerance: 1.037e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,578:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.295e+05, tolerance: 1.021e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,619:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.269e+05, tolerance: 1.045e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,638:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.143e+05, tolerance: 1.032e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,662:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.521e+05, tolerance: 1.031e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,664:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.166e+05, tolerance: 1.022e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,674:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.725e+05, tolerance: 1.039e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:58:03,734:INFO:Calculating mean and std
2022-09-13 00:58:03,736:INFO:Creating metrics dataframe
2022-09-13 00:58:03,740:INFO:Uploading results into container
2022-09-13 00:58:03,741:INFO:Uploading model into container now
2022-09-13 00:58:03,741:INFO:master_model_container: 23
2022-09-13 00:58:03,741:INFO:display_container: 3
2022-09-13 00:58:03,742:INFO:ElasticNet(random_state=618)
2022-09-13 00:58:03,742:INFO:create_model() successfully completed......................................
2022-09-13 00:58:03,883:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:03,883:INFO:Creating metrics dataframe
2022-09-13 00:58:03,902:INFO:Initializing Least Angle Regression
2022-09-13 00:58:03,903:INFO:Total runtime is 0.03740809758504232 minutes
2022-09-13 00:58:03,909:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:03,909:INFO:Initializing create_model()
2022-09-13 00:58:03,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:03,910:INFO:Checking exceptions
2022-09-13 00:58:03,912:INFO:Importing libraries
2022-09-13 00:58:03,912:INFO:Copying training dataset
2022-09-13 00:58:03,917:INFO:Defining folds
2022-09-13 00:58:03,917:INFO:Declaring metric variables
2022-09-13 00:58:03,923:INFO:Importing untrained model
2022-09-13 00:58:03,927:INFO:Least Angle Regression Imported successfully
2022-09-13 00:58:03,935:INFO:Starting cross validation
2022-09-13 00:58:03,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:04,061:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,069:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,073:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,095:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,132:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,156:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,174:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,175:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,200:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,233:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:04,275:INFO:Calculating mean and std
2022-09-13 00:58:04,277:INFO:Creating metrics dataframe
2022-09-13 00:58:04,282:INFO:Uploading results into container
2022-09-13 00:58:04,282:INFO:Uploading model into container now
2022-09-13 00:58:04,283:INFO:master_model_container: 24
2022-09-13 00:58:04,283:INFO:display_container: 3
2022-09-13 00:58:04,284:INFO:Lars(random_state=618)
2022-09-13 00:58:04,284:INFO:create_model() successfully completed......................................
2022-09-13 00:58:04,423:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:04,423:INFO:Creating metrics dataframe
2022-09-13 00:58:04,439:INFO:Initializing Lasso Least Angle Regression
2022-09-13 00:58:04,439:INFO:Total runtime is 0.04633423089981079 minutes
2022-09-13 00:58:04,443:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:04,443:INFO:Initializing create_model()
2022-09-13 00:58:04,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:04,444:INFO:Checking exceptions
2022-09-13 00:58:04,445:INFO:Importing libraries
2022-09-13 00:58:04,445:INFO:Copying training dataset
2022-09-13 00:58:04,450:INFO:Defining folds
2022-09-13 00:58:04,450:INFO:Declaring metric variables
2022-09-13 00:58:04,454:INFO:Importing untrained model
2022-09-13 00:58:04,458:INFO:Lasso Least Angle Regression Imported successfully
2022-09-13 00:58:04,467:INFO:Starting cross validation
2022-09-13 00:58:04,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:04,566:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,589:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,595:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,639:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,669:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,686:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,688:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,700:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,721:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,746:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:58:04,800:INFO:Calculating mean and std
2022-09-13 00:58:04,802:INFO:Creating metrics dataframe
2022-09-13 00:58:04,806:INFO:Uploading results into container
2022-09-13 00:58:04,807:INFO:Uploading model into container now
2022-09-13 00:58:04,807:INFO:master_model_container: 25
2022-09-13 00:58:04,807:INFO:display_container: 3
2022-09-13 00:58:04,808:INFO:LassoLars(random_state=618)
2022-09-13 00:58:04,808:INFO:create_model() successfully completed......................................
2022-09-13 00:58:04,968:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:04,968:INFO:Creating metrics dataframe
2022-09-13 00:58:04,986:INFO:Initializing Orthogonal Matching Pursuit
2022-09-13 00:58:04,986:INFO:Total runtime is 0.055459797382354736 minutes
2022-09-13 00:58:04,991:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:04,991:INFO:Initializing create_model()
2022-09-13 00:58:04,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:04,992:INFO:Checking exceptions
2022-09-13 00:58:04,994:INFO:Importing libraries
2022-09-13 00:58:04,994:INFO:Copying training dataset
2022-09-13 00:58:04,999:INFO:Defining folds
2022-09-13 00:58:04,999:INFO:Declaring metric variables
2022-09-13 00:58:05,005:INFO:Importing untrained model
2022-09-13 00:58:05,009:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-13 00:58:05,019:INFO:Starting cross validation
2022-09-13 00:58:05,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:05,109:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,118:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,139:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,159:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,191:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,194:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,217:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,240:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,247:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,264:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:58:05,313:INFO:Calculating mean and std
2022-09-13 00:58:05,315:INFO:Creating metrics dataframe
2022-09-13 00:58:05,320:INFO:Uploading results into container
2022-09-13 00:58:05,321:INFO:Uploading model into container now
2022-09-13 00:58:05,322:INFO:master_model_container: 26
2022-09-13 00:58:05,322:INFO:display_container: 3
2022-09-13 00:58:05,323:INFO:OrthogonalMatchingPursuit()
2022-09-13 00:58:05,323:INFO:create_model() successfully completed......................................
2022-09-13 00:58:05,460:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:05,461:INFO:Creating metrics dataframe
2022-09-13 00:58:05,480:INFO:Initializing Bayesian Ridge
2022-09-13 00:58:05,480:INFO:Total runtime is 0.06368778149286906 minutes
2022-09-13 00:58:05,485:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:05,486:INFO:Initializing create_model()
2022-09-13 00:58:05,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:05,486:INFO:Checking exceptions
2022-09-13 00:58:05,488:INFO:Importing libraries
2022-09-13 00:58:05,488:INFO:Copying training dataset
2022-09-13 00:58:05,492:INFO:Defining folds
2022-09-13 00:58:05,492:INFO:Declaring metric variables
2022-09-13 00:58:05,496:INFO:Importing untrained model
2022-09-13 00:58:05,502:INFO:Bayesian Ridge Imported successfully
2022-09-13 00:58:05,510:INFO:Starting cross validation
2022-09-13 00:58:05,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:05,849:INFO:Calculating mean and std
2022-09-13 00:58:05,852:INFO:Creating metrics dataframe
2022-09-13 00:58:05,856:INFO:Uploading results into container
2022-09-13 00:58:05,856:INFO:Uploading model into container now
2022-09-13 00:58:05,857:INFO:master_model_container: 27
2022-09-13 00:58:05,857:INFO:display_container: 3
2022-09-13 00:58:05,858:INFO:BayesianRidge()
2022-09-13 00:58:05,858:INFO:create_model() successfully completed......................................
2022-09-13 00:58:05,992:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:05,992:INFO:Creating metrics dataframe
2022-09-13 00:58:06,009:INFO:Initializing Passive Aggressive Regressor
2022-09-13 00:58:06,009:INFO:Total runtime is 0.072497562567393 minutes
2022-09-13 00:58:06,013:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:06,013:INFO:Initializing create_model()
2022-09-13 00:58:06,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:06,014:INFO:Checking exceptions
2022-09-13 00:58:06,016:INFO:Importing libraries
2022-09-13 00:58:06,016:INFO:Copying training dataset
2022-09-13 00:58:06,020:INFO:Defining folds
2022-09-13 00:58:06,020:INFO:Declaring metric variables
2022-09-13 00:58:06,025:INFO:Importing untrained model
2022-09-13 00:58:06,029:INFO:Passive Aggressive Regressor Imported successfully
2022-09-13 00:58:06,039:INFO:Starting cross validation
2022-09-13 00:58:06,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:06,374:INFO:Calculating mean and std
2022-09-13 00:58:06,376:INFO:Creating metrics dataframe
2022-09-13 00:58:06,380:INFO:Uploading results into container
2022-09-13 00:58:06,380:INFO:Uploading model into container now
2022-09-13 00:58:06,381:INFO:master_model_container: 28
2022-09-13 00:58:06,381:INFO:display_container: 3
2022-09-13 00:58:06,381:INFO:PassiveAggressiveRegressor(random_state=618)
2022-09-13 00:58:06,381:INFO:create_model() successfully completed......................................
2022-09-13 00:58:06,525:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:06,525:INFO:Creating metrics dataframe
2022-09-13 00:58:06,542:INFO:Initializing Huber Regressor
2022-09-13 00:58:06,542:INFO:Total runtime is 0.0813904643058777 minutes
2022-09-13 00:58:06,546:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:06,546:INFO:Initializing create_model()
2022-09-13 00:58:06,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:06,546:INFO:Checking exceptions
2022-09-13 00:58:06,548:INFO:Importing libraries
2022-09-13 00:58:06,548:INFO:Copying training dataset
2022-09-13 00:58:06,552:INFO:Defining folds
2022-09-13 00:58:06,552:INFO:Declaring metric variables
2022-09-13 00:58:06,557:INFO:Importing untrained model
2022-09-13 00:58:06,561:INFO:Huber Regressor Imported successfully
2022-09-13 00:58:06,572:INFO:Starting cross validation
2022-09-13 00:58:06,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:06,903:INFO:Calculating mean and std
2022-09-13 00:58:06,905:INFO:Creating metrics dataframe
2022-09-13 00:58:06,909:INFO:Uploading results into container
2022-09-13 00:58:06,909:INFO:Uploading model into container now
2022-09-13 00:58:06,910:INFO:master_model_container: 29
2022-09-13 00:58:06,910:INFO:display_container: 3
2022-09-13 00:58:06,910:INFO:HuberRegressor()
2022-09-13 00:58:06,911:INFO:create_model() successfully completed......................................
2022-09-13 00:58:07,048:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:07,048:INFO:Creating metrics dataframe
2022-09-13 00:58:07,063:INFO:Initializing K Neighbors Regressor
2022-09-13 00:58:07,064:INFO:Total runtime is 0.09008387327194214 minutes
2022-09-13 00:58:07,067:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:07,068:INFO:Initializing create_model()
2022-09-13 00:58:07,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:07,068:INFO:Checking exceptions
2022-09-13 00:58:07,072:INFO:Importing libraries
2022-09-13 00:58:07,072:INFO:Copying training dataset
2022-09-13 00:58:07,076:INFO:Defining folds
2022-09-13 00:58:07,076:INFO:Declaring metric variables
2022-09-13 00:58:07,080:INFO:Importing untrained model
2022-09-13 00:58:07,087:INFO:K Neighbors Regressor Imported successfully
2022-09-13 00:58:07,096:INFO:Starting cross validation
2022-09-13 00:58:07,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:07,552:INFO:Calculating mean and std
2022-09-13 00:58:07,555:INFO:Creating metrics dataframe
2022-09-13 00:58:07,559:INFO:Uploading results into container
2022-09-13 00:58:07,559:INFO:Uploading model into container now
2022-09-13 00:58:07,560:INFO:master_model_container: 30
2022-09-13 00:58:07,560:INFO:display_container: 3
2022-09-13 00:58:07,560:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-13 00:58:07,560:INFO:create_model() successfully completed......................................
2022-09-13 00:58:07,697:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:07,697:INFO:Creating metrics dataframe
2022-09-13 00:58:07,718:INFO:Initializing Decision Tree Regressor
2022-09-13 00:58:07,718:INFO:Total runtime is 0.10098803043365479 minutes
2022-09-13 00:58:07,725:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:07,725:INFO:Initializing create_model()
2022-09-13 00:58:07,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:07,726:INFO:Checking exceptions
2022-09-13 00:58:07,728:INFO:Importing libraries
2022-09-13 00:58:07,728:INFO:Copying training dataset
2022-09-13 00:58:07,731:INFO:Defining folds
2022-09-13 00:58:07,731:INFO:Declaring metric variables
2022-09-13 00:58:07,735:INFO:Importing untrained model
2022-09-13 00:58:07,740:INFO:Decision Tree Regressor Imported successfully
2022-09-13 00:58:07,756:INFO:Starting cross validation
2022-09-13 00:58:07,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:08,077:INFO:Calculating mean and std
2022-09-13 00:58:08,079:INFO:Creating metrics dataframe
2022-09-13 00:58:08,083:INFO:Uploading results into container
2022-09-13 00:58:08,083:INFO:Uploading model into container now
2022-09-13 00:58:08,084:INFO:master_model_container: 31
2022-09-13 00:58:08,084:INFO:display_container: 3
2022-09-13 00:58:08,084:INFO:DecisionTreeRegressor(random_state=618)
2022-09-13 00:58:08,085:INFO:create_model() successfully completed......................................
2022-09-13 00:58:08,227:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:08,228:INFO:Creating metrics dataframe
2022-09-13 00:58:08,245:INFO:Initializing Random Forest Regressor
2022-09-13 00:58:08,246:INFO:Total runtime is 0.10978117386500041 minutes
2022-09-13 00:58:08,249:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:08,250:INFO:Initializing create_model()
2022-09-13 00:58:08,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:08,250:INFO:Checking exceptions
2022-09-13 00:58:08,252:INFO:Importing libraries
2022-09-13 00:58:08,252:INFO:Copying training dataset
2022-09-13 00:58:08,256:INFO:Defining folds
2022-09-13 00:58:08,256:INFO:Declaring metric variables
2022-09-13 00:58:08,261:INFO:Importing untrained model
2022-09-13 00:58:08,265:INFO:Random Forest Regressor Imported successfully
2022-09-13 00:58:08,275:INFO:Starting cross validation
2022-09-13 00:58:08,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:09,207:INFO:Calculating mean and std
2022-09-13 00:58:09,208:INFO:Creating metrics dataframe
2022-09-13 00:58:09,211:INFO:Uploading results into container
2022-09-13 00:58:09,212:INFO:Uploading model into container now
2022-09-13 00:58:09,212:INFO:master_model_container: 32
2022-09-13 00:58:09,212:INFO:display_container: 3
2022-09-13 00:58:09,212:INFO:RandomForestRegressor(n_jobs=-1, random_state=618)
2022-09-13 00:58:09,213:INFO:create_model() successfully completed......................................
2022-09-13 00:58:09,350:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:09,350:INFO:Creating metrics dataframe
2022-09-13 00:58:09,372:INFO:Initializing Extra Trees Regressor
2022-09-13 00:58:09,373:INFO:Total runtime is 0.12856427828470868 minutes
2022-09-13 00:58:09,377:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:09,377:INFO:Initializing create_model()
2022-09-13 00:58:09,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:09,378:INFO:Checking exceptions
2022-09-13 00:58:09,379:INFO:Importing libraries
2022-09-13 00:58:09,379:INFO:Copying training dataset
2022-09-13 00:58:09,382:INFO:Defining folds
2022-09-13 00:58:09,383:INFO:Declaring metric variables
2022-09-13 00:58:09,386:INFO:Importing untrained model
2022-09-13 00:58:09,394:INFO:Extra Trees Regressor Imported successfully
2022-09-13 00:58:09,406:INFO:Starting cross validation
2022-09-13 00:58:09,408:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:10,192:INFO:Calculating mean and std
2022-09-13 00:58:10,194:INFO:Creating metrics dataframe
2022-09-13 00:58:10,199:INFO:Uploading results into container
2022-09-13 00:58:10,199:INFO:Uploading model into container now
2022-09-13 00:58:10,200:INFO:master_model_container: 33
2022-09-13 00:58:10,200:INFO:display_container: 3
2022-09-13 00:58:10,200:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=618)
2022-09-13 00:58:10,200:INFO:create_model() successfully completed......................................
2022-09-13 00:58:10,341:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:10,341:INFO:Creating metrics dataframe
2022-09-13 00:58:10,359:INFO:Initializing AdaBoost Regressor
2022-09-13 00:58:10,359:INFO:Total runtime is 0.14500521024068197 minutes
2022-09-13 00:58:10,363:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:10,364:INFO:Initializing create_model()
2022-09-13 00:58:10,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:10,364:INFO:Checking exceptions
2022-09-13 00:58:10,366:INFO:Importing libraries
2022-09-13 00:58:10,366:INFO:Copying training dataset
2022-09-13 00:58:10,369:INFO:Defining folds
2022-09-13 00:58:10,369:INFO:Declaring metric variables
2022-09-13 00:58:10,374:INFO:Importing untrained model
2022-09-13 00:58:10,378:INFO:AdaBoost Regressor Imported successfully
2022-09-13 00:58:10,387:INFO:Starting cross validation
2022-09-13 00:58:10,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:10,848:INFO:Calculating mean and std
2022-09-13 00:58:10,851:INFO:Creating metrics dataframe
2022-09-13 00:58:10,856:INFO:Uploading results into container
2022-09-13 00:58:10,856:INFO:Uploading model into container now
2022-09-13 00:58:10,857:INFO:master_model_container: 34
2022-09-13 00:58:10,857:INFO:display_container: 3
2022-09-13 00:58:10,858:INFO:AdaBoostRegressor(random_state=618)
2022-09-13 00:58:10,858:INFO:create_model() successfully completed......................................
2022-09-13 00:58:10,997:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:10,999:INFO:Creating metrics dataframe
2022-09-13 00:58:11,016:INFO:Initializing Gradient Boosting Regressor
2022-09-13 00:58:11,017:INFO:Total runtime is 0.15597585439682007 minutes
2022-09-13 00:58:11,021:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:11,021:INFO:Initializing create_model()
2022-09-13 00:58:11,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:11,021:INFO:Checking exceptions
2022-09-13 00:58:11,023:INFO:Importing libraries
2022-09-13 00:58:11,023:INFO:Copying training dataset
2022-09-13 00:58:11,027:INFO:Defining folds
2022-09-13 00:58:11,027:INFO:Declaring metric variables
2022-09-13 00:58:11,031:INFO:Importing untrained model
2022-09-13 00:58:11,035:INFO:Gradient Boosting Regressor Imported successfully
2022-09-13 00:58:11,044:INFO:Starting cross validation
2022-09-13 00:58:11,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:11,504:INFO:Calculating mean and std
2022-09-13 00:58:11,507:INFO:Creating metrics dataframe
2022-09-13 00:58:11,511:INFO:Uploading results into container
2022-09-13 00:58:11,511:INFO:Uploading model into container now
2022-09-13 00:58:11,512:INFO:master_model_container: 35
2022-09-13 00:58:11,512:INFO:display_container: 3
2022-09-13 00:58:11,513:INFO:GradientBoostingRegressor(random_state=618)
2022-09-13 00:58:11,513:INFO:create_model() successfully completed......................................
2022-09-13 00:58:11,651:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:11,651:INFO:Creating metrics dataframe
2022-09-13 00:58:11,674:INFO:Initializing Extreme Gradient Boosting
2022-09-13 00:58:11,674:INFO:Total runtime is 0.16691331466039022 minutes
2022-09-13 00:58:11,678:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:11,679:INFO:Initializing create_model()
2022-09-13 00:58:11,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:11,679:INFO:Checking exceptions
2022-09-13 00:58:11,681:INFO:Importing libraries
2022-09-13 00:58:11,682:INFO:Copying training dataset
2022-09-13 00:58:11,686:INFO:Defining folds
2022-09-13 00:58:11,687:INFO:Declaring metric variables
2022-09-13 00:58:11,692:INFO:Importing untrained model
2022-09-13 00:58:11,699:INFO:Extreme Gradient Boosting Imported successfully
2022-09-13 00:58:11,707:INFO:Starting cross validation
2022-09-13 00:58:11,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:12,271:INFO:Calculating mean and std
2022-09-13 00:58:12,274:INFO:Creating metrics dataframe
2022-09-13 00:58:12,277:INFO:Uploading results into container
2022-09-13 00:58:12,278:INFO:Uploading model into container now
2022-09-13 00:58:12,278:INFO:master_model_container: 36
2022-09-13 00:58:12,278:INFO:display_container: 3
2022-09-13 00:58:12,279:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=618,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-13 00:58:12,279:INFO:create_model() successfully completed......................................
2022-09-13 00:58:12,406:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:12,407:INFO:Creating metrics dataframe
2022-09-13 00:58:12,429:INFO:Initializing Light Gradient Boosting Machine
2022-09-13 00:58:12,430:INFO:Total runtime is 0.17951289415359498 minutes
2022-09-13 00:58:12,434:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:12,434:INFO:Initializing create_model()
2022-09-13 00:58:12,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:12,434:INFO:Checking exceptions
2022-09-13 00:58:12,436:INFO:Importing libraries
2022-09-13 00:58:12,436:INFO:Copying training dataset
2022-09-13 00:58:12,440:INFO:Defining folds
2022-09-13 00:58:12,441:INFO:Declaring metric variables
2022-09-13 00:58:12,445:INFO:Importing untrained model
2022-09-13 00:58:12,450:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-13 00:58:12,458:INFO:Starting cross validation
2022-09-13 00:58:12,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:13,473:INFO:Calculating mean and std
2022-09-13 00:58:13,475:INFO:Creating metrics dataframe
2022-09-13 00:58:13,479:INFO:Uploading results into container
2022-09-13 00:58:13,479:INFO:Uploading model into container now
2022-09-13 00:58:13,480:INFO:master_model_container: 37
2022-09-13 00:58:13,480:INFO:display_container: 3
2022-09-13 00:58:13,480:INFO:LGBMRegressor(random_state=618)
2022-09-13 00:58:13,480:INFO:create_model() successfully completed......................................
2022-09-13 00:58:13,624:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:13,624:INFO:Creating metrics dataframe
2022-09-13 00:58:13,643:INFO:Initializing Dummy Regressor
2022-09-13 00:58:13,643:INFO:Total runtime is 0.1997421383857727 minutes
2022-09-13 00:58:13,647:INFO:SubProcess create_model() called ==================================
2022-09-13 00:58:13,647:INFO:Initializing create_model()
2022-09-13 00:58:13,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06BADBB88>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:13,647:INFO:Checking exceptions
2022-09-13 00:58:13,649:INFO:Importing libraries
2022-09-13 00:58:13,649:INFO:Copying training dataset
2022-09-13 00:58:13,652:INFO:Defining folds
2022-09-13 00:58:13,653:INFO:Declaring metric variables
2022-09-13 00:58:13,657:INFO:Importing untrained model
2022-09-13 00:58:13,663:INFO:Dummy Regressor Imported successfully
2022-09-13 00:58:13,671:INFO:Starting cross validation
2022-09-13 00:58:13,673:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:58:13,988:INFO:Calculating mean and std
2022-09-13 00:58:13,989:INFO:Creating metrics dataframe
2022-09-13 00:58:13,993:INFO:Uploading results into container
2022-09-13 00:58:13,994:INFO:Uploading model into container now
2022-09-13 00:58:13,994:INFO:master_model_container: 38
2022-09-13 00:58:13,995:INFO:display_container: 3
2022-09-13 00:58:13,995:INFO:DummyRegressor()
2022-09-13 00:58:13,995:INFO:create_model() successfully completed......................................
2022-09-13 00:58:14,133:INFO:SubProcess create_model() end ==================================
2022-09-13 00:58:14,134:INFO:Creating metrics dataframe
2022-09-13 00:58:14,166:INFO:Initializing create_model()
2022-09-13 00:58:14,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B063B4C788>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:58:14,167:INFO:Checking exceptions
2022-09-13 00:58:14,170:INFO:Importing libraries
2022-09-13 00:58:14,170:INFO:Copying training dataset
2022-09-13 00:58:14,173:INFO:Defining folds
2022-09-13 00:58:14,173:INFO:Declaring metric variables
2022-09-13 00:58:14,173:INFO:Importing untrained model
2022-09-13 00:58:14,173:INFO:Declaring custom model
2022-09-13 00:58:14,174:INFO:Linear Regression Imported successfully
2022-09-13 00:58:14,176:INFO:Cross validation set to False
2022-09-13 00:58:14,176:INFO:Fitting Model
2022-09-13 00:58:14,229:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:58:14,229:INFO:create_model() successfully completed......................................
2022-09-13 00:58:14,441:INFO:master_model_container: 38
2022-09-13 00:58:14,441:INFO:display_container: 3
2022-09-13 00:58:14,442:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:58:14,442:INFO:compare_models() successfully completed......................................
2022-09-13 00:59:33,427:INFO:PyCaret RegressionExperiment
2022-09-13 00:59:33,427:INFO:Logging name: reg-default-name
2022-09-13 00:59:33,427:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-13 00:59:33,427:INFO:version 3.0.0.rc3
2022-09-13 00:59:33,427:INFO:Initializing setup()
2022-09-13 00:59:33,427:INFO:self.USI: f0da
2022-09-13 00:59:33,427:INFO:self.variable_keys: {'_gpu_n_jobs_param', 'data', 'idx', 'n_jobs_param', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'logging_param', 'memory', 'target_param', 'variable_keys', '_all_models', 'exp_id', '_all_metrics', 'pipeline', 'html_param', 'y', '_all_models_internal', 'log_plots_param', 'exp_name_log', 'y_train', 'X', 'display_container', 'transform_target_method_param', 'master_model_container', 'seed', 'X_test', 'transform_target_param', '_ml_usecase', 'gpu_param', 'y_test', 'fold_generator', 'X_train'}
2022-09-13 00:59:33,427:INFO:Checking environment
2022-09-13 00:59:33,427:INFO:python_version: 3.7.11
2022-09-13 00:59:33,427:INFO:python_build: ('default', 'Jul 27 2021 09:42:29')
2022-09-13 00:59:33,428:INFO:machine: AMD64
2022-09-13 00:59:33,428:INFO:platform: Windows-10-10.0.22000-SP0
2022-09-13 00:59:33,428:INFO:Memory: svmem(total=34156802048, available=11323785216, percent=66.8, used=22833016832, free=11323785216)
2022-09-13 00:59:33,428:INFO:Physical Core: 6
2022-09-13 00:59:33,428:INFO:Logical Core: 12
2022-09-13 00:59:33,428:INFO:Checking libraries
2022-09-13 00:59:33,428:INFO:System:
2022-09-13 00:59:33,428:INFO:    python: 3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]
2022-09-13 00:59:33,428:INFO:executable: c:\Users\Jamel\anaconda3\envs\dev\python.exe
2022-09-13 00:59:33,428:INFO:   machine: Windows-10-10.0.22000-SP0
2022-09-13 00:59:33,428:INFO:PyCaret required dependencies:
2022-09-13 00:59:33,428:INFO:                 pip: 22.1.2
2022-09-13 00:59:33,429:INFO:          setuptools: 60.10.0
2022-09-13 00:59:33,429:INFO:             pycaret: 3.0.0rc3
2022-09-13 00:59:33,429:INFO:             IPython: 7.31.1
2022-09-13 00:59:33,429:INFO:          ipywidgets: 7.6.5
2022-09-13 00:59:33,429:INFO:                tqdm: 4.64.0
2022-09-13 00:59:33,429:INFO:               numpy: 1.21.6
2022-09-13 00:59:33,429:INFO:              pandas: 1.3.5
2022-09-13 00:59:33,429:INFO:              jinja2: 3.0.3
2022-09-13 00:59:33,429:INFO:               scipy: 1.7.3
2022-09-13 00:59:33,429:INFO:              joblib: 1.1.0
2022-09-13 00:59:33,429:INFO:             sklearn: 1.0.2
2022-09-13 00:59:33,429:INFO:                pyod: 1.0.4
2022-09-13 00:59:33,429:INFO:            imblearn: 0.9.0
2022-09-13 00:59:33,429:INFO:   category_encoders: 2.5.0
2022-09-13 00:59:33,429:INFO:            lightgbm: 3.3.2
2022-09-13 00:59:33,429:INFO:               numba: 0.55.1
2022-09-13 00:59:33,429:INFO:            requests: 2.28.1
2022-09-13 00:59:33,429:INFO:          matplotlib: 3.5.1
2022-09-13 00:59:33,430:INFO:          scikitplot: 0.3.7
2022-09-13 00:59:33,430:INFO:         yellowbrick: 1.5
2022-09-13 00:59:33,430:INFO:              plotly: 5.9.0
2022-09-13 00:59:33,430:INFO:             kaleido: 0.2.1
2022-09-13 00:59:33,430:INFO:         statsmodels: 0.13.2
2022-09-13 00:59:33,430:INFO:              sktime: 0.13.2
2022-09-13 00:59:33,430:INFO:               tbats: 1.1.0
2022-09-13 00:59:33,430:INFO:            pmdarima: 1.8.5
2022-09-13 00:59:33,430:INFO:              psutil: 5.9.0
2022-09-13 00:59:33,430:INFO:PyCaret optional dependencies:
2022-09-13 00:59:33,430:INFO:                shap: 0.41.0
2022-09-13 00:59:33,430:INFO:           interpret: 0.2.7
2022-09-13 00:59:33,430:INFO:                umap: 0.5.3
2022-09-13 00:59:33,430:INFO:    pandas_profiling: 3.2.0
2022-09-13 00:59:33,430:INFO:  explainerdashboard: 0.3.8.2
2022-09-13 00:59:33,430:INFO:             autoviz: 0.1.43
2022-09-13 00:59:33,430:INFO:           fairlearn: 0.7.0
2022-09-13 00:59:33,431:INFO:             xgboost: 1.6.1
2022-09-13 00:59:33,431:INFO:            catboost: Not installed
2022-09-13 00:59:33,431:INFO:              kmodes: 0.12.1
2022-09-13 00:59:33,431:INFO:             mlxtend: Not installed
2022-09-13 00:59:33,431:INFO:       statsforecast: Not installed
2022-09-13 00:59:33,431:INFO:        tune_sklearn: Not installed
2022-09-13 00:59:33,431:INFO:                 ray: Not installed
2022-09-13 00:59:33,431:INFO:            hyperopt: Not installed
2022-09-13 00:59:33,431:INFO:              optuna: Not installed
2022-09-13 00:59:33,431:INFO:               skopt: Not installed
2022-09-13 00:59:33,431:INFO:              mlflow: Not installed
2022-09-13 00:59:33,431:INFO:              gradio: Not installed
2022-09-13 00:59:33,431:INFO:             fastapi: Not installed
2022-09-13 00:59:33,431:INFO:             uvicorn: Not installed
2022-09-13 00:59:33,431:INFO:              m2cgen: Not installed
2022-09-13 00:59:33,431:INFO:           evidently: Not installed
2022-09-13 00:59:33,431:INFO:                nltk: 3.7
2022-09-13 00:59:33,431:INFO:            pyLDAvis: Not installed
2022-09-13 00:59:33,432:INFO:              gensim: 4.2.0
2022-09-13 00:59:33,432:INFO:               spacy: 3.3.0
2022-09-13 00:59:33,432:INFO:           wordcloud: 1.8.1
2022-09-13 00:59:33,432:INFO:            textblob: 0.17.1
2022-09-13 00:59:33,432:INFO:               fugue: Not installed
2022-09-13 00:59:33,432:INFO:           streamlit: 1.11.0
2022-09-13 00:59:33,432:INFO:             prophet: Not installed
2022-09-13 00:59:33,432:INFO:None
2022-09-13 00:59:33,432:INFO:Set up data.
2022-09-13 00:59:33,441:INFO:Set up train/test split.
2022-09-13 00:59:33,445:INFO:Set up index.
2022-09-13 00:59:33,446:INFO:Set up folding strategy.
2022-09-13 00:59:33,446:INFO:Assigning column types.
2022-09-13 00:59:33,454:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-13 00:59:33,454:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,459:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,464:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,567:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,568:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:33,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:33,571:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,575:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,579:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,631:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,672:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,673:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:33,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:33,675:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-13 00:59:33,679:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,683:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,789:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:33,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:33,802:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,807:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,899:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:33,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:33,902:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-13 00:59:33,910:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:59:33,961:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,000:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,000:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:34,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:34,011:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,114:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:34,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:34,117:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-13 00:59:34,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,219:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:34,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:34,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,323:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:34,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:34,327:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-13 00:59:34,391:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,432:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:34,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:34,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-13 00:59:34,551:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:34,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:34,554:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-13 00:59:34,659:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:34,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:34,779:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:34,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:34,782:INFO:Preparing preprocessing pipeline...
2022-09-13 00:59:34,783:INFO:Set up simple imputation.
2022-09-13 00:59:34,785:INFO:Set up encoding of categorical features.
2022-09-13 00:59:34,785:INFO:Set up variance threshold.
2022-09-13 00:59:35,016:INFO:Finished creating preprocessing pipeline.
2022-09-13 00:59:35,026:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Jamel\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['unix', 'open', 'high', 'low',
                                             'Volume ETH', 'Volume USD'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'date', 'symbol'],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Unnamed: 0', 'unix', 'date',
                                             'open', 'high', 'low',
                                             'Volume ETH', 'Volume USD'],
                                    transformer=LeaveOneOutEncoder(cols=['Unnamed: '
                                                                         '0',
                                                                         'date'],
                                                                   handle_missing='return_nan',
                                                                   random_state=6729))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-13 00:59:35,026:INFO:Creating final display dataframe.
2022-09-13 00:59:35,871:INFO:Setup display_container:                  Description             Value
0                 Session id              6729
1                     Target             close
2                Target type        Regression
3                 Data shape          (876, 7)
4           Train data shape          (613, 7)
5            Test data shape          (263, 7)
6           Numeric features                 6
7       Categorical features                 3
8                 Preprocess              True
9            Imputation type            simple
10        Numeric imputation              mean
11    Categorical imputation          constant
12  Maximum one-hot encoding                 5
13           Encoding method              None
14    Low variance threshold                 0
15            Fold Generator             KFold
16               Fold Number                10
17                  CPU Jobs                -1
18                   Use GPU             False
19            Log Experiment             False
20           Experiment Name  reg-default-name
21                       USI              f0da
2022-09-13 00:59:35,989:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:35,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:36,102:INFO:Soft dependency imported: xgboost: 1.6.1
2022-09-13 00:59:36,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-13 00:59:36,111:INFO:setup() successfully completed in 2.69s...............
2022-09-13 00:59:40,409:INFO:Initializing compare_models()
2022-09-13 00:59:40,410:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engines': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-13 00:59:40,410:INFO:Checking exceptions
2022-09-13 00:59:40,413:INFO:Preparing display monitor
2022-09-13 00:59:40,462:INFO:Initializing Linear Regression
2022-09-13 00:59:40,463:INFO:Total runtime is 1.6705195109049478e-05 minutes
2022-09-13 00:59:40,469:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:40,469:INFO:Initializing create_model()
2022-09-13 00:59:40,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:40,469:INFO:Checking exceptions
2022-09-13 00:59:40,471:INFO:Importing libraries
2022-09-13 00:59:40,471:INFO:Copying training dataset
2022-09-13 00:59:40,474:INFO:Defining folds
2022-09-13 00:59:40,475:INFO:Declaring metric variables
2022-09-13 00:59:40,480:INFO:Importing untrained model
2022-09-13 00:59:40,485:INFO:Linear Regression Imported successfully
2022-09-13 00:59:40,494:INFO:Starting cross validation
2022-09-13 00:59:40,496:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:41,686:INFO:Calculating mean and std
2022-09-13 00:59:41,688:INFO:Creating metrics dataframe
2022-09-13 00:59:41,692:INFO:Uploading results into container
2022-09-13 00:59:41,692:INFO:Uploading model into container now
2022-09-13 00:59:41,693:INFO:master_model_container: 1
2022-09-13 00:59:41,693:INFO:display_container: 2
2022-09-13 00:59:41,694:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:59:41,694:INFO:create_model() successfully completed......................................
2022-09-13 00:59:41,846:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:41,846:INFO:Creating metrics dataframe
2022-09-13 00:59:41,864:INFO:Initializing Lasso Regression
2022-09-13 00:59:41,864:INFO:Total runtime is 0.02337191104888916 minutes
2022-09-13 00:59:41,869:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:41,869:INFO:Initializing create_model()
2022-09-13 00:59:41,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:41,870:INFO:Checking exceptions
2022-09-13 00:59:41,871:INFO:Importing libraries
2022-09-13 00:59:41,871:INFO:Copying training dataset
2022-09-13 00:59:41,874:INFO:Defining folds
2022-09-13 00:59:41,875:INFO:Declaring metric variables
2022-09-13 00:59:41,880:INFO:Importing untrained model
2022-09-13 00:59:41,885:INFO:Lasso Regression Imported successfully
2022-09-13 00:59:41,893:INFO:Starting cross validation
2022-09-13 00:59:41,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:42,015:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.674e+05, tolerance: 1.047e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,034:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.155e+05, tolerance: 1.027e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,036:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.697e+05, tolerance: 1.051e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,051:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.735e+05, tolerance: 1.044e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,093:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.615e+05, tolerance: 1.058e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,096:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.167e+05, tolerance: 1.061e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,113:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.824e+05, tolerance: 1.061e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,135:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.555e+05, tolerance: 1.031e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,157:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.451e+05, tolerance: 1.051e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,177:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.452e+05, tolerance: 1.019e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:42,346:INFO:Calculating mean and std
2022-09-13 00:59:42,348:INFO:Creating metrics dataframe
2022-09-13 00:59:42,352:INFO:Uploading results into container
2022-09-13 00:59:42,352:INFO:Uploading model into container now
2022-09-13 00:59:42,353:INFO:master_model_container: 2
2022-09-13 00:59:42,353:INFO:display_container: 2
2022-09-13 00:59:42,353:INFO:Lasso(random_state=6729)
2022-09-13 00:59:42,354:INFO:create_model() successfully completed......................................
2022-09-13 00:59:42,497:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:42,498:INFO:Creating metrics dataframe
2022-09-13 00:59:42,515:INFO:Initializing Ridge Regression
2022-09-13 00:59:42,516:INFO:Total runtime is 0.03422337770462036 minutes
2022-09-13 00:59:42,520:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:42,521:INFO:Initializing create_model()
2022-09-13 00:59:42,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:42,521:INFO:Checking exceptions
2022-09-13 00:59:42,523:INFO:Importing libraries
2022-09-13 00:59:42,523:INFO:Copying training dataset
2022-09-13 00:59:42,527:INFO:Defining folds
2022-09-13 00:59:42,527:INFO:Declaring metric variables
2022-09-13 00:59:42,532:INFO:Importing untrained model
2022-09-13 00:59:42,537:INFO:Ridge Regression Imported successfully
2022-09-13 00:59:42,545:INFO:Starting cross validation
2022-09-13 00:59:42,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:42,639:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.1522e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,655:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.21962e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,659:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.12133e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,695:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.27171e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,704:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.23819e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,716:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.85828e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,731:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.28002e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,755:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.18113e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,759:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.14995e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,771:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.86629e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-09-13 00:59:42,813:INFO:Calculating mean and std
2022-09-13 00:59:42,815:INFO:Creating metrics dataframe
2022-09-13 00:59:42,819:INFO:Uploading results into container
2022-09-13 00:59:42,819:INFO:Uploading model into container now
2022-09-13 00:59:42,819:INFO:master_model_container: 3
2022-09-13 00:59:42,819:INFO:display_container: 2
2022-09-13 00:59:42,820:INFO:Ridge(random_state=6729)
2022-09-13 00:59:42,820:INFO:create_model() successfully completed......................................
2022-09-13 00:59:42,974:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:42,974:INFO:Creating metrics dataframe
2022-09-13 00:59:42,994:INFO:Initializing Elastic Net
2022-09-13 00:59:42,994:INFO:Total runtime is 0.042209215958913165 minutes
2022-09-13 00:59:43,001:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:43,002:INFO:Initializing create_model()
2022-09-13 00:59:43,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:43,002:INFO:Checking exceptions
2022-09-13 00:59:43,004:INFO:Importing libraries
2022-09-13 00:59:43,004:INFO:Copying training dataset
2022-09-13 00:59:43,008:INFO:Defining folds
2022-09-13 00:59:43,009:INFO:Declaring metric variables
2022-09-13 00:59:43,014:INFO:Importing untrained model
2022-09-13 00:59:43,019:INFO:Elastic Net Imported successfully
2022-09-13 00:59:43,027:INFO:Starting cross validation
2022-09-13 00:59:43,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:43,109:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.671e+05, tolerance: 1.047e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,133:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e+05, tolerance: 1.051e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,166:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.151e+05, tolerance: 1.027e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,177:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.731e+05, tolerance: 1.044e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,177:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e+05, tolerance: 1.058e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,197:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.164e+05, tolerance: 1.061e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,226:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.820e+05, tolerance: 1.061e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,242:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.551e+05, tolerance: 1.031e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,258:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.447e+05, tolerance: 1.051e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,271:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.448e+05, tolerance: 1.019e+05
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-09-13 00:59:43,320:INFO:Calculating mean and std
2022-09-13 00:59:43,322:INFO:Creating metrics dataframe
2022-09-13 00:59:43,326:INFO:Uploading results into container
2022-09-13 00:59:43,327:INFO:Uploading model into container now
2022-09-13 00:59:43,327:INFO:master_model_container: 4
2022-09-13 00:59:43,328:INFO:display_container: 2
2022-09-13 00:59:43,328:INFO:ElasticNet(random_state=6729)
2022-09-13 00:59:43,328:INFO:create_model() successfully completed......................................
2022-09-13 00:59:43,484:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:43,484:INFO:Creating metrics dataframe
2022-09-13 00:59:43,503:INFO:Initializing Least Angle Regression
2022-09-13 00:59:43,504:INFO:Total runtime is 0.05070616801579793 minutes
2022-09-13 00:59:43,508:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:43,509:INFO:Initializing create_model()
2022-09-13 00:59:43,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:43,509:INFO:Checking exceptions
2022-09-13 00:59:43,510:INFO:Importing libraries
2022-09-13 00:59:43,511:INFO:Copying training dataset
2022-09-13 00:59:43,515:INFO:Defining folds
2022-09-13 00:59:43,516:INFO:Declaring metric variables
2022-09-13 00:59:43,521:INFO:Importing untrained model
2022-09-13 00:59:43,525:INFO:Least Angle Regression Imported successfully
2022-09-13 00:59:43,535:INFO:Starting cross validation
2022-09-13 00:59:43,537:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:43,632:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,638:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,660:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,681:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,691:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,712:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,728:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,734:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,744:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,757:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:43,799:INFO:Calculating mean and std
2022-09-13 00:59:43,801:INFO:Creating metrics dataframe
2022-09-13 00:59:43,806:INFO:Uploading results into container
2022-09-13 00:59:43,806:INFO:Uploading model into container now
2022-09-13 00:59:43,806:INFO:master_model_container: 5
2022-09-13 00:59:43,807:INFO:display_container: 2
2022-09-13 00:59:43,808:INFO:Lars(random_state=6729)
2022-09-13 00:59:43,808:INFO:create_model() successfully completed......................................
2022-09-13 00:59:43,957:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:43,957:INFO:Creating metrics dataframe
2022-09-13 00:59:43,974:INFO:Initializing Lasso Least Angle Regression
2022-09-13 00:59:43,975:INFO:Total runtime is 0.058551816145579014 minutes
2022-09-13 00:59:43,979:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:43,979:INFO:Initializing create_model()
2022-09-13 00:59:43,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:43,979:INFO:Checking exceptions
2022-09-13 00:59:43,982:INFO:Importing libraries
2022-09-13 00:59:43,982:INFO:Copying training dataset
2022-09-13 00:59:43,986:INFO:Defining folds
2022-09-13 00:59:43,986:INFO:Declaring metric variables
2022-09-13 00:59:43,991:INFO:Importing untrained model
2022-09-13 00:59:43,995:INFO:Lasso Least Angle Regression Imported successfully
2022-09-13 00:59:44,005:INFO:Starting cross validation
2022-09-13 00:59:44,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:44,107:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,124:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,134:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,156:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,172:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,199:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,212:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,232:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,242:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,253:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-09-13 00:59:44,292:INFO:Calculating mean and std
2022-09-13 00:59:44,294:INFO:Creating metrics dataframe
2022-09-13 00:59:44,298:INFO:Uploading results into container
2022-09-13 00:59:44,299:INFO:Uploading model into container now
2022-09-13 00:59:44,299:INFO:master_model_container: 6
2022-09-13 00:59:44,299:INFO:display_container: 2
2022-09-13 00:59:44,299:INFO:LassoLars(random_state=6729)
2022-09-13 00:59:44,300:INFO:create_model() successfully completed......................................
2022-09-13 00:59:44,441:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:44,441:INFO:Creating metrics dataframe
2022-09-13 00:59:44,457:INFO:Initializing Orthogonal Matching Pursuit
2022-09-13 00:59:44,458:INFO:Total runtime is 0.06659698486328125 minutes
2022-09-13 00:59:44,461:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:44,462:INFO:Initializing create_model()
2022-09-13 00:59:44,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:44,462:INFO:Checking exceptions
2022-09-13 00:59:44,463:INFO:Importing libraries
2022-09-13 00:59:44,463:INFO:Copying training dataset
2022-09-13 00:59:44,468:INFO:Defining folds
2022-09-13 00:59:44,468:INFO:Declaring metric variables
2022-09-13 00:59:44,472:INFO:Importing untrained model
2022-09-13 00:59:44,476:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-13 00:59:44,485:INFO:Starting cross validation
2022-09-13 00:59:44,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:44,565:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,576:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,603:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,609:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,625:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,675:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,685:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,693:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,696:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,721:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 00:59:44,768:INFO:Calculating mean and std
2022-09-13 00:59:44,770:INFO:Creating metrics dataframe
2022-09-13 00:59:44,773:INFO:Uploading results into container
2022-09-13 00:59:44,774:INFO:Uploading model into container now
2022-09-13 00:59:44,774:INFO:master_model_container: 7
2022-09-13 00:59:44,774:INFO:display_container: 2
2022-09-13 00:59:44,774:INFO:OrthogonalMatchingPursuit()
2022-09-13 00:59:44,774:INFO:create_model() successfully completed......................................
2022-09-13 00:59:44,920:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:44,920:INFO:Creating metrics dataframe
2022-09-13 00:59:44,937:INFO:Initializing Bayesian Ridge
2022-09-13 00:59:44,937:INFO:Total runtime is 0.07459240754445394 minutes
2022-09-13 00:59:44,941:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:44,941:INFO:Initializing create_model()
2022-09-13 00:59:44,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:44,941:INFO:Checking exceptions
2022-09-13 00:59:44,943:INFO:Importing libraries
2022-09-13 00:59:44,943:INFO:Copying training dataset
2022-09-13 00:59:44,946:INFO:Defining folds
2022-09-13 00:59:44,946:INFO:Declaring metric variables
2022-09-13 00:59:44,952:INFO:Importing untrained model
2022-09-13 00:59:44,957:INFO:Bayesian Ridge Imported successfully
2022-09-13 00:59:44,964:INFO:Starting cross validation
2022-09-13 00:59:44,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:45,238:INFO:Calculating mean and std
2022-09-13 00:59:45,238:INFO:Creating metrics dataframe
2022-09-13 00:59:45,242:INFO:Uploading results into container
2022-09-13 00:59:45,242:INFO:Uploading model into container now
2022-09-13 00:59:45,242:INFO:master_model_container: 8
2022-09-13 00:59:45,242:INFO:display_container: 2
2022-09-13 00:59:45,243:INFO:BayesianRidge()
2022-09-13 00:59:45,243:INFO:create_model() successfully completed......................................
2022-09-13 00:59:45,383:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:45,383:INFO:Creating metrics dataframe
2022-09-13 00:59:45,403:INFO:Initializing Passive Aggressive Regressor
2022-09-13 00:59:45,403:INFO:Total runtime is 0.08235483964284261 minutes
2022-09-13 00:59:45,408:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:45,408:INFO:Initializing create_model()
2022-09-13 00:59:45,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:45,409:INFO:Checking exceptions
2022-09-13 00:59:45,410:INFO:Importing libraries
2022-09-13 00:59:45,411:INFO:Copying training dataset
2022-09-13 00:59:45,414:INFO:Defining folds
2022-09-13 00:59:45,414:INFO:Declaring metric variables
2022-09-13 00:59:45,419:INFO:Importing untrained model
2022-09-13 00:59:45,423:INFO:Passive Aggressive Regressor Imported successfully
2022-09-13 00:59:45,431:INFO:Starting cross validation
2022-09-13 00:59:45,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:45,718:INFO:Calculating mean and std
2022-09-13 00:59:45,720:INFO:Creating metrics dataframe
2022-09-13 00:59:45,723:INFO:Uploading results into container
2022-09-13 00:59:45,723:INFO:Uploading model into container now
2022-09-13 00:59:45,724:INFO:master_model_container: 9
2022-09-13 00:59:45,724:INFO:display_container: 2
2022-09-13 00:59:45,724:INFO:PassiveAggressiveRegressor(random_state=6729)
2022-09-13 00:59:45,724:INFO:create_model() successfully completed......................................
2022-09-13 00:59:45,859:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:45,859:INFO:Creating metrics dataframe
2022-09-13 00:59:45,881:INFO:Initializing Huber Regressor
2022-09-13 00:59:45,881:INFO:Total runtime is 0.09031740824381511 minutes
2022-09-13 00:59:45,887:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:45,888:INFO:Initializing create_model()
2022-09-13 00:59:45,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:45,889:INFO:Checking exceptions
2022-09-13 00:59:45,890:INFO:Importing libraries
2022-09-13 00:59:45,890:INFO:Copying training dataset
2022-09-13 00:59:45,894:INFO:Defining folds
2022-09-13 00:59:45,894:INFO:Declaring metric variables
2022-09-13 00:59:45,899:INFO:Importing untrained model
2022-09-13 00:59:45,905:INFO:Huber Regressor Imported successfully
2022-09-13 00:59:45,918:INFO:Starting cross validation
2022-09-13 00:59:45,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:46,215:INFO:Calculating mean and std
2022-09-13 00:59:46,218:INFO:Creating metrics dataframe
2022-09-13 00:59:46,221:INFO:Uploading results into container
2022-09-13 00:59:46,222:INFO:Uploading model into container now
2022-09-13 00:59:46,222:INFO:master_model_container: 10
2022-09-13 00:59:46,222:INFO:display_container: 2
2022-09-13 00:59:46,223:INFO:HuberRegressor()
2022-09-13 00:59:46,223:INFO:create_model() successfully completed......................................
2022-09-13 00:59:46,375:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:46,375:INFO:Creating metrics dataframe
2022-09-13 00:59:46,395:INFO:Initializing K Neighbors Regressor
2022-09-13 00:59:46,395:INFO:Total runtime is 0.09889395236968995 minutes
2022-09-13 00:59:46,400:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:46,401:INFO:Initializing create_model()
2022-09-13 00:59:46,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:46,401:INFO:Checking exceptions
2022-09-13 00:59:46,403:INFO:Importing libraries
2022-09-13 00:59:46,404:INFO:Copying training dataset
2022-09-13 00:59:46,408:INFO:Defining folds
2022-09-13 00:59:46,408:INFO:Declaring metric variables
2022-09-13 00:59:46,412:INFO:Importing untrained model
2022-09-13 00:59:46,415:INFO:K Neighbors Regressor Imported successfully
2022-09-13 00:59:46,425:INFO:Starting cross validation
2022-09-13 00:59:46,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:46,891:INFO:Calculating mean and std
2022-09-13 00:59:46,893:INFO:Creating metrics dataframe
2022-09-13 00:59:46,898:INFO:Uploading results into container
2022-09-13 00:59:46,898:INFO:Uploading model into container now
2022-09-13 00:59:46,899:INFO:master_model_container: 11
2022-09-13 00:59:46,900:INFO:display_container: 2
2022-09-13 00:59:46,900:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-13 00:59:46,900:INFO:create_model() successfully completed......................................
2022-09-13 00:59:47,036:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:47,036:INFO:Creating metrics dataframe
2022-09-13 00:59:47,055:INFO:Initializing Decision Tree Regressor
2022-09-13 00:59:47,056:INFO:Total runtime is 0.1099072575569153 minutes
2022-09-13 00:59:47,060:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:47,060:INFO:Initializing create_model()
2022-09-13 00:59:47,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:47,061:INFO:Checking exceptions
2022-09-13 00:59:47,063:INFO:Importing libraries
2022-09-13 00:59:47,063:INFO:Copying training dataset
2022-09-13 00:59:47,067:INFO:Defining folds
2022-09-13 00:59:47,067:INFO:Declaring metric variables
2022-09-13 00:59:47,072:INFO:Importing untrained model
2022-09-13 00:59:47,076:INFO:Decision Tree Regressor Imported successfully
2022-09-13 00:59:47,085:INFO:Starting cross validation
2022-09-13 00:59:47,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:47,375:INFO:Calculating mean and std
2022-09-13 00:59:47,376:INFO:Creating metrics dataframe
2022-09-13 00:59:47,380:INFO:Uploading results into container
2022-09-13 00:59:47,381:INFO:Uploading model into container now
2022-09-13 00:59:47,381:INFO:master_model_container: 12
2022-09-13 00:59:47,381:INFO:display_container: 2
2022-09-13 00:59:47,382:INFO:DecisionTreeRegressor(random_state=6729)
2022-09-13 00:59:47,383:INFO:create_model() successfully completed......................................
2022-09-13 00:59:47,522:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:47,522:INFO:Creating metrics dataframe
2022-09-13 00:59:47,543:INFO:Initializing Random Forest Regressor
2022-09-13 00:59:47,543:INFO:Total runtime is 0.11802705526351931 minutes
2022-09-13 00:59:47,547:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:47,548:INFO:Initializing create_model()
2022-09-13 00:59:47,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:47,548:INFO:Checking exceptions
2022-09-13 00:59:47,550:INFO:Importing libraries
2022-09-13 00:59:47,551:INFO:Copying training dataset
2022-09-13 00:59:47,555:INFO:Defining folds
2022-09-13 00:59:47,555:INFO:Declaring metric variables
2022-09-13 00:59:47,559:INFO:Importing untrained model
2022-09-13 00:59:47,563:INFO:Random Forest Regressor Imported successfully
2022-09-13 00:59:47,573:INFO:Starting cross validation
2022-09-13 00:59:47,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:48,509:INFO:Calculating mean and std
2022-09-13 00:59:48,511:INFO:Creating metrics dataframe
2022-09-13 00:59:48,516:INFO:Uploading results into container
2022-09-13 00:59:48,516:INFO:Uploading model into container now
2022-09-13 00:59:48,517:INFO:master_model_container: 13
2022-09-13 00:59:48,517:INFO:display_container: 2
2022-09-13 00:59:48,517:INFO:RandomForestRegressor(n_jobs=-1, random_state=6729)
2022-09-13 00:59:48,517:INFO:create_model() successfully completed......................................
2022-09-13 00:59:48,653:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:48,653:INFO:Creating metrics dataframe
2022-09-13 00:59:48,675:INFO:Initializing Extra Trees Regressor
2022-09-13 00:59:48,675:INFO:Total runtime is 0.13688517808914186 minutes
2022-09-13 00:59:48,679:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:48,680:INFO:Initializing create_model()
2022-09-13 00:59:48,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:48,680:INFO:Checking exceptions
2022-09-13 00:59:48,682:INFO:Importing libraries
2022-09-13 00:59:48,682:INFO:Copying training dataset
2022-09-13 00:59:48,686:INFO:Defining folds
2022-09-13 00:59:48,687:INFO:Declaring metric variables
2022-09-13 00:59:48,691:INFO:Importing untrained model
2022-09-13 00:59:48,695:INFO:Extra Trees Regressor Imported successfully
2022-09-13 00:59:48,703:INFO:Starting cross validation
2022-09-13 00:59:48,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:49,418:INFO:Calculating mean and std
2022-09-13 00:59:49,420:INFO:Creating metrics dataframe
2022-09-13 00:59:49,425:INFO:Uploading results into container
2022-09-13 00:59:49,425:INFO:Uploading model into container now
2022-09-13 00:59:49,426:INFO:master_model_container: 14
2022-09-13 00:59:49,426:INFO:display_container: 2
2022-09-13 00:59:49,426:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6729)
2022-09-13 00:59:49,426:INFO:create_model() successfully completed......................................
2022-09-13 00:59:49,568:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:49,568:INFO:Creating metrics dataframe
2022-09-13 00:59:49,591:INFO:Initializing AdaBoost Regressor
2022-09-13 00:59:49,591:INFO:Total runtime is 0.15216101805369062 minutes
2022-09-13 00:59:49,596:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:49,596:INFO:Initializing create_model()
2022-09-13 00:59:49,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:49,597:INFO:Checking exceptions
2022-09-13 00:59:49,599:INFO:Importing libraries
2022-09-13 00:59:49,599:INFO:Copying training dataset
2022-09-13 00:59:49,603:INFO:Defining folds
2022-09-13 00:59:49,604:INFO:Declaring metric variables
2022-09-13 00:59:49,608:INFO:Importing untrained model
2022-09-13 00:59:49,613:INFO:AdaBoost Regressor Imported successfully
2022-09-13 00:59:49,622:INFO:Starting cross validation
2022-09-13 00:59:49,623:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:50,058:INFO:Calculating mean and std
2022-09-13 00:59:50,060:INFO:Creating metrics dataframe
2022-09-13 00:59:50,063:INFO:Uploading results into container
2022-09-13 00:59:50,064:INFO:Uploading model into container now
2022-09-13 00:59:50,065:INFO:master_model_container: 15
2022-09-13 00:59:50,065:INFO:display_container: 2
2022-09-13 00:59:50,065:INFO:AdaBoostRegressor(random_state=6729)
2022-09-13 00:59:50,065:INFO:create_model() successfully completed......................................
2022-09-13 00:59:50,208:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:50,209:INFO:Creating metrics dataframe
2022-09-13 00:59:50,230:INFO:Initializing Gradient Boosting Regressor
2022-09-13 00:59:50,230:INFO:Total runtime is 0.16279997030893964 minutes
2022-09-13 00:59:50,235:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:50,235:INFO:Initializing create_model()
2022-09-13 00:59:50,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:50,235:INFO:Checking exceptions
2022-09-13 00:59:50,238:INFO:Importing libraries
2022-09-13 00:59:50,238:INFO:Copying training dataset
2022-09-13 00:59:50,242:INFO:Defining folds
2022-09-13 00:59:50,242:INFO:Declaring metric variables
2022-09-13 00:59:50,247:INFO:Importing untrained model
2022-09-13 00:59:50,253:INFO:Gradient Boosting Regressor Imported successfully
2022-09-13 00:59:50,262:INFO:Starting cross validation
2022-09-13 00:59:50,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:50,735:INFO:Calculating mean and std
2022-09-13 00:59:50,737:INFO:Creating metrics dataframe
2022-09-13 00:59:50,741:INFO:Uploading results into container
2022-09-13 00:59:50,742:INFO:Uploading model into container now
2022-09-13 00:59:50,742:INFO:master_model_container: 16
2022-09-13 00:59:50,742:INFO:display_container: 2
2022-09-13 00:59:50,742:INFO:GradientBoostingRegressor(random_state=6729)
2022-09-13 00:59:50,742:INFO:create_model() successfully completed......................................
2022-09-13 00:59:50,877:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:50,877:INFO:Creating metrics dataframe
2022-09-13 00:59:50,898:INFO:Initializing Extreme Gradient Boosting
2022-09-13 00:59:50,898:INFO:Total runtime is 0.1739368478457133 minutes
2022-09-13 00:59:50,903:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:50,903:INFO:Initializing create_model()
2022-09-13 00:59:50,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:50,904:INFO:Checking exceptions
2022-09-13 00:59:50,906:INFO:Importing libraries
2022-09-13 00:59:50,907:INFO:Copying training dataset
2022-09-13 00:59:50,911:INFO:Defining folds
2022-09-13 00:59:50,911:INFO:Declaring metric variables
2022-09-13 00:59:50,916:INFO:Importing untrained model
2022-09-13 00:59:50,920:INFO:Extreme Gradient Boosting Imported successfully
2022-09-13 00:59:50,928:INFO:Starting cross validation
2022-09-13 00:59:50,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:51,391:INFO:Calculating mean and std
2022-09-13 00:59:51,393:INFO:Creating metrics dataframe
2022-09-13 00:59:51,397:INFO:Uploading results into container
2022-09-13 00:59:51,398:INFO:Uploading model into container now
2022-09-13 00:59:51,398:INFO:master_model_container: 17
2022-09-13 00:59:51,398:INFO:display_container: 2
2022-09-13 00:59:51,399:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=6729,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-13 00:59:51,399:INFO:create_model() successfully completed......................................
2022-09-13 00:59:51,539:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:51,539:INFO:Creating metrics dataframe
2022-09-13 00:59:51,566:INFO:Initializing Light Gradient Boosting Machine
2022-09-13 00:59:51,567:INFO:Total runtime is 0.1850904186566671 minutes
2022-09-13 00:59:51,572:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:51,573:INFO:Initializing create_model()
2022-09-13 00:59:51,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:51,573:INFO:Checking exceptions
2022-09-13 00:59:51,575:INFO:Importing libraries
2022-09-13 00:59:51,575:INFO:Copying training dataset
2022-09-13 00:59:51,579:INFO:Defining folds
2022-09-13 00:59:51,580:INFO:Declaring metric variables
2022-09-13 00:59:51,584:INFO:Importing untrained model
2022-09-13 00:59:51,591:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-13 00:59:51,599:INFO:Starting cross validation
2022-09-13 00:59:51,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:51,945:INFO:Calculating mean and std
2022-09-13 00:59:51,946:INFO:Creating metrics dataframe
2022-09-13 00:59:51,950:INFO:Uploading results into container
2022-09-13 00:59:51,951:INFO:Uploading model into container now
2022-09-13 00:59:51,951:INFO:master_model_container: 18
2022-09-13 00:59:51,951:INFO:display_container: 2
2022-09-13 00:59:51,951:INFO:LGBMRegressor(random_state=6729)
2022-09-13 00:59:51,952:INFO:create_model() successfully completed......................................
2022-09-13 00:59:52,087:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:52,087:INFO:Creating metrics dataframe
2022-09-13 00:59:52,110:INFO:Initializing Dummy Regressor
2022-09-13 00:59:52,111:INFO:Total runtime is 0.19414947032928467 minutes
2022-09-13 00:59:52,115:INFO:SubProcess create_model() called ==================================
2022-09-13 00:59:52,116:INFO:Initializing create_model()
2022-09-13 00:59:52,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06CE86DC8>, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:52,116:INFO:Checking exceptions
2022-09-13 00:59:52,118:INFO:Importing libraries
2022-09-13 00:59:52,118:INFO:Copying training dataset
2022-09-13 00:59:52,122:INFO:Defining folds
2022-09-13 00:59:52,123:INFO:Declaring metric variables
2022-09-13 00:59:52,128:INFO:Importing untrained model
2022-09-13 00:59:52,132:INFO:Dummy Regressor Imported successfully
2022-09-13 00:59:52,140:INFO:Starting cross validation
2022-09-13 00:59:52,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 00:59:52,427:INFO:Calculating mean and std
2022-09-13 00:59:52,429:INFO:Creating metrics dataframe
2022-09-13 00:59:52,432:INFO:Uploading results into container
2022-09-13 00:59:52,432:INFO:Uploading model into container now
2022-09-13 00:59:52,432:INFO:master_model_container: 19
2022-09-13 00:59:52,433:INFO:display_container: 2
2022-09-13 00:59:52,433:INFO:DummyRegressor()
2022-09-13 00:59:52,433:INFO:create_model() successfully completed......................................
2022-09-13 00:59:52,582:INFO:SubProcess create_model() end ==================================
2022-09-13 00:59:52,582:INFO:Creating metrics dataframe
2022-09-13 00:59:52,624:INFO:Initializing create_model()
2022-09-13 00:59:52,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-13 00:59:52,625:INFO:Checking exceptions
2022-09-13 00:59:52,630:INFO:Importing libraries
2022-09-13 00:59:52,630:INFO:Copying training dataset
2022-09-13 00:59:52,634:INFO:Defining folds
2022-09-13 00:59:52,634:INFO:Declaring metric variables
2022-09-13 00:59:52,634:INFO:Importing untrained model
2022-09-13 00:59:52,634:INFO:Declaring custom model
2022-09-13 00:59:52,635:INFO:Linear Regression Imported successfully
2022-09-13 00:59:52,636:INFO:Cross validation set to False
2022-09-13 00:59:52,636:INFO:Fitting Model
2022-09-13 00:59:52,851:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:59:52,851:INFO:create_model() successfully completed......................................
2022-09-13 00:59:53,077:INFO:master_model_container: 19
2022-09-13 00:59:53,077:INFO:display_container: 2
2022-09-13 00:59:53,077:INFO:LinearRegression(n_jobs=-1)
2022-09-13 00:59:53,077:INFO:compare_models() successfully completed......................................
2022-09-13 01:00:04,351:INFO:Initializing evaluate_model()
2022-09-13 01:00:04,351:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2022-09-13 01:00:04,379:INFO:Initializing plot_model()
2022-09-13 01:00:04,379:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:04,379:INFO:Checking exceptions
2022-09-13 01:00:04,381:INFO:Preloading libraries
2022-09-13 01:00:04,381:INFO:Copying training dataset
2022-09-13 01:00:04,381:INFO:Plot type: pipeline
2022-09-13 01:00:04,619:INFO:Visual Rendered Successfully
2022-09-13 01:00:04,762:INFO:plot_model() successfully completed......................................
2022-09-13 01:00:28,760:INFO:Initializing plot_model()
2022-09-13 01:00:28,761:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:28,761:INFO:Checking exceptions
2022-09-13 01:00:33,003:INFO:Initializing plot_model()
2022-09-13 01:00:33,004:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:33,004:INFO:Checking exceptions
2022-09-13 01:00:33,006:INFO:Preloading libraries
2022-09-13 01:00:33,006:INFO:Copying training dataset
2022-09-13 01:00:33,006:INFO:Plot type: residuals
2022-09-13 01:00:33,267:INFO:Fitting Model
2022-09-13 01:00:33,267:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\base.py:451: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  "X does not have valid feature names, but"

2022-09-13 01:00:33,293:INFO:Scoring test/hold-out set
2022-09-13 01:00:33,844:INFO:Visual Rendered Successfully
2022-09-13 01:00:33,990:INFO:plot_model() successfully completed......................................
2022-09-13 01:00:39,264:INFO:Initializing plot_model()
2022-09-13 01:00:39,264:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:39,264:INFO:Checking exceptions
2022-09-13 01:00:39,267:INFO:Preloading libraries
2022-09-13 01:00:39,267:INFO:Copying training dataset
2022-09-13 01:00:39,267:INFO:Plot type: parameter
2022-09-13 01:00:39,272:INFO:Visual Rendered Successfully
2022-09-13 01:00:39,430:INFO:plot_model() successfully completed......................................
2022-09-13 01:00:43,769:INFO:Initializing plot_model()
2022-09-13 01:00:43,770:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:43,770:INFO:Checking exceptions
2022-09-13 01:00:43,772:INFO:Preloading libraries
2022-09-13 01:00:43,772:INFO:Copying training dataset
2022-09-13 01:00:43,772:INFO:Plot type: error
2022-09-13 01:00:43,937:INFO:Fitting Model
2022-09-13 01:00:43,937:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\base.py:451: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  "X does not have valid feature names, but"

2022-09-13 01:00:43,938:INFO:Scoring test/hold-out set
2022-09-13 01:00:44,114:INFO:Visual Rendered Successfully
2022-09-13 01:00:44,269:INFO:plot_model() successfully completed......................................
2022-09-13 01:00:46,167:INFO:Initializing plot_model()
2022-09-13 01:00:46,168:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:46,168:INFO:Checking exceptions
2022-09-13 01:00:46,170:INFO:Preloading libraries
2022-09-13 01:00:46,170:INFO:Copying training dataset
2022-09-13 01:00:46,170:INFO:Plot type: cooks
2022-09-13 01:00:46,329:INFO:Fitting Model
2022-09-13 01:00:46,550:INFO:Visual Rendered Successfully
2022-09-13 01:00:46,686:INFO:plot_model() successfully completed......................................
2022-09-13 01:00:48,400:INFO:Initializing plot_model()
2022-09-13 01:00:48,400:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:48,400:INFO:Checking exceptions
2022-09-13 01:00:48,403:INFO:Preloading libraries
2022-09-13 01:00:48,403:INFO:Copying training dataset
2022-09-13 01:00:48,403:INFO:Plot type: feature
2022-09-13 01:00:48,604:INFO:Visual Rendered Successfully
2022-09-13 01:00:48,737:INFO:plot_model() successfully completed......................................
2022-09-13 01:00:52,595:INFO:Initializing plot_model()
2022-09-13 01:00:52,595:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:52,596:INFO:Checking exceptions
2022-09-13 01:00:52,597:INFO:Preloading libraries
2022-09-13 01:00:52,598:INFO:Copying training dataset
2022-09-13 01:00:52,598:INFO:Plot type: vc
2022-09-13 01:00:52,598:INFO:Determining param_name
2022-09-13 01:00:53,836:INFO:Initializing plot_model()
2022-09-13 01:00:53,836:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:53,837:INFO:Checking exceptions
2022-09-13 01:00:53,840:INFO:Preloading libraries
2022-09-13 01:00:53,840:INFO:Copying training dataset
2022-09-13 01:00:53,841:INFO:Plot type: manifold
2022-09-13 01:00:54,052:INFO:Fitting & Transforming Model
2022-09-13 01:00:54,054:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\manifold\_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.
  FutureWarning,

2022-09-13 01:00:54,219:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\manifold\_t_sne.py:986: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.
  FutureWarning,

2022-09-13 01:00:54,692:INFO:Visual Rendered Successfully
2022-09-13 01:00:54,835:INFO:plot_model() successfully completed......................................
2022-09-13 01:00:59,649:INFO:Initializing plot_model()
2022-09-13 01:00:59,649:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:00:59,650:INFO:Checking exceptions
2022-09-13 01:00:59,651:INFO:Preloading libraries
2022-09-13 01:00:59,652:INFO:Copying training dataset
2022-09-13 01:00:59,652:INFO:Plot type: rfe
2022-09-13 01:00:59,800:INFO:Fitting Model
2022-09-13 01:01:00,168:INFO:Visual Rendered Successfully
2022-09-13 01:01:00,316:INFO:plot_model() successfully completed......................................
2022-09-13 01:01:09,057:INFO:Initializing plot_model()
2022-09-13 01:01:09,057:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:01:09,057:INFO:Checking exceptions
2022-09-13 01:01:09,059:INFO:Preloading libraries
2022-09-13 01:01:09,059:INFO:Copying training dataset
2022-09-13 01:01:09,059:INFO:Plot type: error
2022-09-13 01:01:09,217:INFO:Fitting Model
2022-09-13 01:01:09,218:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\base.py:451: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  "X does not have valid feature names, but"

2022-09-13 01:01:09,218:INFO:Scoring test/hold-out set
2022-09-13 01:01:09,407:INFO:Visual Rendered Successfully
2022-09-13 01:01:09,551:INFO:plot_model() successfully completed......................................
2022-09-13 01:02:40,033:INFO:Initializing create_model()
2022-09-13 01:02:40,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-13 01:02:40,034:INFO:Checking exceptions
2022-09-13 01:02:40,067:INFO:Importing libraries
2022-09-13 01:02:40,068:INFO:Copying training dataset
2022-09-13 01:02:40,071:INFO:Defining folds
2022-09-13 01:02:40,072:INFO:Declaring metric variables
2022-09-13 01:02:40,076:INFO:Importing untrained model
2022-09-13 01:02:40,080:INFO:Linear Regression Imported successfully
2022-09-13 01:02:40,089:INFO:Starting cross validation
2022-09-13 01:02:40,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 01:02:40,409:INFO:Calculating mean and std
2022-09-13 01:02:40,410:INFO:Creating metrics dataframe
2022-09-13 01:02:40,415:INFO:Finalizing model
2022-09-13 01:02:40,464:INFO:Uploading results into container
2022-09-13 01:02:40,466:INFO:Uploading model into container now
2022-09-13 01:02:40,482:INFO:master_model_container: 20
2022-09-13 01:02:40,483:INFO:display_container: 3
2022-09-13 01:02:40,483:INFO:LinearRegression(n_jobs=-1)
2022-09-13 01:02:40,483:INFO:create_model() successfully completed......................................
2022-09-13 01:04:19,690:INFO:Initializing tune_model()
2022-09-13 01:04:19,691:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=1000, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>)
2022-09-13 01:04:19,691:INFO:Checking exceptions
2022-09-13 01:04:19,735:INFO:Copying training dataset
2022-09-13 01:04:19,741:INFO:Checking base model
2022-09-13 01:04:19,742:INFO:Base model : Linear Regression
2022-09-13 01:04:19,748:INFO:Declaring metric variables
2022-09-13 01:04:19,754:INFO:Defining Hyperparameters
2022-09-13 01:04:19,755:INFO:1000 is bigger than total combinations 4, setting search algorithm to grid
2022-09-13 01:04:20,053:INFO:Tuning with n_jobs=-1
2022-09-13 01:04:20,053:INFO:Initializing GridSearchCV
2022-09-13 01:04:20,161:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,183:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,201:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,208:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,223:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,238:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,257:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,271:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,310:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,316:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,361:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,362:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,379:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,403:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,433:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,435:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,446:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,459:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,465:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,493:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,520:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,525:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,543:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,565:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,568:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,583:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,587:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,629:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,639:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,648:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,670:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,676:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,688:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,717:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,720:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,728:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,743:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,794:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,799:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,801:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:04:20,865:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__normalize': True}
2022-09-13 01:04:20,866:INFO:Hyperparameter search completed
2022-09-13 01:04:20,867:INFO:SubProcess create_model() called ==================================
2022-09-13 01:04:20,867:INFO:Initializing create_model()
2022-09-13 01:04:20,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B911F88>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False, 'normalize': True})
2022-09-13 01:04:20,868:INFO:Checking exceptions
2022-09-13 01:04:20,870:INFO:Importing libraries
2022-09-13 01:04:20,870:INFO:Copying training dataset
2022-09-13 01:04:20,874:INFO:Defining folds
2022-09-13 01:04:20,874:INFO:Declaring metric variables
2022-09-13 01:04:20,879:INFO:Importing untrained model
2022-09-13 01:04:20,879:INFO:Declaring custom model
2022-09-13 01:04:20,885:INFO:Linear Regression Imported successfully
2022-09-13 01:04:20,895:INFO:Starting cross validation
2022-09-13 01:04:20,897:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 01:04:20,982:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:20,998:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,012:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,023:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,048:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,067:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,075:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,087:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,103:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,116:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,162:INFO:Calculating mean and std
2022-09-13 01:04:21,164:INFO:Creating metrics dataframe
2022-09-13 01:04:21,169:INFO:Finalizing model
2022-09-13 01:04:21,216:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:04:21,226:INFO:Uploading results into container
2022-09-13 01:04:21,227:INFO:Uploading model into container now
2022-09-13 01:04:21,227:INFO:master_model_container: 21
2022-09-13 01:04:21,228:INFO:display_container: 4
2022-09-13 01:04:21,228:INFO:LinearRegression(fit_intercept=False, n_jobs=-1, normalize=True)
2022-09-13 01:04:21,228:INFO:create_model() successfully completed......................................
2022-09-13 01:04:21,388:INFO:SubProcess create_model() end ==================================
2022-09-13 01:04:21,388:INFO:choose_better activated
2022-09-13 01:04:21,394:INFO:SubProcess create_model() called ==================================
2022-09-13 01:04:21,394:INFO:Initializing create_model()
2022-09-13 01:04:21,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-13 01:04:21,395:INFO:Checking exceptions
2022-09-13 01:04:21,400:INFO:Importing libraries
2022-09-13 01:04:21,400:INFO:Copying training dataset
2022-09-13 01:04:21,404:INFO:Defining folds
2022-09-13 01:04:21,404:INFO:Declaring metric variables
2022-09-13 01:04:21,405:INFO:Importing untrained model
2022-09-13 01:04:21,405:INFO:Declaring custom model
2022-09-13 01:04:21,406:INFO:Linear Regression Imported successfully
2022-09-13 01:04:21,407:INFO:Starting cross validation
2022-09-13 01:04:21,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 01:04:21,693:INFO:Calculating mean and std
2022-09-13 01:04:21,694:INFO:Creating metrics dataframe
2022-09-13 01:04:21,696:INFO:Finalizing model
2022-09-13 01:04:21,739:INFO:Uploading results into container
2022-09-13 01:04:21,739:INFO:Uploading model into container now
2022-09-13 01:04:21,739:INFO:master_model_container: 22
2022-09-13 01:04:21,739:INFO:display_container: 5
2022-09-13 01:04:21,739:INFO:LinearRegression(n_jobs=-1)
2022-09-13 01:04:21,740:INFO:create_model() successfully completed......................................
2022-09-13 01:04:21,895:INFO:SubProcess create_model() end ==================================
2022-09-13 01:04:21,895:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9991
2022-09-13 01:04:21,896:INFO:LinearRegression(fit_intercept=False, n_jobs=-1, normalize=True) result for R2 is 0.9991
2022-09-13 01:04:21,897:INFO:LinearRegression(n_jobs=-1) is best model
2022-09-13 01:04:21,897:INFO:choose_better completed
2022-09-13 01:04:21,897:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-09-13 01:04:21,917:INFO:master_model_container: 22
2022-09-13 01:04:21,917:INFO:display_container: 4
2022-09-13 01:04:21,917:INFO:LinearRegression(n_jobs=-1)
2022-09-13 01:04:21,918:INFO:tune_model() successfully completed......................................
2022-09-13 01:05:07,743:INFO:Initializing tune_model()
2022-09-13 01:05:07,744:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10000, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>)
2022-09-13 01:05:07,744:INFO:Checking exceptions
2022-09-13 01:05:07,784:INFO:Copying training dataset
2022-09-13 01:05:07,787:INFO:Checking base model
2022-09-13 01:05:07,787:INFO:Base model : Linear Regression
2022-09-13 01:05:07,792:INFO:Declaring metric variables
2022-09-13 01:05:07,797:INFO:Defining Hyperparameters
2022-09-13 01:05:07,797:INFO:10000 is bigger than total combinations 4, setting search algorithm to grid
2022-09-13 01:05:07,981:INFO:Tuning with n_jobs=-1
2022-09-13 01:05:07,981:INFO:Initializing GridSearchCV
2022-09-13 01:05:08,074:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,118:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,121:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,132:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,149:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,164:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,173:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,183:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,229:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,232:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,239:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,255:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,258:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,312:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,324:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,351:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,357:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,360:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,371:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,402:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,423:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,445:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,455:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,459:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,495:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,513:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,535:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,542:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,561:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,562:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,566:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,603:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,640:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,649:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,657:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,661:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,672:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,691:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,698:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,707:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  FutureWarning,

2022-09-13 01:05:08,756:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__normalize': True}
2022-09-13 01:05:08,756:INFO:Hyperparameter search completed
2022-09-13 01:05:08,756:INFO:SubProcess create_model() called ==================================
2022-09-13 01:05:08,757:INFO:Initializing create_model()
2022-09-13 01:05:08,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B06B74D048>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False, 'normalize': True})
2022-09-13 01:05:08,757:INFO:Checking exceptions
2022-09-13 01:05:08,758:INFO:Importing libraries
2022-09-13 01:05:08,758:INFO:Copying training dataset
2022-09-13 01:05:08,762:INFO:Defining folds
2022-09-13 01:05:08,762:INFO:Declaring metric variables
2022-09-13 01:05:08,767:INFO:Importing untrained model
2022-09-13 01:05:08,767:INFO:Declaring custom model
2022-09-13 01:05:08,774:INFO:Linear Regression Imported successfully
2022-09-13 01:05:08,783:INFO:Starting cross validation
2022-09-13 01:05:08,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 01:05:08,876:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,881:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,890:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,913:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,924:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,958:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,973:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,989:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:08,992:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:09,015:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:09,059:INFO:Calculating mean and std
2022-09-13 01:05:09,060:INFO:Creating metrics dataframe
2022-09-13 01:05:09,067:INFO:Finalizing model
2022-09-13 01:05:09,115:WARNING:c:\Users\Jamel\anaconda3\envs\dev\lib\site-packages\sklearn\linear_model\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-09-13 01:05:09,123:INFO:Uploading results into container
2022-09-13 01:05:09,124:INFO:Uploading model into container now
2022-09-13 01:05:09,125:INFO:master_model_container: 23
2022-09-13 01:05:09,125:INFO:display_container: 5
2022-09-13 01:05:09,125:INFO:LinearRegression(fit_intercept=False, n_jobs=-1, normalize=True)
2022-09-13 01:05:09,126:INFO:create_model() successfully completed......................................
2022-09-13 01:05:09,294:INFO:SubProcess create_model() end ==================================
2022-09-13 01:05:09,295:INFO:choose_better activated
2022-09-13 01:05:09,300:INFO:SubProcess create_model() called ==================================
2022-09-13 01:05:09,300:INFO:Initializing create_model()
2022-09-13 01:05:09,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-13 01:05:09,300:INFO:Checking exceptions
2022-09-13 01:05:09,304:INFO:Importing libraries
2022-09-13 01:05:09,304:INFO:Copying training dataset
2022-09-13 01:05:09,308:INFO:Defining folds
2022-09-13 01:05:09,308:INFO:Declaring metric variables
2022-09-13 01:05:09,308:INFO:Importing untrained model
2022-09-13 01:05:09,308:INFO:Declaring custom model
2022-09-13 01:05:09,309:INFO:Linear Regression Imported successfully
2022-09-13 01:05:09,310:INFO:Starting cross validation
2022-09-13 01:05:09,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-13 01:05:09,569:INFO:Calculating mean and std
2022-09-13 01:05:09,569:INFO:Creating metrics dataframe
2022-09-13 01:05:09,574:INFO:Finalizing model
2022-09-13 01:05:09,618:INFO:Uploading results into container
2022-09-13 01:05:09,618:INFO:Uploading model into container now
2022-09-13 01:05:09,618:INFO:master_model_container: 24
2022-09-13 01:05:09,618:INFO:display_container: 6
2022-09-13 01:05:09,619:INFO:LinearRegression(n_jobs=-1)
2022-09-13 01:05:09,619:INFO:create_model() successfully completed......................................
2022-09-13 01:05:09,755:INFO:SubProcess create_model() end ==================================
2022-09-13 01:05:09,756:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9991
2022-09-13 01:05:09,757:INFO:LinearRegression(fit_intercept=False, n_jobs=-1, normalize=True) result for R2 is 0.9991
2022-09-13 01:05:09,757:INFO:LinearRegression(n_jobs=-1) is best model
2022-09-13 01:05:09,757:INFO:choose_better completed
2022-09-13 01:05:09,757:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-09-13 01:05:09,773:INFO:master_model_container: 24
2022-09-13 01:05:09,773:INFO:display_container: 5
2022-09-13 01:05:09,773:INFO:LinearRegression(n_jobs=-1)
2022-09-13 01:05:09,774:INFO:tune_model() successfully completed......................................
2022-09-13 01:08:00,485:INFO:Initializing predict_model()
2022-09-13 01:08:00,485:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B06B4ECB88>)
2022-09-13 01:08:00,485:INFO:Checking exceptions
2022-09-13 01:08:00,485:INFO:Preloading libraries
2022-09-13 01:08:00,487:INFO:Set up data.
2022-09-13 01:08:00,497:INFO:Set up index.
2022-09-13 01:33:11,132:INFO:Initializing predict_model()
2022-09-13 01:33:11,134:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B06BAE2288>)
2022-09-13 01:33:11,134:INFO:Checking exceptions
2022-09-13 01:33:11,134:INFO:Preloading libraries
2022-09-13 01:33:11,145:INFO:Set up data.
2022-09-13 01:33:11,160:INFO:Set up index.
2022-09-13 01:33:57,814:INFO:Initializing predict_model()
2022-09-13 01:33:57,814:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B06B4D0C18>)
2022-09-13 01:33:57,815:INFO:Checking exceptions
2022-09-13 01:33:57,815:INFO:Preloading libraries
2022-09-13 01:33:57,821:INFO:Set up data.
2022-09-13 01:33:57,836:INFO:Set up index.
2022-09-13 01:40:05,875:INFO:Initializing plot_model()
2022-09-13 01:40:05,876:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=unseen_prediction, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, system=True)
2022-09-13 01:40:05,876:INFO:Checking exceptions
2022-09-13 01:40:47,448:INFO:Initializing predict_model()
2022-09-13 01:40:47,448:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B06F701678>)
2022-09-13 01:40:47,448:INFO:Checking exceptions
2022-09-13 01:40:47,448:INFO:Preloading libraries
2022-09-13 01:40:47,453:INFO:Set up data.
2022-09-13 01:40:47,462:INFO:Set up index.
2022-09-13 01:41:23,681:INFO:Initializing predict_model()
2022-09-13 01:41:23,682:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B06F701318>)
2022-09-13 01:41:23,682:INFO:Checking exceptions
2022-09-13 01:41:23,682:INFO:Preloading libraries
2022-09-13 01:41:23,684:INFO:Set up data.
2022-09-13 01:41:23,691:INFO:Set up index.
2022-09-13 01:41:54,114:INFO:Initializing predict_model()
2022-09-13 01:41:54,114:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B06CE864C8>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B06B010C18>)
2022-09-13 01:41:54,114:INFO:Checking exceptions
2022-09-13 01:41:54,114:INFO:Preloading libraries
2022-09-13 01:41:54,117:INFO:Set up data.
2022-09-13 01:41:54,125:INFO:Set up index.
